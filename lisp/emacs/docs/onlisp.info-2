This is onlisp.info, produced by makeinfo version 6.3 from onlisp.texi.

INFO-DIR-SECTION Common LISP
START-INFO-DIR-ENTRY
* On Lisp: (onlisp).                *On Lisp* by Paul Graham.
END-INFO-DIR-ENTRY


File: onlisp.info,  Node: 10-4 Recursion,  Prev: 10-3 Non-functional Expanders,  Up: 10 Other Macro Pitfalls

10.4 10-4 Recursion
===================

Sometimes it's natural to define a function recursively.  There's
something inher- ently recursive about a function like this:

     (defun our-length (x)
       (if (null x)
               0(1+ (our-length (cdr x)))))

   This definition somehow seems more natural (though probably slower)
than the iterative equivalent:

     (defun our-length (x)
       (do ((len 0 (1+ len))
                (y x (cdr y)))
               ((null y) len)))

   A function which is neither recursive, nor part of some mutually
recursive set of functions, can be transformed into a macro by the
simple technique described in Section 7-10.  However, just inserting
backquotes and commas won't work with a recursive function.  Let's
take the built-in nth as an example.  (For simplicity, our versions of
nth will do no error-checking.)  Figure 10-2 shows a mistaken attempt
to define nth as a macro.  Superficially, nthb appears to be
equivalent to ntha, but a program containing a call to nthb would not
compile, because the expansion of the call would never terminate.

   In general, it's fine for macros to contain references to other
macros, so long as expansion terminates somewhere.  The trouble with
nthb is that every expansion contains a reference to nthb itself.  The
function version,ntha, terminates because it recurses on the value of
n, which is decremented on each recursion.  But macroexpansion only
has access to forms, not to their values.  When the compiler tries to
macroexpand, say, (nthb x y), the first expansion will yield

     (if (= x 0)
             (car y)
             (nthb (- x 1) (cdr y)))

   This will work:

      (defun ntha (n lst)
            (if (= n 0)
                 (car lst)
                 (ntha (- n 1) (cdr lst))))

   This won't compile:

      (defmacro nthb (n lst)
            `(if (= ,n 0)
                   (car ,lst)
                   (nthb (- ,n 1) (cdr ,lst))))

   Figure 10-2: Mistaken analogy to a recursive function.

   which will in turn expand into:

     (if (= x 0)
             (car y)
             (if (= (- x 1) 0)
                  (car (cdr y))
                  (nthb (- (- x 1) 1) (cdr (cdr y)))))

   and so on into an infinite loop.  It's fine for a macro to expand
into a call to itself, just so long as it doesn't always do so.

   The dangerous thing about recursive macros like nthb is that they
usually work fine under the interpreter.  Then when you finally have
your program working and you try to compile it, it won't even compile.
Not only that, but there will usually be no indication that the
problem is due to a recursive macro; the compiler will simply go into
an infinite loop and leave you to figure out what went wrong.

   In this case, ntha is tail-recursive.  A tail-recursive function
can easily be transformed into an iterative equivalent, and then used
as a model for a macro.  A macro like nthb could be written

     (defmacro nthc (n lst)
       `(do ((n2 ,n (1- n2))
                  (lst2 ,lst (cdr lst2)))
                 ((= n2 0) (car lst2))))

   so it is not impossible in principle to duplicate a recursive
function with a macro.  However, transforming more complicated
recursive functions could be difficult, or even impossible.

      (defmacro nthd (n lst)
         `(nth-fn ,n ,lst))

      (defun nth-fn (n lst)
         (if (= n 0)
              (car lst)
              (nth-fn (- n 1) (cdr lst))))

      (defmacro nthe (n lst)
         `(labels ((nth-fn (n lst)
                            (if (= n 0)
                               (car lst)
                               (nth-fn (- n 1) (cdr lst)))))
             (nth-fn ,n ,lst)))

   Figure 10-3: Two ways to fix the problem.

   Depending on what you need a macro for, you may find it sufficient
to use instead a combination of macro and function.  Figure 10-3 shows
two ways to make what appears to be a recursive macro.  The first
strategy, embodied by nthd, is simply to make the macro expand into a
call to a recursive function.  If, for example, you need a macro only
to save users the trouble of quoting arguments, then this approach
should suffice.

   If you need a macro because you want its whole expansion to be
inserted into the lexical environment of the macro call, then you
would more likely want to follow the example of nthe.  The built-in
labels special form (Section 2-7) creates a local function definition.
While each expansion of nthc will call the globally defined function
nth-fn, each expansion of nthe will have its own version of such a
function within it.

   Although you can't translate a recursive function directly into a
macro, you can write a macro whose expansion is recursively generated.
The expansion function of a macro is a regular Lisp function, and can
of course be recursive.  For example, if we were to define a version
of the built-in or, we would want to use a recursive expansion
function.

   Figure 10-4 shows two ways of defining recursive expansion
functions for or.  The macro ora calls the recursive function
or-expand to generate its expansion.  This macro will work, and so
will the equivalent orb.  Although orb recurses, it recurses on the
arguments to the macro (which are available at macroexpansion time),
not upon their values (which aren't).  It might seem as if the
expansion would contain a reference to orb itself, but the call to orb
generated by one

      (defmacro ora (&rest args)
            (or-expand args))

      (defun or-expand (args)
            (if (null args)
                    nil
               (let ((sym (gensym)))
                     `(let ((,sym ,(car args)))
                           (if ,sym
                              ,sym
                              ,(or-expand (cdr args)))))))

      (defmacro orb (&rest args)
            (if (null args)
               nil
               (let ((sym (gensym)))
                     `(let ((,sym ,(car args)))
                           (if ,sym
                              ,sym
                              (orb ,@(cdr args)))))))

   Figure 10-4: Recursive expansion functions.

   macroexpansion step will be replaced by a let in the next one,
yielding in the final expansion nothing more than a nested stack of
lets; (orb x y) expands into code equivalent to:

     (let ((g2 x))
       (if g2
              g2
              (let ((g3 y))
                (if g3 g3 nil))))

   In fact, ora and orb are equivalent, and which style to use is just
a matter of personal preference.


File: onlisp.info,  Node: 11 Classic Macros,  Next: 12 Generalized Variables,  Prev: 10 Other Macro Pitfalls,  Up: Top

11 11 Classic Macros
********************

This chapter shows how to define the most commonly used types of
macros.  They fall into three categories-with a fair amount of
overlap.  The first group are macros which create context.  Any
operator which causes its arguments to be evaluated in a new context
will probably have to be defined as a macro.  The first two sections
describe the two basic types of context, and show how to define macros
for each.

   The next three sections describe macros for conditional and
repeated evalua- tion.  An operator whose arguments are to be
evaluated less than once, or more than once, must also be defined as a
macro.  There is no sharp distinction between operators for
conditional and repeated evaluation: some of the examples in this
chapter do both (as well as binding).  The final section explains
another similarity between conditional and repeated evaluation: in
some cases, both can be done with functions.

* Menu:

* 11-1 Creating Context::       
* 11-2 The with- Macro::        
* 11-3 Conditional Evaluation::  
* 11-4 Iteration::              
* 11-5 Iteration with Multiple Values::  
* 11-6 Need for Macros::        


File: onlisp.info,  Node: 11-1 Creating Context,  Next: 11-2 The with- Macro,  Prev: 11 Classic Macros,  Up: 11 Classic Macros

11.1 11-1 Creating Context
==========================

Context here has two senses.  One sort of context is a lexical
environment.  The let special form creates a new lexical environment;
the expressions in the body of a let will be evaluated in an
environment which may contain new variables.  If x is set to a at the
toplevel, then

     (let ((x 'b)) (list x))

will nonetheless return (b), because the call to list will be made in
an environ- ment containing a new x, whose value is b.

      (defmacro our-let (binds &body body)
            `((lambda ,(mapcar #'(lambda (x)
                                          (if (consp x) (car x) x))
                                     binds)
                 ,@body)
              ,@(mapcar #'(lambda (x)
                                 (if (consp x) (cadr x) nil))
                            binds)))

   Figure 11-1: Macro implementation of let.

   An operator which is to have a body of expressions must usually be
defined as a macro.  Except for cases like prog1 and progn, the
purpose of such an operator will usually be to cause the body to be
evaluated in some new context.  A macro will be needed to wrap
context-creating code around the body, even if the context does not
include new lexical variables.

   Figure 11-1 shows how let could be defined as a macro on lambda.An
our-let expands into a function application-

     (our-let ((x 1) (y 2))
       (+ x y))

expands into

     ((lambda (x y) (+ x y)) 1 2)

   Figure 11-2 contains three new macros which establish lexical
environments.  Section 7-5 used when-bind as an example of parameter
list destructuring, so this macro has already been described on page
94.  The more general when-bind* takes a list of pairs of the form
(symbol expression)-the same form as the first argument to let.If any
expression returns nil, the whole when-bind* expression returns nil.
Otherwise its body will be evaluated with each symbol bound as if by
let*:


     > (when-bind* ((x (find-if #'consp '(a (1 2) b)))
                            (y (find-if #'oddp x)))
             (+ y 10))
     11

   Finally, the macro with-gensyms is itself for use in writing
macros.  Many macro definitions begin with the creation of gensyms,
sometimes quite a number of them.  The macro with-redraw (page 115)
had to create five:

      (defmacro when-bind ((var expr) &body body)
         `(let ((,var ,expr))
               (when ,var
                 ,@body)))

      (defmacro when-bind* (binds &body body)
         (if (null binds)
                `(progn ,@body)
                `(let (,(car binds))
                      (if ,(caar binds)
                         (when-bind* ,(cdr binds) ,@body)))))

      (defmacro with-gensyms (syms &body body)
         `(let ,(mapcar #'(lambda (s)
                                    `(,s (gensym)))
                               syms)
               ,@body))

   Figure 11-2: Macros which bind variables.

     (defmacro with-redraw ((var objs) &body body)
       (let ((gob (gensym))
                (x0 (gensym)) (y0 (gensym))
                (x1 (gensym)) (y1 (gensym)))
             ...))

   Such definitions are simplified by with-gensyms, which binds a
whole list of variables to gensyms.  With the new macro we would write
just:

     (defmacro with-redraw ((var objs) &body body)
       (with-gensyms (gob x0 y0 x1 y1)
             ...))

   This new macro will be used throughout the remaining chapters.

   If we want to bind some variables and then, depending on some
condition, evaluate one of a set of expressions, we just use a
conditional within a let:

     (let ((sun-place 'park) (rain-place 'library))
       (if (sunny)
               (visit sun-place)
               (visit rain-place)))


      (defmacro condlet (clauses &body body)
            (let ((bodfn (gensym))
                   (vars (mapcar #'(lambda (v) (cons v (gensym)))
                                     (remove-duplicates
                                       (mapcar #'car
                                                  (mappend #'cdr clauses))))))
              `(labels ((,bodfn ,(mapcar #'car vars)
                              ,@body))
                  (cond ,@(mapcar #'(lambda (cl)
                                            (condlet-clause vars cl bodfn))
                                      clauses)))))

      (defun condlet-clause (vars cl bodfn)
            `(,(car cl) (let ,(mapcar #'cdr vars)
                             (let ,(condlet-binds vars cl)
                               (,bodfn ,@(mapcar #'cdr vars))))))


      (defun condlet-binds (vars cl)
            (mapcar #'(lambda (bindform)
                          (if (consp bindform)
                               (cons (cdr (assoc (car bindform) vars))
                                       (cdr bindform))))
                     (cdr cl)))

   Figure 11-3: Combination of cond and let.

   Unfortunately, there is no convenient idiom for the opposite
situation, where we always want to evaluate the same code, but where
the bindings must vary depending on some condition.

   Figure 11-3 contains a macro intended for such situations.  As its
name suggests, condlet behaves like the offspring of cond and let.  It
takes as arguments a list of binding clauses, followed by a body of
code.  Each of the binding clauses is guarded by a test expression;
the body of code will be evaluated with the bindings specified by the
first binding clause whose test expression returns true.  Variables
which occur in some clauses and not others will be bound to nil if the
successful clause does not specify bindings for them:

     > (condlet (((= 1 2) (x (princ 'a)) (y (princ 'b)))
                       ((= 1 1) (y (princ 'c)) (x (princ 'd)))
                       (t          (x (princ 'e)) (z (princ 'f))))
             (list x y z))
     CD
     (D C NIL)

   The definition of condlet can be understood as a generalization of
the def- inition of our-let.  The latter makes its body into a
function, which is applied to the results of evaluating the
initial-value forms.  A condlet expands into code which defines a
local function with labels; within it a cond clause determines which
set of initial-value forms will be evaluated and passed to the
function.

   Notice that the expander uses mappend instead of mapcan to extract
the variable names from the binding clauses.  This is because mapcan
is destructive, and as Section 10-3 warned, it is dangerous to modify
parameter list structure.


File: onlisp.info,  Node: 11-2 The with- Macro,  Next: 11-3 Conditional Evaluation,  Prev: 11-1 Creating Context,  Up: 11 Classic Macros

11.2 11-2 The with- Macro
=========================

There is another kind of context besides a lexical environment.  In
the broader sense, the context is the state of the world, including
the values of special variables, the contents of data structures, and
the state of things outside Lisp.  Operators which build this kind of
context must be defined as macros too, unless their code bodies are to
be packaged up in closures.

   The names of context-building macros often begin with with-.  The
most commonly used macro of this type is probably with-open-file.  Its
body is evaluated with a newly opened file bound to a user-supplied
variable:

     (with-open-file (s "dump" :direction :output)
       (princ 99 s))

   After evaluation of this expression the file "dump" will
automatically be closed, and its contents will be the two characters
"99".

   This operator clearly has to be defined as a macro,because it binds
s.  However, operators which cause forms to be evaluated in a new
context must be defined as macros anyway.  The ignore-errors macro,
new in CLTL2, causes its arguments to be evaluated as if in a progn.
If an error occurs at any point, the whole ignore-errors form simply
returns nil.  (This would be useful, for example, when reading input
typed by the user.)  Though ignore-errors creates no variables, it
still must be defined as a macro, because its arguments are evaluated
in a new context.

   Generally, macros which create context will expand into a block of
code; additional expressions may be placed before the body, after it,
or both.  If code occurs after the body, its purpose may be to leave
the system in a consistent state-to clean up something.  For example,
with-open-file has to close the file it opened.  In such situations,
it is typical to make the context-creating macro expand into an
unwind-protect.

   The purpose of unwind-protect is to ensure that certain expressions
are evaluated even if execution is interrupted.  It takes one or more
arguments, which are evaluated in order.  If all goes smoothly it will
return the value of the first argument, like a prog1.  The difference
is, the remaining arguments will be evaluated even if an error or
throw interrupts evaluation of the first.

     > (setq x 'a)
     A> (unwind-protect
             (progn (princ "What error?")
                      (error "This error."))
             (setq x 'b))
     What error?
     >>Error: This error.

   The unwind-protect form as a whole yields an error.  However, after
returning to the toplevel, we notice that the second argument still
got evaluated:

     >x
     B

   Because with-open-file expands into an unwind-protect, the file it
opens will usually be closed even if an error occurs during the
evaluation of its body.

   Context-creating macros are mostly written for specific
applications.  As an example, suppose we are writing a program which
deals with multiple, remote databases.  The program talks to one
database at a time, indicated by the global variable *db*.  Before
using a database, we have to lock it, so that no one else can use it
at the same time.  When we are finished we have to release the lock.
If we want the value of the query q on the database db, we might say
something like:

     (let ((temp *db*))
          (setq *db* db)
          (lock *db*)
          (prog1 (eval-query q)
                   (release *db*)
                   (setq *db* temp)))

   With a macro we can hide all this bookkeeping.  Figure 11-4 defines
a macro which will allow us to deal with databases at a higher level
of abstraction.  Using with-db, we would say just:

   Pure macro:

      (defmacro with-db (db &body body)
         (let ((temp (gensym)))
             `(let ((,temp *db*))
               (unwind-protect
                  (progn
                       (setq *db* ,db)
                       (lock *db*)
                       ,@body)
                  (progn
                       (release *db*)
                       (setq *db* ,temp))))))

Combination of macro and function:

      (defmacro with-db (db &body body)
         (let ((gbod (gensym)))
             `(let ((,gbod #'(lambda () ,@body)))
               (declare (dynamic-extent ,gbod))
               (with-db-fn *db* ,db ,gbod))))

      (defun with-db-fn (old-db new-db body)
         (unwind-protect
             (progn
              (setq *db* new-db)
              (lock *db*)
              (funcall body))
             (progn
              (release *db*)
              (setq *db* old-db))))

   Figure 11-4: A typical with- macro.

     (with-db db
       (eval-query q))

   Calling with-db is also safer, because it expands into an
unwind-protect instead of a simple prog1.

   The two definitions of with-db in Figure 11-4 illustrate two
possible ways to write this kind of macro.  The first is a pure macro,
the second a combination of a function and a macro.  The second
approach becomes more practical as the

      (defmacro if3 (test t-case nil-case ?-case)
            `(case ,test
                ((nil) ,nil-case)
                (?       ,?-case)
                (t       ,t-case)))

      (defmacro nif (expr pos zero neg)
            (let ((g (gensym)))
              `(let ((,g ,expr))
                  (cond ((plusp ,g) ,pos)
                           ((zerop ,g) ,zero)
                           (t ,neg)))))

   Figure 11-5: Macros for conditional evaluation.

desired with- macro grows in complexity.

   In CLTL2 Common Lisp, the dynamic-extent declaration allows the
closure containing the body to be allocated more efficiently (in CLTL1
implementations, it will be ignored).  We only need this closure for
the duration of the call to with-db-fn, and the declaration says as
much, allowing the compiler to allocate space for it on the stack.
This space will be reclaimed automatically on exit from the let
expression, instead of being reclaimed later by the garbage-collector.


File: onlisp.info,  Node: 11-3 Conditional Evaluation,  Next: 11-4 Iteration,  Prev: 11-2 The with- Macro,  Up: 11 Classic Macros

11.3 11-3 Conditional Evaluation
================================

Sometimes we want an argument in a macro call to be evaluated only
under certain conditions.  This is beyond the ability of functions,
which always evaluate all their arguments.  Built-in operators like
if, and, and cond protect some of their arguments from evaluation
unless other arguments return certain values.  For example, in this
expression

     (if t'phew
             (/ x 0))

   the third argument would cause a division-by-zero error if it were
evaluated.  But since only the first two arguments ever will be
evaluated, the if as a whole will always safely return phew.

   We can create new operators of this sort by writing macros which
expand into calls to the existing ones.  The two macros in Figure 11-5
are two of many possible variations on if.  The definition of if3
shows how we could define a conditional for a three-valued logic.
Instead of treating nil as false and everything else as true, this
macro considers three categories of truth: true, false, and uncertain,
represented as ?.  It might be used as in the following description of
a five year-old:

     (while (not sick)
       (if3 (cake-permitted)
              (eat-cake)
              (throw 'tantrum nil)
              (plead-insistently)))

   The new conditional expands into a case.  (The nil key has to be
enclosed within a list because a nil key alone would be ambiguous.)
Only one of the last three arguments will be evaluated, depending on
the value of the first.

   The name nif stands for "numeric if."  Another implementation of
this macro appeared on page 86.  It takes a numeric expression as its
first argument, and depending on its sign evaluates one of the
remaining three arguments.

     > (mapcar #'(lambda (x)
                        (nif x 'p 'z 'n))
                   '(0 1 -1))
     (ZPN)

   Figure 11-6 contains several more macros which take advantage of
conditional evaluation.  The macro in is to test efficiently for set
membership.  When you want to test whether an object is one of a set
of alternatives, you could express the query as a disjunction:

     (let ((x (foo)))
       (or (eql x (bar)) (eql x (baz))))

or you could express it in terms of set membership:

     (member (foo) (list (bar) (baz)))

   The latter is more abstract, but less efficient.  The member
expression incurs unnecessary costs from two sources.  It conses,
because it must assemble the alternatives into a list for member to
search.  And to form the alternatives into a list they all have to be
evaluated, even though some of the values may never be needed.  If the
value of (foo) is equal to the value of (bar), then there is no need
to evaluate (baz).  Whatever its conceptual advantages, this is not a
good way to use member.  We can get the same abstraction more
efficiently with a macro: in combines the abstraction of member with
the efficiency of or.  The equivalent in expression

      (defmacro in (obj &rest choices)
            (let ((insym (gensym)))
             `(let ((,insym ,obj))
                (or ,@(mapcar #'(lambda (c) `(eql ,insym ,c))
                                 choices)))))

      (defmacro inq (obj &rest args)
            `(in ,obj ,@(mapcar #'(lambda (a)
                                       `',a)
                                   args)))

      (defmacro in-if (fn &rest choices)
            (let ((fnsym (gensym)))
             `(let ((,fnsym ,fn))
                (or ,@(mapcar #'(lambda (c)
                                      `(funcall ,fnsym ,c))
                                 choices)))))

      (defmacro >case (expr &rest clauses)
            (let ((g (gensym)))
             `(let ((,g ,expr))
                (cond ,@(mapcar #'(lambda (cl) (>casex g cl))
                                    clauses)))))

      (defun >casex (g cl)
            (let ((key (car cl)) (rest (cdr cl)))
             (cond ((consp key) `((in ,g ,@key) ,@rest))
                   ((inq key t otherwise) `(t ,@rest))
                   (t (error "bad >case clause")))))

   Figure 11-6: Macros for conditional evaluation.

     (in (foo) (bar) (baz))

has the same shape as the member expression, but expands into

     (let ((#:g25 (foo)))
       (or (eql #:g25 (bar))
              (eql #:g25 (baz))))

   As is often the case, when faced with a choice between a clean
idiom and an efficient one, we go between the horns of the dilemma by
writing a macro which transforms the former into the latter.

   Pronounced "in queue," inq is a quoting variant of in,assetq used
to be of set.  The expression

     (inq operator + - *)

   expands into

     (in operator '+ '- '*)

   As member does by default, in and inq use eql to test for equality.
When you want to use some other test-or any other function of one
argument-you can use the more general in-if.  What in is to member,
in-if is to some.  The expression

     (member x (list a b) :test #'equal)

can be duplicated by

     (in-if #'(lambda (y) (equal x y)) a b)

and

     (some #'oddp (list a b))

becomes

     (in-if #'oddp a b)

   Using a combination of cond and in, we can define a useful variant
of case.  The Common Lisp case macro assumes that its keys are
constants.  Sometimes we may want the behavior of a case expression,
but with keys which are evaluated.  For such situations we define
>case, like case except that the keys guarding each clause are
evaluated before comparison.  (The > in the name is intended to
suggest the arrow notation used to represent evaluation.)  Because
>case uses in, it evaluates no more of the keys than it needs to.

   Since keys can be Lisp expressions, there is no way to tell if (x
y) is a call or a list of two keys.  To avoid ambiguity, keys (other
than t and otherwise) must always be given in a list, even if there is
only one of them.  In case expressions, nil may not appear as the car
of a clause on grounds of ambiguity.  In a >case expression, nil is no
longer ambiguous as the car of a clause, but it does mean that the
rest of the clause will never be evaluated.

   For clarity, the code that generates the expansion of each >case
clause is defined as a separate function, >casex.  Notice that >casex
itself uses inq.

      (defmacro while (test &body body)
            `(do ()
                  ((not ,test))
               ,@body))

      (defmacro till (test &body body)
            `(do ()
                  (,test)
               ,@body))

      (defmacro for ((var start stop) &body body)
            (let ((gstop (gensym)))
              `(do ((,var ,start (1+ ,var))
                       (,gstop ,stop))
                    ((> ,var ,gstop))
                  ,@body)))

   Figure 11-7: Simple iteration macros.


File: onlisp.info,  Node: 11-4 Iteration,  Next: 11-5 Iteration with Multiple Values,  Prev: 11-3 Conditional Evaluation,  Up: 11 Classic Macros

11.4 11-4 Iteration
===================

Sometimes the trouble with functions is not that their arguments are
always evaluated, but that they are evaluated only once.  Because each
argument to a function will be evaluated exactly once, if we want to
define an operator which takes some body of expressions and iterates
through them, we will have to define it as a macro.

   The simplest example would be a macro which evaluated its arguments
in sequence forever:

     (defmacro forever (&body body)
       `(do ()
                (nil)
              ,@body))

   This is just what the built-in loop macro does if you give it no
loop keywords.  It might seem that there is not much future (or too
much future) in looping forever.  But combined with block and
return-from, this kind of macro becomes the most natural way to
express loops where termination is always in the nature of an
emergency.

   Some of the simplest macros for iteration are shown in Figure 11-7.
We have already seen while (page 91), whose body will be evaluated
while a test expression returns true.  Its converse is till, which
does the same while a test expression returns false.  Finally for,
also seen before (page 129), iterates for a range of numbers.

   By defining these macros to expand into dos, we enable the use of
go and return within their bodies.  As do inherits these rights from
block and tagbody, while, till, and for inherit them from do.  As
explained on page 131, the nil tag of the implicit block around do
will be captured by the macros defined in Figure 11-7.  This is more
of a feature than a bug, but it should at least be mentioned
explicitly.

   Macros are indispensable when we need to define more powerful
iteration constructs.  Figure 11-8 contains two generalizations of
dolist; both evaluate their body with a tuple of variables bound to
successive subsequences of a list.  For example, given two parameters,
do-tuples/o will iterate by pairs:

     > (do-tuples/o (x y) '(abcd)
              (princ (list x y)))
     (A B)(B C)(C D)
     NIL

Given the same arguments, do-tuples/c will do the same thing, then
wrap around to the front of the list:

     > (do-tuples/c (x y) '(abcd)
              (princ (list x y)))
     (A B)(B C)(C D)(D A)
     NIL

   Both macros return nil, unless an explicit return occurs within the
body.

   This kind of iteration is often needed in programs which deal with
some notion of a path.  The suffixes /o and /c are intended to suggest
that the two versions traverse open and closed paths, respectively.
For example, if points is a list of points and (drawline xy) draws the
line between x and y, then to draw the path from the first point to
the last we write.

     (do-tuples/o (x y) points (drawline x y))

whereas, if points is a list of the vertices of a polygon, to draw its
perimeter we write

     (do-tuples/c (x y) points (drawline x y))

   The list of parameters given as the first argument can be any
length, and iteration will proceed by tuples of that length.  If just
one parameter is given, both

      (defmacro do-tuples/o (parms source &body body)
            (if parms
               (let ((src (gensym)))
                 `(prog ((,src ,source))
                     (mapc #'(lambda ,parms ,@body)
                             ,@(map0-n #'(lambda (n)
                                              `(nthcdr ,n ,src))
                                           (1- (length parms))))))))

      (defmacro do-tuples/c (parms source &body body)
            (if parms
               (with-gensyms (src rest bodfn)
                 (let ((len (length parms)))
                   `(let ((,src ,source))
                         (when (nthcdr ,(1- len) ,src)
                           (labels ((,bodfn ,parms ,@body))
                             (do ((,rest ,src (cdr ,rest)))
                                  ((not (nthcdr ,(1- len) ,rest))
                                   ,@(mapcar #'(lambda (args)
                                                       `(,bodfn ,@args))
                                                (dt-args len rest src))
                                   nil)
                               (,bodfn ,@(map1-n #'(lambda (n)
                                                           `(nth ,(1- n)
                                                                   ,rest))
                                                        len))))))))))

      (defun dt-args (len rest src)
            (map0-n #'(lambda (m)
                          (map1-n #'(lambda (n)
                                        (let ((x (+ m n)))
                                            (if (>= x len)
                                                `(nth ,(- x len) ,src)
                                                `(nth ,(1- x) ,rest))))
                                   len))
                   (- len 2)))

   Figure 11-8: Macros for iteration by subsequences.

      (do-tuples/c (x y z) '(a b c d)
            (princ (list x y z)))

expands into:

      (let ((#:g2 '(a b c d)))
            (when (nthcdr 2 #:g2)
              (labels ((#:g4 (x y z)
                            (princ (list x y z))))
                (do ((#:g3 #:g2 (cdr #:g3)))
                    ((not (nthcdr 2 #:g3))
                       (#:g4 (nth 0 #:g3)
                               (nth 1 #:g3)
                               (nth 0 #:g2))
                       (#:g4 (nth 1 #:g3)
                               (nth 0 #:g2)
                               (nth 1 #:g2))
                       nil)
                  (#:g4 (nth 0 #:g3)
                           (nth 1 #:g3)
                           (nth 2 #:g3))))))

   Figure 11-9: Expansion of a call to do-tuples/c.

degenerate to dolist:

     > (do-tuples/o (x) '(a b c) (princ x))
     ABC
     NIL
     > (do-tuples/c (x) '(a b c) (princ x))
     ABC
     NIL

   The definition of do-tuples/c is more complex than that of
do-tuples/o, because it has to wrap around on reaching the end of the
list.  If there are n parameters, do-tuples/c must do n-1 more
iterations before returning:

     > (do-tuples/c (x y z) '(abcd)
             (princ (list x y z)))
     (A B C)(B C D)(C D A)(D A B)
     NIL

     > (do-tuples/c (wxyz)'(abcd)
                (princ (list w x y z)))
        (A B C D)(B C D A)(C D A B)(D A B C)
        NIL

   The expansion of the former call to do-tuples/c is shown in Figure
11-9.  The hard part to generate is the sequence of calls representing
the wrap around to the front of the list.  These calls (in this case,
two of them) are generated by dt-args.


File: onlisp.info,  Node: 11-5 Iteration with Multiple Values,  Next: 11-6 Need for Macros,  Prev: 11-4 Iteration,  Up: 11 Classic Macros

11.5 11-5 Iteration with Multiple Values
========================================

The built-in do macros have been around longer than multiple return
values.  Fortunately do can evolve to suit the new situation, because
the evolution of Lisp is in the hands of the programmer.  Figure 11-10
contains a version of do* adapted for multiple values.  With mvdo*,
each of the initial clauses can bind more than one variable:

        > (mvdo* ((x 1 (1+ x))
                         ((y z) (values 0 0) (values z x)))
                       ((> x 5) (list x y z))
                (princ (list x y z)))
        (1 0 0)(2 0 2)(3 2 3)(4 3 4)(5 4 5)
        (656)

   This kind of iteration is useful, for example, in interactive
graphics programs, which often have to deal with multiple quantities
like coordinates and regions.

   Suppose that we want to write a simple interactive game, in which
the object is to avoid being squashed between two pursuing objects.
If the two pursuers both hit you at the same time, you lose; if they
crash into one another first, you win.  Figure 11-11 shows how the
main loop of this game could be written using mvdo*.

   It is also possible to write an mvdo, which binds its local
variables in parallel:

        > (mvdo ((x 1 (1+ x))
                       ((y z) (values 0 0) (values z x)))
                      ((> x 5) (list x y z))
                (princ (list x y z)))
        (1 0 0)(2 0 1)(3 1 2)(4 2 3)(5 3 4)
        (645)

   The need for psetq in defining do was described on page 96.  To
define mvdo, we need a multiple-value version of psetq.  Since Common
Lisp doesn't have one, we have to write it ourselves, as in Figure
11-12.  The new macro works as follows:

      (defmacro mvdo* (parm-cl test-cl &body body)
         (mvdo-gen parm-cl parm-cl test-cl body))

      (defun mvdo-gen (binds rebinds test body)
         (if (null binds)
                (let ((label (gensym)))
                  `(prog nil
                     ,label
                     (if ,(car test)
                          (return (progn ,@(cdr test))))
                     ,@body
                     ,@(mvdo-rebind-gen rebinds)
                     (go ,label)))
                (let ((rec (mvdo-gen (cdr binds) rebinds test body)))
                  (let ((var/s (caar binds)) (expr (cadar binds)))
                    (if (atom var/s)
                         `(let ((,var/s ,expr)) ,rec)
                         `(multiple-value-bind ,var/s ,expr ,rec))))))

      (defun mvdo-rebind-gen (rebinds)
         (cond ((null rebinds) nil)
                  ((< (length (car rebinds)) 3)
                   (mvdo-rebind-gen (cdr rebinds)))
                  (t(cons (list (if (atom (caar rebinds))
                                        'setq
                                        'multiple-value-setq)
                                   (caar rebinds)
                                   (third (car rebinds)))
                          (mvdo-rebind-gen (cdr rebinds))))))

   Figure 11-10: Multiple value binding version of do*.

     > (let ((w 0) (x 1) (y 2) (z 3))
             (mvpsetq (w x) (values 'a 'b) (y z) (values w x))
             (list wxyz))
     (AB01)

   The definition of mvpsetq relies on three utility functions: mklist
(page 45), group (page 47), and shuffle, defined here, which
interleaves two lists:

      (mvdo* (((px py) (pos player)               (move player mx my))
                   ((x1 y1) (pos obj1)            (move obj1 (- px x1)
                                                                 (- py y1)))
                   ((x2 y2) (pos obj2)            (move obj2 (- px x2)
                                                                 (- py y2)))
                   ((mx my) (mouse-vector) (mouse-vector))
                   (win       nil                 (touch obj1 obj2))
                   (lose      nil                 (and (touch obj1 player)
                                                        (touch obj2 player))))
                  ((or win lose) (if win 'win 'lose))
            (clear)
            (draw obj1)
            (draw obj2)
            (draw player))

   (pos obj) returns two values x,y representing the position of obj.
Initially, the three objects have random positions.

   (move obj dx dy) moves the object obj depending on its type and the
vector dx,dy .  Returns two values x,y indicating the new position.

   (mouse-vector) returns two values dx,dy indicating the current
movement of the mouse.

   (touch obj1 obj2) returns true if obj1 and obj2 are touching.

   (clear) clears the game region.

   (draw obj) draws obj at its current position.

   Figure 11-11: A game of squash.

     > (shuffle '(a b c) '(1 2 3 4))
     (A1B2C34)

   With mvpsetq, we can define mvdo as in Figure 11-13.  Like condlet,
this macro uses mappend instead of mapcar to avoid modifying the
original macro call.  The mappend-mklist idiom flattens a tree by one
level:

     > (mappend #'mklist '((a b c) d (e (f g) h) ((i)) j))
     (ABCDE(FG)H(I)J)

      (defmacro mvpsetq (&rest args)
         (let* ((pairs (group args 2))
                   (syms (mapcar #'(lambda (p)
                                           (mapcar #'(lambda (x) (gensym))
                                                      (mklist (car p))))
                                      pairs)))
             (labels ((rec (ps ss)
                          (if (null ps)
                               `(setq
                                   ,@(mapcan #'(lambda (p s)
                                                    (shuffle (mklist (car p))
                                                                s))
                                               pairs syms))
                               (let ((body (rec (cdr ps) (cdr ss))))
                                   (let ((var/s (caar ps))
                                          (expr (cadar ps)))
                                    (if (consp var/s)
                                          `(multiple-value-bind ,(car ss)
                                                                        ,expr
                                              ,body)
                                          `(let ((,@(car ss) ,expr))
                                              ,body)))))))
              (rec pairs syms))))

      (defun shuffle (x y)
         (cond ((null x) y)
                   ((null y) x)
                   (t (list* (car x) (car y)
                              (shuffle (cdr x) (cdr y))))))

   Figure 11-12: Multiple value version of psetq.

   To help in understanding this rather large macro, Figure 11-14
contains a sample expansion.


File: onlisp.info,  Node: 11-6 Need for Macros,  Prev: 11-5 Iteration with Multiple Values,  Up: 11 Classic Macros

11.6 11-6 Need for Macros
=========================

Macros aren't the only way to protect arguments against evaluation.
Another is to wrap them in closures.  Conditional and repeated
evaluation are similar because neither problem inherently requires
macros.  For example, we could write a version

      (defmacro mvdo (binds (test &rest result) &body body)
            (let ((label (gensym))
                 (temps (mapcar #'(lambda (b)
                                            (if (listp (car b))
                                                 (mapcar #'(lambda (x)
                                                                 (gensym))
                                                             (car b))
                                                 (gensym)))
                                       binds)))
             `(let ,(mappend #'mklist temps)
                (mvpsetq ,@(mapcan #'(lambda (b var)
                                                (list var (cadr b)))
                                           binds
                                           temps))
                (prog ,(mapcar #'(lambda (b var) (list b var))
                                    (mappend #'mklist (mapcar #'car binds))
                                    (mappend #'mklist temps))
                      ,label
                      (if ,test
                          (return (progn ,@result)))
                      ,@body
                      (mvpsetq ,@(mapcan #'(lambda (b)
                                                    (if (third b)
                                                          (list (car b)
                                                               (third b))))
                                             binds))
                      (go ,label)))))

   Figure 11-13: Multiple value binding version of do.

of if as a function:

     (defun fnif (test then &optional else)
       (if test
              (funcall then)
              (if else (funcall else))))

   We would protect the then and else arguments by expressing them as
closures, so instead of

     (if (rich) (go-sailing) (rob-bank))
      (mvdo ((x 1 (1+ x))
                  ((y z) (values 0 0) (values z x)))
                ((> x 5) (list x y z))
          (princ (list x y z)))

expands into:

      (let (#:g2 #:g3 #:g4)
          (mvpsetq #:g2 1
                        (#:g3 #:g4) (values 0 0))
          (prog ((x #:g2) (y #:g3) (z #:g4))
               #:g1
               (if (> x 5)
                     (return (progn (list x y z))))
               (princ (list x y z))
               (mvpsetq x (1+ x)
                             (y z) (values z x))
               (go #:g1)))

   Figure 11-14: Expansion of a call to mvdo.

we would say

     (fnif (rich)
              #'(lambda () (go-sailing))
              #'(lambda () (rob-bank)))

   If all we want is conditional evaluation, macros aren't absolutely
necessary.  They just make programs cleaner.  However, macros are
necessary when we want to take apart argument forms, or bind variables
passed as arguments.

   The same applies to macros for iteration.  Although macros offer
the only way to define an iteration construct which can be followed by
a body of expressions, it is possible to do iteration with functions,
so long as the body of the loop is packaged up in a function
itself.(1)  The built-in function mapc, for example, is the functional
counterpart of dolist.  The expression

     (dolist (b bananas)
        (peel b)
        (eat b))

has the same side-effects as

     (mapc #'(lambda (b)
                     (peel b)
                     (eat b))
                bananas)

(though the former returns nil and the latter returns the list
bananas).  We could likewise implement forever as a function,

     (defun forever (fn)
       (do ()
                (nil)
             (funcall fn)))

if we were willing to pass it a closure instead of a body of
expressions.

   However, iteration constructs usually want to do more than just
iterate, as forever does: they usually want to do a combination of
binding and iteration.  With a function, the prospects for binding are
limited.  If you want to bind variables to successive elements of
lists, you can use one of the mapping functions.  But if the
requirements get much more complicated than that, you'll have to write
a macro.

   ---------- Footnotes ----------

   (1) It's not impossible to write an iteration function which
doesn't need its argument wrapped up in a function.  We could write a
function that called eval on expressions passed to it as arguments.
For an explanation of why it's usually bad to call eval, see page 278.


File: onlisp.info,  Node: 12 Generalized Variables,  Next: 13 Computation at Compile-Time,  Prev: 11 Classic Macros,  Up: Top

12 12 Generalized Variables
***************************

Chapter 8 mentioned that one of the advantages of macros is their
ability to transform their arguments.  One macro of this sort is setf.
This chapter looks at the implications of setf, and then shows some
examples of macros which can be built upon it.

   Writing correct macros on setf is surprisingly difficult.  To
introduce the topic, the first section will provide a simple example
which is slightly incorrect.  The next section will explain what's
wrong with this macro, and show how to fix it.  The third and fourth
sections present examples of utilities built on setf, and the final
section explains how to define your own setf inversions.
* Menu:

* 12-1 The Concept::            
* 12-2 The Multiple Evaluation Problem::  
* 12-3 New Utilities::          
* 12-4 More Complex Utilities::  
* 12-5 Defining Inversions::    


File: onlisp.info,  Node: 12-1 The Concept,  Next: 12-2 The Multiple Evaluation Problem,  Prev: 12 Generalized Variables,  Up: 12 Generalized Variables

12.1 12-1 The Concept
=====================

The built-in macro setf is a generalization of setq.  The first
argument to setf can be a call instead of just a variable:

     > (setq lst '(a b c))
     (ABC)
     > (setf (car lst) 480)
     480
     > lst
     (480 B C)

   In general (setf xy) can be understood as saying "see to it that x
evaluates to y."  As a macro, setf can look inside its arguments to
see what needs to be done to make such a statement true.  If the first
argument (after macroexpansion) is a symbol, the setf just expands
into a setq.  But if the first argument is a query, the setf expands
into the corresponding assertion.  Since the second argument is a
constant, the preceding example could expand into:

     (progn (rplaca lst 480) 480)

   This transformation from query to assertion is called inversion.
All the most frequently used Common Lisp access functions have
predefined inversions, in- cluding car, cdr, nth, aref, get, gethash,
and the access functions created by defstruct.  (The full list is in
CLTL2, p.  125.)

   An expression which can serve as the first argument to setf is
called a generalized variable.  Generalized variables have turned out
to be a powerful abstraction.  A macro call resembles a generalized
variable in that any macro call which expands into an invertible
reference will itself be invertible.

   When we also write our own macros on top of setf, the combination
leads to noticeably cleaner programs.  One of the macros we can define
on top of setf is toggle,(1)

     (defmacro toggle (obj)                                                       ; wrong
       `(setf ,obj (not ,obj)))

which toggles the value of a generalized variable:

     > (let ((lst '(a b c)))
             (toggle (car lst))
             lst)
     (NIL B C)

   Now consider the following sample application.  Suppose someone-a
soap- opera writer, energetic busybody, or party official-wants to
maintain a database of all the relations between the inhabitants of a
small town.  Among the tables required is one which records people's
friends:

     (defvar *friends* (make-hash-table))

   The entries in this hash-table are themselves hash-tables, in which
names of potential friends are mapped to t or nil:

     (setf (gethash 'mary *friends*) (make-hash-table))

To make John the friend of Mary, we would say:

     (setf (gethash 'john (gethash 'mary *friends*)) t)

   The town is divided between two factions.  As factions are wont to
do, each says "anyone who is not with us is against us," so everyone
in town has been compelled to join one side or the other.  Thus when
someone switches sides, all his friends become enemies and all his
enemies become friends.

   To toggle whether x is the friend of y using only built-in
operators, we have to say:

     (setf (gethash x (gethash y *friends*))
                (not (gethash x (gethash y *friends*))))

   which is a rather complicated expression, though much simpler than
it would have been without setf.  If we had defined an access macro
upon the database as follows:

     (defmacro friend-of (p q)
       `(gethash ,p (gethash ,q *friends*)))

   then between this macro and toggle, we would have been better
equipped to deal with changes to the database.  The previous update
could have been expressed as simply:

     (toggle (friend-of x y))

   Generalized variables are like a health food that tastes good.
They yield programs which are virtuously modular, and yet beautifully
elegant.  If you provide access to your data structures through macros
or invertible functions, other modules can use setf to modify your
data structures without having to know the details of their
representation.

   ---------- Footnotes ----------

   (1) This definition is not correct, as the following section will
explain.


File: onlisp.info,  Node: 12-2 The Multiple Evaluation Problem,  Next: 12-3 New Utilities,  Prev: 12-1 The Concept,  Up: 12 Generalized Variables

12.2 12-2 The Multiple Evaluation Problem
=========================================

The previous section warned that our initial definition of toggle was
incorrect:

     (defmacro toggle (obj)                                                   ; wrong
       `(setf ,obj (not ,obj)))

   It is subject to the problem described in Section 10-1, multiple
evaluation.  Trouble arises when its argument has side-effects.  For
example, if lst is a list of objects, and we write:

     (toggle (nth (incf i) lst))

   then we would expect to be toggling the (i+1)th element.  However,
with the current definition of toggle this call will expand into:

     (setf (nth (incf i) lst)
                (not (nth (incf i) lst)))

   This increments i twice, and sets the (i+1)th element to the
opposite of the (i+2)th element.  So in this example

     > (let ((lst '(t nil t))
                  (i -1))
             (toggle (nth (incf i) lst))
             lst)
     (T NIL T)

the call to toggle seems to have no effect.

   It is not enough just to take the expression given as an argument
to toggle and insert it as the first argument to setf.  We have to
look inside the expression to see what it does: if it contains
subforms, we have to break them apart and evaluate them separately, in
case they have side effects.  In general, this is a complicated
business.

   To make it easier, Common Lisp provides a macro which automatically
defines a limited class of macros on setf.  This macro is called
define-modify-macro, and it takes three arguments: the name of the
macro, its additional parameters (after the generalized variable), and
the name of the function (1) which yields the new value for the
generalized variable.

   Using define-modify-macro, we could define toggle as follows:

     (define-modify-macro toggle () not)

   Paraphrased, this says "to evaluate an expression of the form
(toggle place), find the location specified by place, and if the value
stored there is val, replace it with the value of (not val)."  Here is
the new macro used in the same example:

     > (let ((lst '(t nil t))
                  (i -1))
             (toggle (nth (incf i) lst))
             lst)
     (NIL NIL T)

   This version gives the correct result, but it could be made more
general.  Since setf and setq can take an arbitrary number of
arguments, so should toggle.  We can add this capability by defining
another macro on top of the modify-macro, as in Figure 12-1.

      (defmacro allf (val &rest args)
             (with-gensyms (gval)
              `(let ((,gval ,val))
                 (setf ,@(mapcan #'(lambda (a) (list a gval))
                                       args)))))

      (defmacro nilf (&rest args) `(allf nil ,@args))

      (defmacro tf (&rest args) `(allf t ,@args))

      (defmacro toggle (&rest args)
             `(progn
               ,@(mapcar #'(lambda (a) `(toggle2 ,a))
                            args)))

      (define-modify-macro toggle2 () not)

   Figure 12-1: Macros which operate on generalized variables.

   ---------- Footnotes ----------

   (1) A function name in the general sense: either 1+ or (lambda (x)
(+ x 1)).


File: onlisp.info,  Node: 12-3 New Utilities,  Next: 12-4 More Complex Utilities,  Prev: 12-2 The Multiple Evaluation Problem,  Up: 12 Generalized Variables

12.3 12-3 New Utilities
=======================

This section gives some examples of new utilities which operate on
generalized variables.  They must be macros in order to pass their
arguments intact to setf.

   Figure 12-1 shows four new macros built upon setf.  The first,
allf, is for setting a number of generalized variables to the same
value.  Upon it are built nilf and tf, which set their arguments to
nil and t, respectively.  These macros are simple, but they make a
difference.

   Like setq, setf can take multiple arguments-alternating variables
and val- ues:

     (setf x1y2)

   So can these new utilities, but you can skip giving half the
arguments.  If you want to initialize a number of variables to nil,
instead of

     (setf x nil y nil z nil)

   you can say just

     (nilf x y z)

      (define-modify-macro concf (obj) nconc)

      (define-modify-macro conc1f (obj)
            (lambda (place obj)
               (nconc place (list obj))))

      (define-modify-macro concnew (obj &rest args)
            (lambda (place obj &rest args)
               (unless (apply #'member obj place args)
                 (nconc place (list obj)))))

   Figure 12-2: List operations on generalized variables.

   The last macro, toggle, was described in the previous section: it
is like nilf, but gives each of its arguments the opposite truth
value.

   These four macros illustrate an important point about operators for
assignment.  Even if we only intend to use an operator on ordinary
variables, it's worth writing it to expand into a setf instead of a
setq.  If the first argument is a symbol, the setf will expand into a
setq anyway.  Since we can have the generality of setf at no extra
cost, it is rarely desirable to use setq in a macroexpansion.

   Figure 12-2 contains three macros for destructively modifying the
ends of lists.  Section 3-1 mentioned that it is unsafe to rely on

     (nconc x y)

   for side-effects, and that one must write instead

     (setq x (nconc x y))

   This idiom is embodied in concf.  The more specialized conc1f and
concnew are like push and pushnew for the other end of the list:
conc1f adds one element to the end of a list, and concnew does the
same, but only if the element is not already a member.

   Section 2-2 mentioned that the name of a function can be a
lambda-expression as well as a symbol.  Thus it is fine to give a
whole lambda-expression as the third argument to define-modify-macro,
as in the definition of conc1f.  Using conc1 from page 45, this macro
could also have been written:

     (define-modify-macro conc1f (obj) conc1)

   The macros in Figure 12-2 should be used with one reservation.  If
you're planning to build a list by adding elements to the end, it may
be preferable to use push, and then nreverse the list.  It is cheaper
to do something to the front of a list than to the end, because to do
something to the end you have to get there first.  It is probably to
encourage efficient programming that Common Lisp has many operators
for the former and few for the latter.


File: onlisp.info,  Node: 12-4 More Complex Utilities,  Next: 12-5 Defining Inversions,  Prev: 12-3 New Utilities,  Up: 12 Generalized Variables

12.4 12-4 More Complex Utilities
================================

Not all macros on setf can be defined with define-modify-macro.
Suppose, for example, that we want to define a macro f for applying a
function destructively to a generalized variable.  The built-in macro
incf is an abbreviation for setf of +.  Instead of

     (setf x (+ x y))

we say just

     (incf x y)

   The new f is to be a generalization of this idea: while incf
expands into a call to +, f will expand into a call to the operator
given as the first argument.  For example, in the definition of
scale-objs on page 115, we had to write

     (setf (obj-dx o) (* (obj-dx o) factor))

   With f this will become

     (_f * (obj-dx o) factor)

   The incorrect way to write f would be:

     (defmacro _f (op place &rest args)                                        ; wrong
       `(setf ,place (,op ,place ,@args)))

   Unfortunately, we can't define a correct f with
define-modify-macro,because the operator to be applied to the
generalized variable is given as an argument.

   More complex macros like this one have to be written by hand.  To
make such macros easier to write, Common Lisp provides the function
get-setf-method, which takes a generalized variable and returns all
the information necessary to retrieve or set its value.  We will see
how to use this information by hand-generating an expansion for:

     (incf (aref a (incf i)))

   When we call get-setf-method on the generalized variable, we get
five values intended for use as ingredients in the macroexpansion:

     > (get-setf-method '(aref a (incf i)))
     (#:G4 #:G5)
     (A (INCF I))
     (#:G6)
     (SYSTEM:SET-AREF #:G6 #:G4 #:G5)
     (AREF #:G4 #:G5)

   The first two values are lists of temporary variables and the
values that should be assigned to them.  So we can begin the expansion
with:

     (let* ((#:g4 a)
                 (#:g5 (incf i)))
        ...)

   These bindings should be created in a let* because in the general
case the value forms can refer to earlier variables.  The third(1) and
fifth values are another temporary variable and the form that will
return the original value of the generalized variable.  Since we want
to add 1 to this value, we wrap the latter in a call to 1+:

     (let* ((#:g4 a)
                 (#:g5 (incf i))
                 (#:g6 (1+ (aref #:g4 #:g5))))
        ...)

   Finally, the fourth value returned by get-setf-method is the
assignment that must be made within the scope of the new bindings:

     (let* ((#:g4 a)
                 (#:g5 (incf i))
                 (#:g6 (1+ (aref #:g4 #:g5))))
        (system:set-aref #:g6 #:g4 #:g5))

   More often than not, this form will refer to internal functions
which are not part of Common Lisp.  Usually setf masks the presence of
these functions, but they have to exist somewhere.  Everything about
them is implementation-dependent, so portable code should use forms
returned by get-setf-method, rather than referring directly to
functions like system:set-aref.

   Now to implement f we write a macro which does almost exactly what
we did when expanding incf by hand.  The only difference is that,
instead of wrapping the last form in the let* in a call to 1+, we wrap
it in an expression made from the arguments to f.  The definition of f
is shown in Figure 12-3.

      (defmacro _f (op place &rest args)
        (multiple-value-bind (vars forms var set access)
                                  (get-setf-method place)
             `(let* (,@(mapcar #'list vars forms)
                    (,(car var) (,op ,access ,@args)))
               ,set)))

      (defmacro pull (obj place &rest args)
        (multiple-value-bind (vars forms var set access)
                                  (get-setf-method place)
             (let ((g (gensym)))
              `(let* ((,g ,obj)
                      ,@(mapcar #'list vars forms)
                      (,(car var) (delete ,g ,access ,@args)))
                 ,set))))

      (defmacro pull-if (test place &rest args)
        (multiple-value-bind (vars forms var set access)
                                  (get-setf-method place)
             (let ((g (gensym)))
              `(let* ((,g ,test)
                      ,@(mapcar #'list vars forms)
                      (,(car var) (delete-if ,g ,access ,@args)))
                 ,set))))

      (defmacro popn (n place)
        (multiple-value-bind (vars forms var set access)
                                  (get-setf-method place)
             (with-gensyms (gn glst)
              `(let* ((,gn ,n)
                      ,@(mapcar #'list vars forms)
                      (,glst ,access)
                      (,(car var) (nthcdr ,gn ,glst)))
                 (prog1 (subseq ,glst 0 ,gn)
                          ,set)))))

   Figure 12-3: More complex macros on setf.

   This utility is quite a useful one.  Now that we have it, for
example, we can easily replace any named function with a memoized
(Section 5-3) equivalent.(2)  To memoize foo we would say:

     (_f memoize (symbol-function 'foo))

   Having f also makes it easy to define other macros on setf.  For
example, we could now define conc1f (Figure 12-2) as:

     (defmacro conc1f (lst obj)
        `(_f nconc ,lst (list ,obj)))

   Figure 12-3 contains some other useful macros on setf.  The next,
pull, is intended as a complement to the built-in pushnew.  The pair
are like more discerning versions of push and pop; pushnew pushes a
new element onto a list if it is not already a member, and pull
destructively removes selected elements from a list.  The &rest
parameter in pull's definition makes pull able to accept all the same
keyword parameters as delete:

     > (setq x '(1 2 (a b) 3))
     (12(AB)3)
     > (pull 2 x)
     (1 (A B) 3)
     > (pull '(a b) x :test #'equal)
     (1 3)
     >x
     (1 3)

   You could almost think of this macro as if it were defined:

     (defmacro pull (obj seq &rest args)                                           ; wrong
        `(setf ,seq (delete ,obj ,seq ,@args)))

though if it really were defined that way, it would be subject to
problems with both order and number of evaluations.  We could define a
version of pull as a simple modify-macro:

     (define-modify-macro pull (obj &rest args)
        (lambda (seq obj &rest args)
             (apply #'delete obj seq args)))

   but since modify-macros must take the generalized variable as their
first argument, we would have to give the first two arguments in
reverse order, which would be less intuitive.

   The more general pull-if takes an initial function argument, and
expands into a delete-if instead of a delete:

     > (let ((lst '(1 23456)))
             (pull-if #'oddp lst)
             lst)
     (246)

   These two macros illustrate another general point.  If the
underlying function takes optional arguments, so should the macro
built upon it.  Both pull and pull-if pass optional arguments on to
their deletes.

   The final macro in Figure 12-3, popn, is a generalization of pop.
Instead of popping just one element of a list, it pops and returns a
subsequence of arbitrary length:

     > (setq x '(a b c d e f))
     (ABCDEF)
     > (popn 3 x)
     (ABC)
     >x
     (DEF)

   Figure 12-4 contains a macro which sorts its arguments.  If x and y
are variables and we want to ensure that x does not have the lower of
the two values, we can write:

     (if (> y x) (rotatef x y))

   But if we want to do this for three or more variables, the code
required grows rapidly.  Instead of writing it by hand, we can have
sortf write it for us.  This macro takes a comparison operator plus
any number of generalized variables, and swaps their values until they
are in the order dictated by the operator.  In the simplest case, the
arguments could be ordinary variables:

     > (setq x1y2z3)
     3> (sortf > x y z)
     3> (list x y z)
     (321)

      (defmacro sortf (op &rest places)
            (let* ((meths (mapcar #'(lambda (p)
                                              (multiple-value-list
                                                (get-setf-method p)))
                                         places))
                     (temps (apply #'append (mapcar #'third meths))))
               `(let* ,(mapcar #'list
                                   (mapcan #'(lambda (m)
                                                   (append (first m)
                                                             (third m)))
                                              meths)
                                   (mapcan #'(lambda (m)
                                                   (append (second m)
                                                             (list (fifth m))))
                                              meths))
                  ,@(mapcon #'(lambda (rest)
                                     (mapcar
                                       #'(lambda (arg)
                                            `(unless (,op ,(car rest) ,arg)
                                                (rotatef ,(car rest) ,arg)))
                                       (cdr rest)))
                               temps)
                  ,@(mapcar #'fourth meths))))

   Figure 12-4: A macro which sorts its arguments.

   In general, they could be any invertible expressions.  Suppose cake
is an invertible function which returns someone's piece of cake, and
bigger is a comparison function defined on pieces of cake.  If we want
to enforce the rule that the cake of moe is no less than the cake of
larry, which is no less than that of curly,we write:

     (sortf bigger (cake 'moe) (cake 'larry) (cake 'curly))

   The definition of sortf is similar in outline to that of f.  It
begins with a let* in which the temporary variables returned by
get-setf-method are bound to the initial values of the generalized
variables.  The core of sortf is the central mapcon expression, which
generates code to sort these temporary variables.  The code generated
by this portion of the macro grows exponentially with the number of
arguments.  After sorting, the generalized variables are reassigned
using the

      (sortf > x (aref ar (incf i)) (car lst))

expands (in one possible implementation) into:

      (let* ((#:g1 x)
                 (#:g4 ar)
                 (#:g3 (incf i))
                 (#:g2 (aref #:g4 #:g3))
                 (#:g6 lst)
                 (#:g5 (car #:g6)))
         (unless (> #:g1 #:g2)
             (rotatef #:g1 #:g2))
         (unless (> #:g1 #:g5)
             (rotatef #:g1 #:g5))
         (unless (> #:g2 #:g5)
             (rotatef #:g2 #:g5))
         (setq x #:g1)
         (system:set-aref #:g2 #:g4 #:g3)
         (system:set-car #:g6 #:g5))

   Figure 12-5: Expansion of a call to sortf.

   forms returned by get-setf-method.  The algorithm used is the O(n2)
bubble- sort, but this macro is not intended to be called with huge
numbers of arguments.

   Figure 12-5 shows the expansion of a call to sortf.  In the initial
let*, the arguments and their subforms are carefully evaluated in
left-to-right order.  Then appear three expressions which compare and
possibly swap the values of the temporary variables: the first is
compared to the second, then the first to the third, then the second
to the third.  Finally the the generalized variables are reassigned
left-to-right.  Although the issue rarely arises, macro arguments
should usually be assigned left-to-right, as well as being evaluated
in this order.

   Operators like f and sortf bear a certain resemblance to functions
that take functional arguments.  It should be understood that they are
something quite different.  A function like find-if takes a function
and calls it; a macro like f takes a name, and makes it the car of an
expression.  Both f and sortf could have been written to take
functional arguments.  For example, f could have been written:

     (defmacro _f (op place &rest args)
          (let ((g (gensym)))
             (multiple-value-bind (vars forms var set access)
                                        (get-setf-method place)
             `(let* ((,g ,op)
                       ,@(mapcar #'list vars forms)
                       (,(car var) (funcall ,g ,access ,@args)))
                   ,set))))

and called ( f #'+ x 1).  But the original version of f can do
anything this one could, and since it deals in names, it can also take
the name of a macro or special form.  As well as +, you could call,
for example, nif (page 150):

     > (let ((x 2))
             (_f nif x 'p 'z 'n)
             x)
     P

   ---------- Footnotes ----------

   (1) The third value is currently always a list of one element.  It
is returned as a list to provide the (so far unconsummated) potential
to store multiple values in generalized variables.

   (2) Built-in functions should not be memoized in this way, though.
Common Lisp forbids the redefinition of built-in functions.


File: onlisp.info,  Node: 12-5 Defining Inversions,  Prev: 12-4 More Complex Utilities,  Up: 12 Generalized Variables

12.5 12-5 Defining Inversions
=============================

Section 12-1 explained that any macro call which expands into an
invertible reference will itself be invertible.  You don't have to
define operators as macros just to make them invertible, though.  By
using defsetf you can tell Lisp how to invert any function or macro
call.

   This macro can be used in two ways.  In the simplest case, its
arguments are two symbols:

     (defsetf symbol-value set)

   In the more complicated form, a call to defsetf is like a call to
defmacro, with an additional parameter for the updated value form.
For example, this would define a possible inversion for car:

     (defsetf car (lst) (new-car)
          `(progn (rplaca ,lst ,new-car)
                     ,new-car))

   There is one important difference between defmacro and defsetf: the
latter automatically creates gensyms for its arguments.  With the
definition given above,

     (setf (car x) y) would expand into:
     (let* ((#:g2 x)
                   (#:g1 y))
          (progn (rplaca #:g2 #:g1)
                    #:g1))

      (defvar *cache* (make-hash-table))

      (defun retrieve (key)
         (multiple-value-bind (x y) (gethash key *cache*)
             (if y(values x y)
                 (cdr (assoc key *world*)))))

      (defsetf retrieve (key) (val)
         `(setf (gethash ,key *cache*) ,val))

   Figure 12-6: An asymmetric inversion.

   Thus we can write defsetf expanders without having to worry about
variable capture, or number or order of evaluations.

   In CLTL2 Common Lisp, it is possible to define setf inversions
directly with defun, so the previous example could also be written:

     (defun (setf car) (new-car lst)
       (rplaca lst new-car)
       new-car)

   The updated value should be the first parameter in such a function.
It is also conventional to return this value as the value of the
function.

   The examples so far have suggested that generalized variables are
supposed to refer to a place in a data structure.  The villain carries
his hostage down to the dungeon, and the rescuing hero carries her
back up again; they both follow the same path, but in different
directions.  It's not surprising if people have the impression that
setf must work this way, because all the predefined inversions seem to
be of this form; indeed, place is the conventional name for a
parameter which is to be inverted.

   In principle, setf is more general: an access form and its
inversion need not even operate on the same data structure.  Suppose
that in some application we want to cache database updates.  This
could be necessary, for example, if it were not efficient to do real
updates on the fly, or if all the updates had to be verified for
consistency before committing to them.

   Suppose that *world* is the actual database.  For simplicity, we
will make it an assoc-list whose elements are of the form (key .
val).  Figure 12-6 shows a lookup function called retrieve.If*world*
is

     ((a . 2) (b . 16) (c . 50) (d . 20) (f . 12))

then

       > (retrieve 'c)
       50

   Unlike a call to car, a call to retrieve does not refer to a
specific place in a data structure.  The return value could come from
one of two places.  And the inversion of retrieve, also defined in
Figure 12-6, only refers to one of them:

     > (setf (retrieve 'n) 77)
     77
     > (retrieve 'n)
     77
     T

   This lookup returns a second value of t, indicating that the answer
was found in the cache.

   Like macros themselves, generalized variables are an abstraction of
remarkable power.  There is probably more to be discovered here.
Certainly individual users are likely to discover ways in which the
use of generalized variables could lead to more elegant or more
powerful programs.  But it may also be possible to use setf inversion
in new ways, or to discover other classes of similarly useful
transformations.


File: onlisp.info,  Node: 13 Computation at Compile-Time,  Next: 14 Anaphoric Macros,  Prev: 12 Generalized Variables,  Up: Top

13 13 Computation at Compile-Time
*********************************

The preceding chapters described several types of operators which have
to be implemented by macros.  This one describes a class of problems
which could be solved by functions, but where macros are more
efficient.  Section 8-2 listed the pros and cons of using macros in a
given situation.  Among the pros was "computation at compile-time."
By defining an operator as a macro, you can sometimes make it do some
of its work when it is expanded.  This chapter looks at macros which
take advantage of this possibility.
* Menu:

* 13-1 New Utilities::          
* 13-2 Example Bezier Curves::  
* 13-3 Applications::           


File: onlisp.info,  Node: 13-1 New Utilities,  Next: 13-2 Example Bezier Curves,  Prev: 13 Computation at Compile-Time,  Up: 13 Computation at Compile-Time

13.1 13-1 New Utilities
=======================

Section 8-2 raised the possibility of using macros to shift
computation to compile- time.  There we had as an example the macro
avg, which returns the average of its arguments:

     > (avg pi 4 5)
     4.047...

   Figure 13-1 shows avg defined first as a function and then as a
macro.  When avg is defined as a macro, the call to length can be made
at compile-time.  In the macro version we also avoid the expense of
manipulating the &rest parameter at runtime.  In many implementations,
avg will be faster written as a macro.

   The kind of savings which comes from knowing the number of
arguments at expansion-time can be combined with the kind we get from
in (page 152), where it was possible to avoid even evaluating some of
the arguments.  Figure 13-2 contains two versions of most-of, which
returns true if most of its arguments do:

          (defun avg (&rest args)
            (/ (apply #'+ args) (length args)))

          (defmacro avg (&rest args)
            `(/ (+ ,@args) ,(length args)))

   Figure 13-1: Shifting computation when finding averages.

          (defun most-of (&rest args)
            (let ((all 0)
                  (hits 0))
             (dolist (a args)
               (incf all)
               (if a (incf hits)))
             (> hits (/ all 2))))

          (defmacro most-of (&rest args)
            (let ((need (floor (/ (length args) 2)))
                  (hits (gensym)))
             `(let ((,hits 0))
                (or ,@(mapcar #'(lambda (a)
                                        `(and ,a (> (incf ,hits) ,need)))
                                   args)))))

   Figure 13-2: Shifting and avoiding computation.

     > (most-of t t t nil)
     T

   The macro version expands into code which, like in, only evaluates
as many of the arguments as it needs to.  For example, (most-of (a)
(b) (c)) expands into the equivalent of:

     (let ((count 0))
          (or (and (a) (> (incf count) 1))
              (and (b) (> (incf count) 1))
              (and (c) (> (incf count) 1))))

   In the best case, just over half the arguments will be evaluated.

      (defun nthmost (n lst)
        (nth n (sort (copy-list lst) #'>)))

      (defmacro nthmost (n lst)
        (if (and (integerp n) (< n 20))
              (with-gensyms (glst gi)
                 (let ((syms (map0-n #'(lambda (x) (gensym)) n)))
                     `(let ((,glst ,lst))
                       (unless (< (length ,glst) ,(1+ n))
                         ,@(gen-start glst syms)
                         (dolist (,gi ,glst)
                           ,(nthmost-gen gi syms t))
                         ,(car (last syms))))))
              `(nth ,n (sort (copy-list ,lst) #'>))))

      (defun gen-start (glst syms)
        (reverse
             (maplist #'(lambda (syms)
                           (let ((var (gensym)))
                             `(let ((,var (pop ,glst)))
                                 ,(nthmost-gen var (reverse syms)))))
                       (reverse syms))))

      (defun nthmost-gen (var vars &optional long?)
        (if (null vars)
              nil
              (let ((else (nthmost-gen var (cdr vars) long?)))
                 (if (and (not long?) (null else))
                      `(setq ,(car vars) ,var)
                      `(if (> ,var ,(car vars))
                           (setq ,@(mapcan #'list
                                               (reverse vars)
                                               (cdr (reverse vars)))
                                  ,(car vars) ,var)
                           ,else)))))

   Figure 13-3: Use of arguments known at compile-time.

   A macro may also be able to shift computation to compile-time if
the values of particular arguments are known.  Figure 13-3 contains an
example of such a macro.  The function nthmost takes a number n and a
list of numbers, and returns the nth largest among them; like other
sequence functions, it is zero-indexed:

     > (nthmost 2 '(2 61534))
     4

   The function version is written very simply.  It sorts the list and
calls nth on the result.  Since sort is destructive, nthmost copies
the list before sorting it.  Written thus, nthmost is inefficient is
two respects: it conses, and it sorts the entire list of arguments,
though all we care about are the top n.

   If we know n at compile-time, we can approach the problem
differently.  The rest of the code in Figure 13-3 defines a macro
version of nthmost.  The first thing this macro does is look at its
first argument.  If the first argument is not a literal number, it
expands into the same code we saw above.  If the first argument is a
number, we can follow a different course.  If you wanted to find, say,
the third biggest cookie on a plate, you could do it by looking at
each cookie in turn, always keeping in your hand the three biggest
found so far.  When you have looked at all the cookies, the smallest
cookie in your hand is the one you are looking for.  If n is a small
constant, not proportional to the number of cookies, then this
technique gets you a given cookie with less effort that it would take
to sort all of them first.

   This is the strategy followed when n is known at expansion-time.
In its expansion, the macro creates n variables, then calls
nthmost-gen to generate the code which has to be evaluated upon
looking at each cookie.  Figure 13-4 shows a sample macroexpansion.
The macro nthmost behaves just like the original function, except that
it can't be passed as an argument to apply.  The justification for
using a macro is purely one of efficiency: the macro version does not
cons at runtime, and if n is a small constant, performs fewer
comparisons.

   To have efficient programs, must one then take the trouble to write
such huge macros?  In this case, probably not.  The two versions of
nthmost are intended as an example of a general principle: when some
arguments are known at compile- time, you can use a macro to generate
more efficient code.  Whether or not you take advantage of this
possibility will depend on how much you stand to gain, and how much
more effort it will take to write an efficient macro version.  Since
the macro version of nthmost is long and complicated, it would only be
worth writing in extreme cases.  However, information known at
compile-time is always a factor worth considering, even if you choose
not to take advantage of it.

      (nthmost 2 nums)

expands into:

      (let ((#:g7 nums))
         (unless (< (length #:g7) 3)
             (let ((#:g6 (pop #:g7)))
              (setq #:g1 #:g6))
             (let ((#:g5 (pop #:g7)))
              (if (> #:g5 #:g1)
                   (setq #:g2 #:g1 #:g1 #:g5)
                   (setq #:g2 #:g5)))
             (let ((#:g4 (pop #:g7)))
              (if (> #:g4 #:g1)
                   (setq #:g3 #:g2 #:g2 #:g1 #:g1 #:g4)
                   (if (> #:g4 #:g2)
                        (setq #:g3 #:g2 #:g2 #:g4)
                        (setq #:g3 #:g4))))
             (dolist (#:g8 #:g7)
              (if (> #:g8 #:g1)
                   (setq #:g3 #:g2 #:g2 #:g1 #:g1 #:g8)
                   (if (> #:g8 #:g2)
                        (setq #:g3 #:g2 #:g2 #:g8)
                        (if (> #:g8 #:g3)
                               (setq #:g3 #:g8)
                               nil))))
             #:g3))

   Figure 13-4: Expansion of nthmost.


File: onlisp.info,  Node: 13-2 Example Bezier Curves,  Next: 13-3 Applications,  Prev: 13-1 New Utilities,  Up: 13 Computation at Compile-Time

13.2 13-2 Example Bezier Curves
===============================

Like the with- macro (Section 11-2), the macro for computation at
compile-time is more likely to be written for a specific application
than as a general-purpose utility.  How much can a general-purpose
utility know at compile-time?  The number of arguments it has been
given, and perhaps some of their values.  If we want to use other
constraints, they will probably have to be ones imposed by individual
programs.

   As an example, this section shows how macros can speed up the
generation of Bezier curves.  Curves must be generated fast if they
are being manipulated interactively.  It turns out that if the number
of segments in the curve is known beforehand, most of the computation
can be done at compile-time.  By writing our curve-generator as a
macro, we can weave precomputed values right into code.  This should
be even faster than the more usual optimization of storing them in an
array.

   A Bezier curve is defined in terms of four points-two endpoints and
two control points.  When we are working in two dimensions, these
points define parametric equations for the x and y coordinates of
points on the curve.  If the two endpoints are (x0, y0) and (x3, y3)
and the two control points are (x1, y1) and (x2, y2), then the
equations defining points on the curve are:

               x =(x                           3                      2
                        3 - 3x2 + 3x1 - x0)u +(3x2 - 6x1 + 3x0)u +(3x1 - 3x0)u + x0

               y =(y                      3                      2
                      3 - 3y2 + 3y1 - y0)u +(3y2 - 6y1 + 3y0)u +(3y1 - 3y0)u + y0

   If we evaluate these equations for n values of u between 0 and 1,
we get n points on the curve.  For example, if we want to draw the
curve as 20 segments, then we would evaluate the equations for u =
.05, .1,..., .95.  There is no need to evaluate them for u of 0 or 1,
because if u = 0 they will yield the first endpoint (x 0, y0), and if
u = 1 they will yield the second endpoint (x3, y3).

   An obvious optimization is to make n fixed, calculate the powers of
u before- hand, and store them in an (n-1)  3 array.  By defining the
curve-generator as a macro, we can do even better.  If n is known at
expansion-time, the program could simply expand into n line-drawing
commands.  The precomputed powers of u, instead of being stored in an
array, could be inserted as literal values right into the macro
expansion.

   Figure 13-5 contains a curve-generatingmacro which implements this
strategy.  Instead of drawing lines immediately, it dumps the
generated points into an array.  When a curve is moving interactively,
each instance has to be drawn twice: once to show it, and again to
erase it before drawing the next.  In the meantime, the points have to
be saved somewhere.

   With n = 20, genbez expands into 21 setfs.  Since the powers of u
appear directly in the code, we save the cost of looking them up at
runtime, and the cost of computing them at startup.  Like the powers
of u, the array indices appear as constants in the expansion, so the
bounds-checking for the (setf aref)s could also be done at
compile-time.


File: onlisp.info,  Node: 13-3 Applications,  Prev: 13-2 Example Bezier Curves,  Up: 13 Computation at Compile-Time

13.3 13-3 Applications
======================

Later chapters contain several other macros which use information
available at compile-time.  A good example is if-match (page 242).
Pattern-matchers com- pare two sequences, possibly containing
variables, to see if there is some way of assigning values to the
variables which will make the two sequences equal.  The

      (defconstant *segs* 20)
      (defconstant *du*       (/ 1-0 *segs*))
      (defconstant *pts* (make-array (list (1+ *segs*) 2)))

      (defmacro genbez (x0 y0 x1 y1 x2 y2 x3 y3)
        (with-gensyms (gx0 gx1 gy0 gy1 gx3 gy3)
             `(let ((,gx0 ,x0) (,gy0 ,y0)
                   (,gx1 ,x1) (,gy1 ,y1)
                   (,gx3 ,x3) (,gy3 ,y3))
                (let ((cx (* (- ,gx1 ,gx0) 3))
                     (cy (* (- ,gy1 ,gy0) 3))
                     (px (* (- ,x2 ,gx1) 3))
                     (py (* (- ,y2 ,gy1) 3)))
                 (let ((bx (- px cx))
                        (by (- py cy))
                        (ax (- ,gx3 px ,gx0))
                        (ay (- ,gy3 py ,gy0)))
                   (setf (aref *pts* 0 0) ,gx0
                          (aref *pts* 0 1) ,gy0)
                   ,@(map1-n #'(lambda (n)
                                     (let* ((u (* n *du*))
                                              (u^2 (* u u))
                                              (u^3 (expt u 3)))
                                       `(setf (aref *pts* ,n 0)
                                                (+ (* ax ,u^3)
                                                     (* bx ,u^2)
                                                     (* cx ,u)
                                                     ,gx0)
                                                (aref *pts* ,n 1)
                                                (+ (* ay ,u^3)
                                                     (* by ,u^2)
                                                     (* cy ,u)
                                                     ,gy0))))
                                  (1- *segs*))
                     (setf (aref *pts* *segs* 0) ,gx3
                             (aref *pts* *segs* 1) ,gy3))))))

   Figure 13-5: Macro for generating Bezier curves.

   design of if-match shows that if one of the sequences is known at
compile-time, and only that one contains variables, then matching can
be done more efficiently.  Instead of comparing the two sequences at
runtime and consing up lists to hold the variable bindings established
in the process, we can have a macro generate code to perform the exact
comparisons dictated by the known sequence, and can store the bindings
in real Lisp variables.

   The embedded languages described in Chapters 1924 also, for the
most part, take advantage of information available at compile-time.
Since an embedded language is a compiler of sorts, it's only natural
that it should use such information.  As a general rule, the more
elaborate the macro, the more constraints it imposes on its arguments,
and the better your chances of using these constraints to generate
efficient code.


File: onlisp.info,  Node: 14 Anaphoric Macros,  Next: 15 Macros Returning Functions,  Prev: 13 Computation at Compile-Time,  Up: Top

14 14 Anaphoric Macros
**********************

Chapter 9 treated variable capture exclusively as a problem-as
something which happens inadvertently, and which can only affect
programs for the worse.  This chapter will show that variable capture
can also be used constructively.  There are some useful macros which
couldn't be written without it.

   It's not uncommon in a Lisp program to want to test whether an
expression returns a non-nil value, and if so, to do something with
the value.  If the expression is costly to evaluate, then one must
normally do something like this:

     (let ((result (big-long-calculation)))
       (if result
             (foo result)))

   Wouldn't it be easier if we could just say, as we would in English:

     (if (big-long-calculation)
          (foo it))

   By taking advantage of variable capture, we can write a version of
if which works just this way.

* Menu:

* 14-1 Anaphoric Variants::     
* 14-2 Failure::                
* 14-3 Referential Transparency::  


File: onlisp.info,  Node: 14-1 Anaphoric Variants,  Next: 14-2 Failure,  Prev: 14 Anaphoric Macros,  Up: 14 Anaphoric Macros

14.1 14-1 Anaphoric Variants
============================

In natural language, an anaphor is an expression which refers back in
the con- versation.  The most common anaphor in English is probably
"it," as in "Get the wrench and put it on the table."  Anaphora are a
great convenience in everyday language-imagine trying to get along
without them-but they don't appear much in programming languages.  For
the most part, this is good.  Anaphoric expressions are often
genuinely ambiguous, and present-day programming languages are not
designed to handle ambiguity.

   However, it is possible to introduce a very limited form of
anaphora into Lisp programs without causing ambiguity.  An anaphor, it
turns out, is a lot like a captured symbol.  We can use anaphora in
programs by designating certain symbols to serve as pronouns, and then
writing macros intentionally to capture these symbols.

   In the new version of if, the symbol it is the one we want to
capture.  The anaphoric if, called aif for short, is defined as
follows:

     (defmacro aif (test-form then-form &optional else-form)
       `(let ((it ,test-form))
              (if it ,then-form ,else-form)))

and used as in the previous example:

     (aif (big-long-calculation)
              (foo it))

   When you use an aif, the symbol it is left bound to the result
returned by the test clause.  In the macro call, it seems to be free,
but in fact the expression (foo it) will be inserted by expansion of
the aif into a context in which the symbol it is bound:

     (let ((it (big-long-calculation)))
       (if it (foo it) nil))

   So a symbol which looks free in the source code is left bound by
the macroex- pansion.  All the anaphoric macros in this chapter use
some variation of the same technique.

   Figure 14-1 contains anaphoric variants of several Common Lisp
operators.  After aif comes awhen, the obvious anaphoric variant of
when:

     (awhen (big-long-calculation)
       (foo it)
       (bar it))

   Both aif and awhen are frequently useful, but awhile is probably
unique among the anaphoric macros in being more often needed than its
regular cousin, while (defined on page 91).  Macros like while and
awhile are typically used in situations where a program needs to poll
some outside source.  And when you are polling a source, unless you
are simply waiting for it to change state, you will usually want to do
something with the object you find there:

      (defmacro aif (test-form then-form &optional else-form)
             `(let ((it ,test-form))
                  (if it ,then-form ,else-form)))

      (defmacro awhen (test-form &body body)
             `(aif ,test-form
                      (progn ,@body)))

      (defmacro awhile (expr &body body)
             `(do ((it ,expr ,expr))
                     ((not it))
                  ,@body))

      (defmacro aand (&rest args)
             (cond ((null args) t)
                      ((null (cdr args)) (car args))
                      (t `(aif ,(car args) (aand ,@(cdr args))))))

      (defmacro acond (&rest clauses)
             (if (null clauses)
                   nil
                   (let ((cl1 (car clauses))
                            (sym (gensym)))
                      `(let ((,sym ,(car cl1)))
                           (if ,sym
                                 (let ((it ,sym)) ,@(cdr cl1))
                                 (acond ,@(cdr clauses)))))))

   Figure 14-1: Anaphoric variants of Common Lisp operators.

     (awhile (poll *fridge*)
        (eat it))

   The definition of aand is a bit more complicated than the preceding
ones.  It provides an anaphoric version of and; during the evaluation
of each of its arguments, it will be bound to the value returned by
the previous argument.  (1) In practice, aand tends to be used in
programs which make conditional queries, as in:

     (aand (owner x) (address it) (town it))

which returns the town (if there is one) of the address (if there is
one) of the owner (if there is one) of x.  Without aand, this
expression would have to be written

     (let ((own (owner x)))
       (if own
                (let ((adr (address own)))
                   (if adr (town adr)))))

   The definition of aand shows that the expansion will vary depending
on the number of arguments in the macro call.  If there are no
arguments, then aand, like the regular and, should simply return t.
Otherwise the expansion is generated recursively, each step yielding
one layer in a chain of nested aifs:

     (aif  first argument
               expansion for rest of arguments )

   The expansion of an aand must terminate when there is one argument
left, instead of working its way down to nil like most recursive
functions.  If the recursion continued until no conjuncts remained,
the expansion would always be of the form:

     (aif  c1
              ...(aif  cn t)...)

   Such an expression would always return t or nil, and the example
above wouldn't work as intended.

   Section 10-4 warned that if a macro always yielded an expansion
containing a call to itself, the expansion would never terminate.
Though recursive, aand is safe because in the base case its expansion
doesn't refer to aand.

   The last example, acond, is meant for those cases where the
remainder of a cond clause wants to use the value returned by the test
expression.  (This situation arises so often that some Scheme
implementations provide a way to use the value returned by the test
expression in a cond clause.)

   In the expansion of an acond clause, the result of the test
expression will initially be kept in a gensymed variable, in order
that the symbol it may be bound only within the remainder of the
clause.  When macros create bindings, they should always do so over
the narrowest possible scope.  Here, if we dispensed with the

      (defmacro alambda (parms &body body)
            `(labels ((self ,parms ,@body))
              #'self))

      (defmacro ablock (tag &rest args)
            `(block ,tag
              ,(funcall (alambda (args)
                               (case (length args)
                                 (0 nil)
                                 (1 (car args))
                                 (t `(let ((it ,(car args)))
                                         ,(self (cdr args))))))
                            args)))

   Figure 14-2: More anaphoric variants.

gensym and instead bound it immediately to the result of the test
expression, as in:

     (defmacro acond (&rest clauses)                                            ; wrong
       (if (null clauses)
              nil
              (let ((cl1 (car clauses)))
                `(let ((it ,(car cl1)))
                     (if it
                          (progn ,@(cdr cl1))
                          (acond ,@(cdr clauses)))))))

then that binding of it would also have within its scope the following
test expres- sion.Figure 14-2contains some more
complicatedanaphoricvariants.  The macro alambda is for referring
literally to recursive functions.  When does one want to refer
literally to a recursive function?  We can refer literally to a
function by using a sharp-quoted lambda-expression:

     #'(lambda (x) (* x 2))

   But as Chapter 2 explained, you can't express a recursive function
with a simple lambda-expression.  Instead you have to define a local
function with labels.  The following function (reproduced from page
22)

     (defun count-instances (obj lists)
       (labels ((instances-in (list)
                         (if list
                              (+ (if (eq (car list) obj) 1 0)
                                    (instances-in (cdr list)))
                              0)))
             (mapcar #'instances-in lists)))

takes an object and a list, and returns a list of the number of
occurrences of the object in each element:

     > (count-instances 'a '((a b c) (darpa)(dar)(aa)))
     (1212)

   With anaphora we can make what amounts to a literal recursive
function.  The alambda macro uses labels to create one, and thus can
be used to express, for example, the factorial function:

     (alambda (x) (if (= x 0) 1 (* x (self (1- x)))))

   Using alambda we can define an equivalent version of
count-instances as follows:

     (defun count-instances (obj lists)
       (mapcar (alambda (list)
                        (if list
                             (+ (if (eq (car list) obj) 1 0)
                                  (self (cdr list)))
                             0))
                     lists))

   Unlike the other macros in Figures 14-1 and 14-2, which all capture
it, alambda captures self.  An instance of alambda expands into a
labels expression in which self is bound to the function being
defined.  As well as being smaller, alambda expressions look like
familiar lambda expressions, making code which uses them easier to
read.

   The new macro is used in the definition of ablock, an anaphoric
version of the built-in block special form.  In a block, the arguments
are evaluated left-to-right.  The same happens in an ablock, but
within each the variable it will be bound to the value of the previous
expression.

   This macro should be used with discretion.  Though convenient at
times, ablock would tend to beat what could be nice functional
programs into imperative form.  The following is, unfortunately, a
characteristically ugly example:

     > (ablock north-pole
             (princ "ho ")
             (princ it)
             (princ it)
             (return-from north-pole))
     ho ho ho
     NIL

   Whenever a macro which does intentional variable capture is
exported to another package, it is necessary also to export the symbol
being captured.  For example, wherever aif is exported, it should be
as well.  Otherwise the it which appears in the macro definition would
be a different symbol from an it used in a macro call.

   ---------- Footnotes ----------

   (1) Although one tends to think of and and or together, there would
be no point in writing an anaphoric version of or.  An argument in an
or expression is evaluated only if the previous argument evaluated to
nil, so there would be nothing useful for an anaphor to refer to in an
aor.


File: onlisp.info,  Node: 14-2 Failure,  Next: 14-3 Referential Transparency,  Prev: 14-1 Anaphoric Variants,  Up: 14 Anaphoric Macros

14.2 14-2 Failure
=================

In Common Lisp the symbol nil has at least three different jobs.  It
is first of all the empty list, so that

     > (cdr '(a))
     NIL

   As well as the empty list, nil is used to represent falsity, as in

     >(=10)
     NIL

   And finally, functions return nil to indicate failure.  For
example, the job of the built-in find-if is to return the first
element of a list which satisfies some test.  If no such element is
found, find-if returns nil:

     > (find-if #'oddp '(2 4 6))
     NIL

   Unfortunately, we can't tell this case from the one in which
find-if succeeds, but succeeds in finding nil:

     > (find-if #'null '(2 nil 6))
     NIL

   In practice, it doesn't cause too much trouble to use nil to
represent both falsity and the empty list.  In fact, it can be rather
convenient.  However, it is a pain to have nil represent failure as
well, because it means that the result returned by a function like
find-if can be ambiguous.

   The problem of distinguishing between failure and a nil return
value arises with any function which looks things up.  Common Lisp
offers no less than three solutions to the problem.  The most common
approach, before multiple return values, was to return gratuitous list
structure.  There is no trouble distinguishing failure with assoc, for
example; when successful it returns the whole pair in question:

     > (setq synonyms '((yes . t) (no . nil)))
     ((YES . T) (NO))
     > (assoc 'no synonyms)
     (NO)

   Following this approach, if we were worried about ambiguity with
find-if,we would use member-if, which instead of just returning the
element satisfying the test, returns the whole cdr which begins with
it:

     > (member-if #'null '(2 nil 6))
     (NIL 6)

   Since the advent of multiple return values, there has been another
solution to this problem: use one value for data and a second to
indicate success or failure.  The built-in gethash works this way.  It
always returns two values, the second indicating whether anything was
found:

     > (setf edible                                     (make-hash-table)
                   (gethash 'olive-oil edible) t
                   (gethash 'motor-oil edible) nil)
     NIL
     > (gethash 'motor-oil edible)
     NIL
     T

   So if you want to detect all three possible cases, you can use an
idiom like the following:

     (defun edible? (x)
          (multiple-value-bind (val found?) (gethash x edible)
             (if found?
                   (if val 'yes 'no)
                   'maybe)))

thereby distinguishing falsity from failure:

     > (mapcar #'edible? '(motor-oil olive-oil iguana))
     (NO YES MAYBE)

   Common Lisp supports yet a third way of indicating failure: to have
the access function take as an argument a special object, presumably a
gensym, to be returned in case of failure.  This approach is used with
get, which takes an optional argument saying what to return if the
specified property isn't found:

     > (get 'life 'meaning (gensym))
     #:G618

   Where multiple return values are possible, the approach used by
gethash is the cleanest.  We don't want to have to pass additional
arguments to every access function, as we do with get.  And between
the other two alternatives, using multiple values is the more general;
find-if could be written to return two values, but gethash could not,
without consing, be written to return disambiguating list structure.
Thus in writing new functions for lookup, or for other tasks where
failure is possible, it will usually be better to follow the model of
gethash.

   The idiom found in edible?  is just the sort of bookkeeping which
is well hidden by a macro.  For access functions like gethash we will
want a new version of aif which, instead of binding and testing the
same value, binds the first but also tests the second.  The new
version of aif, called aif2, is shown in Figure 14-3.  Using it we
could write edible?  as:

     (defun edible? (x)
       (aif2 (gethash x edible)
                (if it 'yes 'no)
                'maybe))

   Figure 14-3 also contains similarly altered versions of awhen,
awhile, and acond.  For an example of the use of acond2, see the
definition of match on page 239.  By using this macro we are able to
express in the form of a cond a function that would otherwise be much
longer and less symmetrical.

   The built-in read indicates failure in the same way as get.  It
takes optional arguments saying whether or not to generate an error in
case of eof, and if not, what value to return.  Figure 14-4 contains
an alternative version of read which uses a second return value to
indicate failure: read2 returns two values, the input expression and a
flag which is nil upon eof.  It calls read with a gensym to be
returned in case of eof, but to save the trouble of building the
gensym each time read2 is called, the function is defined as a closure
with a private copy of a gensym made at compile time.

   Figure 14-4 also contains a convenient macro to iterate over the
expressions in a file, written using awhile2 and read2.  Using do-file
we could, for example, write a version of load as:

     (defun our-load (filename)
       (do-file filename (eval it)))

           (defmacro aif2 (test &optional then else)
                 (let ((win (gensym)))
                    `(multiple-value-bind (it ,win) ,test
                        (if (or it ,win) ,then ,else))))

           (defmacro awhen2 (test &body body)
                 `(aif2 ,test
                             (progn ,@body)))

           (defmacro awhile2 (test &body body)
                 (let ((flag (gensym)))
                    `(let ((,flag t))
                        (while ,flag
                             (aif2 ,test
                                   (progn ,@body)
                                   (setq ,flag nil))))))

           (defmacro acond2 (&rest clauses)
                 (if (null clauses)
                      nil
                      (let ((cl1 (car clauses))
                               (val (gensym))
                               (win (gensym)))
                         `(multiple-value-bind (,val ,win) ,(car cl1)
                              (if (or ,val ,win)
                                   (let ((it ,val)) ,@(cdr cl1))
                                   (acond2 ,@(cdr clauses)))))))

   Figure 14-3: Multiple-value anaphoric macros.


File: onlisp.info,  Node: 14-3 Referential Transparency,  Prev: 14-2 Failure,  Up: 14 Anaphoric Macros

14.3 14-3 Referential Transparency
==================================

Anaphoric macros are sometimes said to violate referential
transparency, which Gelernter and Jagannathan define as follows:

     A language is referentially transparent if (a) every
     subexpression can be replaced by any other that's equal to it in
     value and (b) all occurrences of an expression within a given
     context yield the same value.

   Note that this standard applies to languages,not to programs.  No
language with assignment is referentially transparent.  The first and
the last x in this expression

      (let ((g (gensym)))
         (defun read2 (&optional (str *standard-input*))
             (let ((val (read str nil g)))
               (unless (equal val g) (values val t)))))

      (defmacro do-file (filename &body body)
         (let ((str (gensym)))
             `(with-open-file (,str ,filename)
                    (awhile2 (read2 ,str)
                     ,@body))))

   Figure 14-4: File utilities.

     (list x(setq x (not x))
              x)

yield different values, because a setq intervenes.  Admittedly, this
is ugly code.  The fact that it is even possible means that Lisp is
not referentially transparent.

   Norvig mentions that it would be convenient to redefine if as:

     (defmacro if (test then &optional else)
       `(let ((that ,test))
             (if that ,then ,else)))

but rejects this macro on the grounds that it violates referential
transparency.

   However, the problem here comes from redefining built-in operators,
not from using anaphora.  Clause (b) of the definition above requires
that an expression always return the same value "within a given
context."  It is no problem if, within this let expression,

     (let ((that 'which))
       ...)

the symbol that denotes a new variable, because let is advertised to
create a new context.

   The trouble with the macro above is that it redefines if, which is
not supposed to create a new context.  This problem goes away if we
give anaphoric macros distinct names.  (As of CLTL2, it is illegal to
redefine if anyway.)  As long as it is part of the definition of aif
that it establishes a new context in which it isanew variable, such a
macro does not violate referential transparency.

   Now, aif does violate another convention, which has nothing to do
with referential transparency: that newly established variables
somehow be indicated in the source code.  The let expression above
clearly indicates that that will refer to a new variable.  It could be
argued that the binding of it within an aif is not so clear.  However,
this is not a very strong argument: aif only creates one variable, and
the creation of that variable is the only reason to use it.

   Common Lisp itself does not treat this convention as inviolable.
The binding of the CLOS function call-next-method depends on the
context in just the same way that the binding of the symbol it does
within the body of an aif.(Fora suggestion of how call-next-method
would be implemented, see the macro defmeth on page 358.)  In any
case, such conventions are only supposed to be a means to an end:
programs which are easy to read.  And anaphora do make programs easier
to read, just as they make English easier to read.


File: onlisp.info,  Node: 15 Macros Returning Functions,  Next: 16 Macro-Defining Macros,  Prev: 14 Anaphoric Macros,  Up: Top

15 15 Macros Returning Functions
********************************

Chapter 5 showed how to write functions which return other functions.
Macros make the task of combining operators much easier.  This chapter
will show how to use macros to build abstractions which are equivalent
to those defined in Chapter 5, but cleaner and more efficient.

* Menu:

* 15-1 Building Functions::     
* 15-2 Recursion on Cdrs::      
* 15-3 Recursion on Subtrees::  
* 15-4 Lazy Evaluation::        


File: onlisp.info,  Node: 15-1 Building Functions,  Next: 15-2 Recursion on Cdrs,  Prev: 15 Macros Returning Functions,  Up: 15 Macros Returning Functions

15.1 15-1 Building Functions
============================

If f and g are functions, then f g(x)=f (g(x)).  Section 5-4 showed
how to implement the operator as a Lisp function called compose:

     > (funcall (compose #'list #'1+) 2)
     (3)

   In this section, we consider ways to define better function
builders with macros.  Figure 15-1 contains a general function-builder
called fn, which builds compound functions from their descriptions.
Its argument should be an expression of the form (operator .
arguments).  The operator can be the name of a function or macro-or
compose, which is treated specially.  The arguments can be names of
functions or macros of one argument, or expressions that could be
arguments to fn.  For example,

     (fn (and integerp oddp))

yields a function equivalent to

     #'(lambda (x) (and (integerp x) (oddp x)))

      (defmacro fn (expr) `#',(rbuild expr))

      (defun rbuild (expr)
            (if (or (atom expr) (eq (car expr) 'lambda))
                 expr
                 (if (eq (car expr) 'compose)
                      (build-compose (cdr expr))
                      (build-call (car expr) (cdr expr)))))

      (defun build-call (op fns)
            (let ((g (gensym)))
              `(lambda (,g)
                  (,op ,@(mapcar #'(lambda (f)
                                           `(,(rbuild f) ,g))
                                      fns)))))

      (defun build-compose (fns)
            (let ((g (gensym)))
              `(lambda (,g)
                  ,(labels ((rec (fns)
                                  (if fns
                                       `(,(rbuild (car fns))
                                          ,(rec (cdr fns)))
                                       g)))
                      (rec fns)))))

   Figure 15-1: General function-building macro.

   If we use compose as the operator, we get a function representing
the compo- sition of the arguments, but without the explicit funcalls
that were needed when compose was defined as a function.  For example,

     (fn (compose list 1+ truncate))

expands into:

     #'(lambda (#:g1) (list (1+ (truncate #:g1))))

   which enables inline compilation of simple functions like list and
1+.  The fn macro takes names of operators in the general sense;
lambda-expressions are allowed too, as in

     (fn (compose (lambda (x) (+ x 3)) truncate))

which expands into

     #'(lambda (#:g2) ((lambda (x) (+ x 3)) (truncate #:g2)))

   Here the function expressed as a lambda-expression will certainly
be compiled inline, whereas a sharp-quoted lambda-expression given as
an argument to the function compose would have to be funcalled.

   Section 5-4 showed how to define three more function builders: fif,
fint, and fun.  These are now subsumed in the general fn macro.  Using
and as the operator yields the intersection of the operators given as
arguments:

     > (mapcar (fn (and integerp oddp))
                  '(c 3 p 0))
     (NIL T NIL NIL)

while or yields the union:

     > (mapcar (fn (or integerp symbolp))
                  '(c 3 p 0-2))
     (T T T NIL)

and if yields a function whose body is a conditional:

     > (map1-n (fn (if oddp 1+ identity)) 6)
     (224466)

   However, we can use other Lisp functions besides these three:

     > (mapcar (fn (list 1- identity 1+))
                  '(1 2 3))
     ((012)(123)(234))

and the arguments in the fn expression may themselves be expressions:

     > (remove-if (fn (or (and integerp oddp)
                                     (and consp cdr)))
                      '(1 (a b) c (d) 2 3-4 (e f g)))
     (C (D) 2 3-4)

   Making fn treat compose as a special case does not make it any more
powerful.  If you nest the arguments to fn, you get functional
composition.  For example,

     (fn (list (1+ truncate)))

expands into:

     #'(lambda (#:g1)
              (list ((lambda (#:g2) (1+ (truncate #:g2))) #:g1)))

which behaves like

     (compose #'list #'1+ #'truncate)

   The fn macro treats compose as a special case only to make such
calls easier to read.


File: onlisp.info,  Node: 15-2 Recursion on Cdrs,  Next: 15-3 Recursion on Subtrees,  Prev: 15-1 Building Functions,  Up: 15 Macros Returning Functions

15.2 15-2 Recursion on Cdrs
===========================

Sections 5-5 and 5-6 showed how to write functions that build
recursive functions.  The following two sections show how anaphoric
macros can provide a cleaner interface to the functions we defined
there.

   Section 5-5 showed how to define a flat list recurser builder
called lrec.  With lrec we can express a call to:

     (defun our-every (fn lst)
          (if (null lst)
                t(and (funcall fn (car lst))
                      (our-every fn (cdr lst)))))

for e.g.  oddp as:

     (lrec #'(lambda (x f) (and (oddp x) (funcall f)))
                t)

   Here macros could make life easier.  How much do we really have to
say to express recursive functions?  If we can refer anaphorically to
the current car of the list (as it) and the recursive call (as rec),
we should be able to make do with something like:

     (alrec (and (oddp it) rec) t)

   Figure 15-2 contains the definition of the macro which will allow
us to say this.

     > (funcall (alrec (and (oddp it) rec) t)
                      '(1 3 5))
     T

      (defmacro alrec (rec &optional base)
         "cltl2 version"
         (let ((gfn (gensym)))
             `(lrec #'(lambda (it ,gfn)
                          (symbol-macrolet ((rec (funcall ,gfn)))
                             ,rec))
                     ,base)))

      (defmacro alrec (rec &optional base)
         "cltl1 version"
         (let ((gfn (gensym)))
             `(lrec #'(lambda (it ,gfn)
                          (labels ((rec () (funcall ,gfn)))
                             ,rec))
                     ,base)))

      (defmacro on-cdrs (rec base &rest lsts)
         `(funcall (alrec ,rec #'(lambda () ,base)) ,@lsts))

   Figure 15-2: Macros for list recursion.

   The new macro works by transforming the expression given as the
second argument into a function to be passed to lrec.  Since the
second argument may refer anaphorically to it or rec, in the macro
expansion the body of the function must appear within the scope of
bindings established for these symbols.

   Figure 15-2 actually has two different versions of alrec.  The
version used in the preceding examples requires symbol macros (Section
7-11).  Only recent versions of Common Lisp have symbol macros, so
Figure 15-2 also contains a slightly less convenient version of alrec
in which rec is defined as a local function.  The price is that, as a
function, rec would have to be enclosed within parentheses:

     (alrec (and (oddp it) (rec)) t)

   The original version is preferable in Common Lisp implementations
which provide symbol-macrolet.

   Common Lisp, with its separate name-space for functions, makes it
awkward to use these recursion builders to define named functions:

     (setf (symbol-function 'our-length)
             (alrec (1+ rec) 0))





      (defun our-copy-list (lst)
            (on-cdrs (cons it rec) nil lst))

      (defun our-remove-duplicates (lst)
            (on-cdrs (adjoin it rec) nil lst))

      (defun our-find-if (fn lst)
            (on-cdrs (if (funcall fn it) it rec) nil lst))

      (defun our-some (fn lst)
            (on-cdrs (or (funcall fn it) rec) nil lst))

   Figure 15-3: Common Lisp functions defined with on-cdrs.

   The final macro in Figure 15-2 is intended to make this more
abstract.  Using on-cdrs we could say instead:

     (defun our-length (lst)
       (on-cdrs (1+ rec) 0 lst))

     (defun our-every (fn lst)
       (on-cdrs (and (funcall fn it) rec) t lst))

   Figure 15-3 shows some existing Common Lisp functions defined with
the new macro.  Expressed with on-cdrs, these functions are reduced to
their most basic form, and we notice similarities between them which
might not otherwise have been apparent.

   Figure 15-4 contains some new utilities which can easily be defined
with on-cdrs.  The first three, unions, intersections, and differences
imple- ment set union, intersection, and complement, respectively.
Common Lisp has built-in functions for these operations, but they can
only take two lists at a time.  Thus if we want to find the union of
three lists we have to say:

     > (union '(a b) (union '(b c) '(c d)))
     (ABCD)

   The new unions behaves like union, but takes an arbitrary number of
arguments, so that we could say:

     > (unions '(a b) '(b c) '(c d))
     (DCAB)

      (defun unions (&rest sets)
         (on-cdrs (union it rec) (car sets) (cdr sets)))

      (defun intersections (&rest sets)
         (unless (some #'null sets)
              (on-cdrs (intersection it rec) (car sets) (cdr sets))))

      (defun differences (set &rest outs)
         (on-cdrs (set-difference rec it) set outs))

      (defun maxmin (args)
         (when args
              (on-cdrs (multiple-value-bind (mx mn) rec
                           (values (max mx it) (min mn it)))
                        (values (car args) (car args))
                        (cdr args))))

   Figure 15-4: New utilities defined with on-cdrs.

Like union, unions does not preserve the order of the elements in the
initial lists.

   The same relation holds between the Common Lisp intersection and
the more general intersections.  In the definition of this function,
the initial test for null arguments was added for efficiency; it
short-circuits the computation if one of the sets is empty.

   Common Lisp also has a function called set-difference, which takes
two lists and returns the elements of the first which are not in the
second:

     > (set-difference '(a b c d) '(a c))
     (D B)

   Our new version handles multiple arguments much as - does.  For
example, (differences x y z) is equivalent to (set-difference x
(unions y z)), though without the consing that the latter would
entail.

     > (differences '(a b c d e) '(a f) '(d))
     (BCE)

   These set operators are intended only as examples.  There is no
real need for them, because they represent a degenerate case of list
recursion already handled by the built-in reduce.  For example,
instead of

     (unions ...)

you might as well say just

     ((lambda (&rest args) (reduce #'union args)) ...)

   In the general case, on-cdrs is more powerful than reduce, however.

   Because rec refers to a call instead of a value, we can use on-cdrs
to create functions which return multiple values.  The final function
in Figure 15-4, maxmin, takes advantage of this possibility to find
both the maximum and minimum ele- ments in a single traversal of a
list:

     > (maxmin '(3 4 2 85167))
     81

   It would also have been possible to use on-cdrs in some of the code
which appears in later chapters.  For example, compile-cmds (page 310)

     (defun compile-cmds (cmds)
           (if (null cmds)
                'regs
                `(,@(car cmds) ,(compile-cmds (cdr cmds)))))

could have been defined as simply:

     (defun compile-cmds (cmds)
           (on-cdrs `(,@it ,rec) 'regs cmds))


File: onlisp.info,  Node: 15-3 Recursion on Subtrees,  Next: 15-4 Lazy Evaluation,  Prev: 15-2 Recursion on Cdrs,  Up: 15 Macros Returning Functions

15.3 15-3 Recursion on Subtrees
===============================

What macros did for recursion on lists, they can also do for recursion
on trees.  In this section, we use macros to define cleaner interfaces
to the tree recursers defined in Section 5-6.

   In Section 5-6 we defined two tree recursion builders,ttrav, which
always tra- verses the whole tree, and trec which is more complex, but
allows you to control when recursion stops.  Using these functions we
could express our-copy-tree

     (defun our-copy-tree (tree)
           (if (atom tree)
                tree
                (cons (our-copy-tree (car tree))
                         (if (cdr tree) (our-copy-tree (cdr tree))))))

as

     (ttrav #'cons)

and a call to rfind-if

     (defun rfind-if (fn tree)
       (if (atom tree)
             (and (funcall fn tree) tree)
             (or (rfind-if fn (car tree))
                  (and (cdr tree) (rfind-if fn (cdr tree))))))

for e.g.  oddp as:

     (trec #'(lambda (o l r) (or (funcall l) (funcall r)))
             #'(lambda (tree) (and (oddp tree) tree)))

   Anaphoric macros can make a better interface to trec, as they did
for lrec in the previous section.  A macro sufficient for the general
case will have to be able to refer anaphorically to three things: the
current tree, which we'll call it, the recursion down the left
subtree, which we'll call left, and the recursion down the right
subtree, which we'll call right.  With these conventions established,
we should be able to express the preceding functions in terms of a new
macro thus:

     (atrec (cons left right))

     (atrec (or left right) (and (oddp it) it))

   Figure 15-5 contains the definition of this macro.

   In versions of Lisp which don't have symbol-macrolet,we can define
atrec using the second definition in Figure 15-5.  This version
defines left and right as local functions, so our-copy-tree would have
to be expressed as:

     (atrec (cons (left) (right)))

   For convenience, we also define a macro on-trees, which is
analogous to on-cdrs from the previous section.  Figure 15-6 shows the
four functions from Section 5-6 defined with on-trees.

   As noted in Chapter 5, functions built by the recurser generators
defined in that chapter will not be tail-recursive.  Using on-cdrs or
on-trees to define a function will not necessarily yield the most
efficient implementation.  Like the underlying trec and lrec, these
macros are mainly for use in prototypes and in parts of a program
where efficiency is not paramount.  However, the underlying idea of
this chapter and Chapter 5 is that one can write function generators
and put a clean macro interface on them.  This same technique could
equally well be used to build function generators which yielded
particularly efficient code.

      (defmacro atrec (rec &optional (base 'it))
            "cltl2 version"
            (let ((lfn (gensym)) (rfn (gensym)))
             `(trec #'(lambda (it ,lfn ,rfn)
                         (symbol-macrolet ((left (funcall ,lfn))
                                                 (right (funcall ,rfn)))
                            ,rec))
                    #'(lambda (it) ,base))))

      (defmacro atrec (rec &optional (base 'it))
            "cltl1 version"
            (let ((lfn (gensym)) (rfn (gensym)))
             `(trec #'(lambda (it ,lfn ,rfn)
                         (labels ((left () (funcall ,lfn))
                                      (right () (funcall ,rfn)))
                            ,rec))
                    #'(lambda (it) ,base))))

      (defmacro on-trees (rec base &rest trees)
            `(funcall (atrec ,rec ,base) ,@trees))

   Figure 15-5: Macros for recursion on trees.

      (defun our-copy-tree (tree)
            (on-trees (cons left right) it tree))

      (defun count-leaves (tree)
            (on-trees (+ left (or right 1)) 1 tree))

      (defun flatten (tree)
            (on-trees (nconc left right) (mklist it) tree))

      (defun rfind-if (fn tree)
            (on-trees (or left right)
                     (and (funcall fn it) it)
                     tree))

   Figure 15-6: Functions defined using on-trees.

      (defconstant unforced (gensym))

      (defstruct delay forced closure)

      (defmacro delay (expr)
         (let ((self (gensym)))
              `(let ((,self (make-delay :forced unforced)))
                 (setf (delay-closure ,self)
                          #'(lambda ()
                               (setf (delay-forced ,self) ,expr)))
                 ,self)))

      (defun force (x)
         (if (delay-p x)
                (if (eq (delay-forced x) unforced)
                       (funcall (delay-closure x))
                       (delay-forced x))
                x))

   Figure 15-7: Implementation of force and delay.


File: onlisp.info,  Node: 15-4 Lazy Evaluation,  Prev: 15-3 Recursion on Subtrees,  Up: 15 Macros Returning Functions

15.4 15-4 Lazy Evaluation
=========================

Lazy evaluation means only evaluating an expression when you need its
value.  One way to use lazy evaluation is to build an object known as
a delay.  A delay is a placeholder for the value of some expression.
It represents a promise to deliver the value of the expression if it
is needed at some later time.  Meanwhile, since the promise is a Lisp
object, it can serve many of the purposes of the value it represents.
And when the value of the expression is needed, the delay can return
it.  Scheme has built-in support for delays.  The Scheme operators
force and delay can be implemented in Common Lisp as in Figure 15-7.
A delay is represented as a two-part structure.  The first field
indicates whether the delay has been evaluated yet, and if it has,
contains the value.  The second field contains a closure which can be
called to find the value that the delay represents.  The macro delay
takes an expression, and returns a delay representing its value:

     > (let ((x 2))
             (setq d (delay (1+ x))))
     #S(DELAY ...)

   To call the closure within a delay is to force the delay.  The
function force takes any object: for ordinary objects it is the
identity function, but for delays it is a demand for the value that
the delay represents.

     > (force 'a)
     A> (force d)
     3

   We use force whenever we are dealing with objects that might be
delays.  For example, if we are sorting a list which might contain
delays, we would say:

     (sort lst #'(lambda (x y) (> (force x) (force y))))

   It's slightly inconvenient to use delays in this naked form.  In a
real application, they might be hidden beneath another layer of
abstraction.


File: onlisp.info,  Node: 16 Macro-Defining Macros,  Next: 17 Read-Macros,  Prev: 15 Macros Returning Functions,  Up: Top

16 16 Macro-Defining Macros
***************************

Patterns in code often signal the need for new abstractions.  This
rule holds just as much for the code in macros themselves.  When
several macros have definitions of a similar form, we may be able to
write a macro-defining macro to produce them.  This chapter presents
three examples of macro-defining macros: one to define abbreviations,
one to define access macros, and a third to define anaphoric macros of
the type described in Section 14-1.

* Menu:

* 16-1 Abbreviations::          
* 16-2 Properties::             
* Anaphoric Macros::            


File: onlisp.info,  Node: 16-1 Abbreviations,  Next: 16-2 Properties,  Prev: 16 Macro-Defining Macros,  Up: 16 Macro-Defining Macros

16.1 16-1 Abbreviations
=======================

The simplest use of macros is as abbreviations.  Some Common Lisp
operators have rather long names.  Ranking high among them (though by
no means the longest) is destructuring-bind, which has 18 characters.
A corollary of Steele's principle (page 43) is that commonly used
operators ought to have short names.  ("We think of addition as cheap
partly because we can notate it with a single character: '+'.")  The
built-in destructuring-bind macro introduces a new layer of
abstraction, but the actual gain in brevity is masked by its long
name:

     (let ((a (car x)) (b (cdr x))) ...)

     (destructuring-bind (a . b) x ...)

   A program, like printed text, is easiest to read when it contains
no more than about 70 characters per line.  We begin at a disadvantage
when the lengths of individual names are a quarter of that.

      (defmacro abbrev (short long)
            `(defmacro ,short (&rest args)
                `(,',long ,@args)))

      (defmacro abbrevs (&rest names)
            `(progn
                ,@(mapcar #'(lambda (pair)
                                    `(abbrev ,@pair))
                              (group names 2))))

   Figure 16-1: Automatic definition of abbreviations.

   Fortunately, in a language like Lisp you don't have to live with
all the decisions of the designers.  Having defined

     (defmacro dbind (&rest args)
       `(destructuring-bind ,@args))

you need never use the long name again.  Likewise for
multiple-value-bind, which is longer and more frequently used.

     (defmacro mvbind (&rest args)
       `(multiple-value-bind ,@args))

   Notice how nearly identical are the definitions of dbind and
mvbind.  Indeed, this formula of &rest and comma-at will suffice to
define an abbreviation for any function,(1) macro, or special form.
Why crank out more definitions on the model of mvbind when we could
have a macro do it for us?

   To define a macro-defining macro we will often need nested
backquotes.  Nested backquotes are notoriously hard to understand.
Eventually common cases will become familiar, but one should not
expect to be able to look at an arbitrary backquoted expression and
say what it will yield.  It is not a fault in Lisp that this is so,
any more than it is a fault of the notation that one can't just look
at a complicated integral and know what its value will be.  The
difficulty is in the problem, not the notation.

   However, as we do when finding integrals, we can break up the
analysis of backquotes into small steps, each of which can easily be
followed.  Suppose we want to write a macro abbrev, which will allow
us to define mvbind just by saying

     (abbrev mvbind multiple-value-bind)

   Figure 16-1 contains a definition of this macro.  Where did it come
from?  The definition of such a macro can be derived from a sample
expansion.  One expansion is:

     (defmacro mvbind (&rest args)
            `(multiple-value-bind ,@args))

   The derivation will be easier if we pull multiple-value-bind from
within the backquote, because we know it will be an argument to the
eventual macro.  This yields the equivalent definition

     (defmacro mvbind (&rest args)
            (let ((name 'multiple-value-bind))
             `(,name ,@args)))

   Now we take this expression and turn it into a template.  We affix
a backquote, and replace the expressions which will vary, with
variables.

     `(defmacro ,short (&rest args)
             (let ((name ',long))
              `(,name ,@args)))

   The final step is to simplify this expression by substituting
',long for name within the inner backquote:

     `(defmacro ,short (&rest args)
             `(,',long ,@args))

   which yields the body of the macro defined in Figure 16-1.

   Figure 16-1 also contains abbrevs, for cases where we want to
define several abbreviations in one shot.

     (abbrevs dbind destructuring-bind
                   mvbind multiple-value-bind
                   mvsetq multiple-value-setq)

   The user of abbrevs doesn't have to insert additional parentheses
because abbrevs calls group (page 47) to group its arguments by twos.
It's gener- ally a good thing for macros to save users from typing
logically unnecessary parentheses, and group will be useful to most
such macros.

      (defmacro propmacro (propname)
            `(defmacro ,propname (obj)
                `(get ,obj ',',propname)))

      (defmacro propmacros (&rest props)
            `(progn
                ,@(mapcar #'(lambda (p) `(propmacro ,p))
                              props)))

   Figure 16-2: Automatic definition of access macros.

   ---------- Footnotes ----------

   (1) Though the abbreviation can't be passed to apply or funcall.


File: onlisp.info,  Node: 16-2 Properties,  Next: Anaphoric Macros,  Prev: 16-1 Abbreviations,  Up: 16 Macro-Defining Macros

16.2 16-2 Properties
====================

Lisp offers many ways to associate properties with objects.  If the
object in question can be represented as a symbol, one of the most
convenient (though least efficient) ways is to use the symbol's
property list.  To describe the fact that an object o has a property
p, the value of which is v, we modify the property list of o:

     (setf (get op) v)

   So to say that ball1 has color red, we say:

     (setf (get 'ball1 'color) 'red)

   If we're going to refer often to some property of objects, we can
define a macro to retrieve it:

     (defmacro color (obj)
        `(get ,obj 'color))

   and thereafter use color in place of get:

     > (color 'ball1)
     RED

   Since macro calls are transparent to setf (see Chapter 12) we can
also say:

     > (setf (color 'ball1) 'green)
     GREEN

   Such macros have the advantage of hiding the particular way in
which the program represents the color of an object.  Property lists
are slow; a later version of the program might, for the sake of speed,
represent color as a field in a structure, or an entry in a
hash-table.  When data is reached through a facade of macros like
color, it becomes easy, even in a comparatively mature program, to
make pervasive changes to the lowest-level code.  If a program
switches from using property lists to structures, nothing above the
facade of access macros will have to be changed; none of the code
which looks upon the facade need even be aware of the rebuilding going
on behind it.

   For the weight property, we can define a macro similar to the one
written for color:

     (defmacro weight (obj)
       `(get ,obj 'weight))

   Like the abbreviations in the previous section, the definitions of
of color and weight are nearly identical.  Here propmacro (Figure
16-2) can play the same role as abbrev did.

   A macro-defining macro can be designed by the same process as any
other macro: look at the macro call, then its intended expansion, then
figure out how to transform the former into the latter.  We want

     (propmacro color)

   to expand into

     (defmacro color (obj)
       `(get ,obj 'color))

   Though this expression is itself a defmacro, we can still make a
template of it, by backquoting it and putting comma'd parameter names
in place of instances of color.  As in the previous section, we begin
by transforming it so that no instances of color are within existing
backquotes:

     (defmacro color (obj)
       (let ((p 'color))
             `(get ,obj ',p)))

   Then we go ahead and make the template,

     `(defmacro ,propname (obj)
         (let ((p ',propname))
               `(get ,obj ',p)))

   which simplifies to

     `(defmacro ,propname (obj)
            `(get ,obj ',',propname))

   For cases where a group of property-names all have to be defined as
macros, there is propmacros (Figure 16-2), which expands into a series
of individual calls to propmacro.  Like abbrevs, this modest piece of
code is actually a macro-defining-macro-defining macro.

   Though this section dealt with property lists, the technique
described here is a general one.  We could use it to define access
macros on data stored in any form.


File: onlisp.info,  Node: Anaphoric Macros,  Prev: 16-2 Properties,  Up: 16 Macro-Defining Macros

16.3 16-3 Anaphoric Macros
==========================

Section 14-1 gave definitions of several anaphoric macros.  When you
use a macro like aif or aand, during the evaluation of some arguments
the symbol it will be bound to the values returned by other ones.  So
instead of

     (let ((res (complicated-query)))
       (if res
                (foo res)))

you can use just

     (aif (complicated-query)
              (foo it))

and instead of

     (let ((o (owner x)))
       (and o (let ((a (address o)))
                       (and a (city a)))))

simply

     (aand (owner x) (address it) (city it))

   Section 14-1 presented seven anaphoric macros: aif, awhen, awhile,
acond, alambda, ablock, and aand.  These seven are by no means the
only useful anaphoric macros of their type.  In fact, we can define an
anaphoric variant of just about any Common Lisp function or macro.
Many of these macros will be like mapcon: rarely used, but
indispensable when they are needed.

   For example, we can define a+ so that, as with aand, it is always
bound to the value returned by the previous argument.  The following
function calculates the cost of dining out in Massachusetts:

      (defmacro a+ (&rest args)
         (a+expand args nil))

      (defun a+expand (args syms)
         (if args
              (let ((sym (gensym)))
                 `(let* ((,sym ,(car args))
                              (it ,sym))
                     ,(a+expand (cdr args)
                                      (append syms (list sym)))))
              `(+ ,@syms)))

      (defmacro alist (&rest args)
         (alist-expand args nil))

      (defun alist-expand (args syms)
         (if args
              (let ((sym (gensym)))
                 `(let* ((,sym ,(car args))
                              (it ,sym))
                     ,(alist-expand (cdr args)
                                      (append syms (list sym)))))
              `(list ,@syms)))

   Figure 16-3: Definitions of a+ and alist.

     (defun mass-cost (menu-price)
       (a+ menu-price (* it .05) (* it 3)))

   The Massachusetts Meals Tax is 5%, and residents often calculate
the tip by tripling the tax.  By this formula, the total cost of the
broiled scrod at Dolphin Seafood is therefore:

     > (mass-cost 7-95)
     9-54

   but this includes salad and a baked potato.

   The macro a+,defined in Figure 16-3,relies on a recursive
function,a+expand, to generate its expansion.  The general strategy of
a+expand is to cdr down the list of arguments in the macro call,
generating a series of nested let expressions; each let leaves it
bound to a different argument, but also binds a distinct gensym

      (defmacro defanaph (name &optional calls)
             (let ((calls (or calls (pop-symbol name))))
              `(defmacro ,name (&rest args)
                  (anaphex args (list ',calls)))))

      (defun anaphex (args expr)
            (if args
                 (let ((sym (gensym)))
                    `(let* ((,sym ,(car args))
                              (it ,sym))
                        ,(anaphex (cdr args)
                                     (append expr (list sym)))))
                 expr))

      (defun pop-symbol (sym)
            (intern (subseq (symbol-name sym) 1)))

   Figure 16-4: Automatic definition of anaphoric macros.

   to each argument.  The expansion function accumulates a list of
these gensyms, and when it reaches the end of the list of arguments it
returns a + expression with the gensyms as the arguments.  So the
expression

     (a+ menu-price (* it .05) (* it 3))

   yields the macroexpansion:

     (let* ((#:g2 menu-price) (it #:g2))
       (let* ((#:g3 (* it 0-05)) (it #:g3))
             (let* ((#:g4 (* it 3)) (it #:g4))
                (+ #:g2 #:g3 #:g4))))

   Figure 16-3 also contains the definition of the analogous alist:

     > (alist 1 (+ 2 it) (+ 2 it))
     (135)

   Once again, the definitions of a+ and alist are almost identical.
If we want to define more macros like them, these too will be mostly
duplicate code.  Why not have a program produce it for us?  The macro
defanaph in Figure 16-4 will do so.  With defanaph, defining a+ and
alist is as simple as

     (defanaph a+)
     (defanaph alist)

   The expansions of a+ and alist so defined will be identical to the
expansions made by the code in Figure 16-3.  The macro-defining macro
defanaph will create an anaphoric variant of anything whose arguments
are evaluated according to the normal evaluation rule for functions.
That is, defanaph will work for anything whose arguments are all
evaluated, and evaluated left-to-right.  So you couldn't use this
version of defanaph to define aif or awhile, but you can use it to
define an anaphoric variant of any function.

   As a+ called a+expand to generate its expansion, defanaph defines a
macro which will call anaphex to do so.  The generic expander anaphex
differs from a+expand only in taking as an argument the function name
to appear finally in the expansion.  In fact, a+ could now be defined:

     (defmacro a+ (&rest args)
       (anaphex args '(+)))

   Neither anaphex nor a+expand need have been defined as distinct
functions: anaphex could have been defined with labels or alambda
within defanaph.  The expansion generators are here broken out as
separate functions only for the sake of clarity.

   By default, defanaph determines what to call in the expansion by
pulling the first letter (presumably an a) from the front of its
argument.  (This operation is performed by pop-symbol.)  If the user
prefers to specify an alternate name, it can be given as an optional
argument.  Although defanaph can build anaphoric variants of all
functions and some macros, it imposes some irksome restrictions:

  1. It only works for operators whose arguments are all evaluated.
  2. In the macroexpansion, it is always bound to successive
     arguments.  In some cases-awhen, for example-we want it to stay
     bound to the value of the first argument.
  3. It won't work for a macro like setf, which expects a generalized
     variable as its first argument.

   Let's consider how to remove some of these restrictions.  Part of
the first problem can be solved by solving the second.  To generate
expansions for a macro like aif, we need a modified version of anaphex
which only replaces the first argument in the macro call:

     (defun anaphex2 (op args)
       `(let ((it ,(car args)))
             (,op it ,@(cdr args))))

   This nonrecursive version of anaphex doesn't need to ensure that
the macroex- pansion will bind it to successive arguments, so it can
generate an expansion which won't necessarily evaluate all the
arguments in the macro call.  Only the first argument must be
evaluated, in order to bind it to its value.  So aif could be defined
as:

     (defmacro aif (&rest args)
            (anaphex2 'if args))

   This definition would differ from the original on page 191 only in
the point where it would complain if aif were given the wrong number
of arguments; for correct macro calls, the two generate identical
expansions.

   The third problem, that defanaph won't work with generalized
variables, can be solved by using f (page 173) in the expansion.
Operators like setf can be handled by a variant of anaphex2 defined as
follows:

     (defun anaphex3 (op args)
            `(_f (lambda (it) (,op it ,@(cdr args))) ,(car args)))

   This expander assumes that the macro call will have one or more
arguments, the first of which will be a generalized variable.  Using
it we could define asetf thus:

     (defmacro asetf (&rest args)
            (anaphex3 'setf args))

   Figure 16-5 shows all three expander functions yoked together under
the control of a single macro, the new defanaph.  The user signals the
type of macro expansion desired with the optional rule keyword
parameter, which specifies the evaluation rule to be used for the
arguments in the macro call.  If this parameter is:

   :all (the default) the macroexpansion will be on the model of
alist.  All the arguments in the macro call will be evaluated, with it
always bound to the value of the previous argument.

   :first the macroexpansion will be on the model of aif.  Only the
first argument will necessarily be evaluated, and it will be bound to
its value.

   :place the macroexpansion will be on the model of asetf.  The first
argument will be treated as a generalized variable, and it will be
bound to its initial value.

   Using the new defanaph, some of the previous examples would be
defined as follows:

      (defmacro defanaph (name &optional &key calls (rule :all))
         (let* ((opname (or calls (pop-symbol name)))
                  (body (case rule
                             (:all       `(anaphex1 args '(,opname)))
                             (:first `(anaphex2 ',opname args))
                             (:place `(anaphex3 ',opname args)))))
             `(defmacro ,name (&rest args)
                ,body)))

      (defun anaphex1 (args call)
         (if args
              (let ((sym (gensym)))
                 `(let* ((,sym ,(car args))
                            (it ,sym))
                     ,(anaphex1 (cdr args)
                                      (append call (list sym)))))
              call))

      (defun anaphex2 (op args)
         `(let ((it ,(car args))) (,op it ,@(cdr args))))

      (defun anaphex3 (op args)
         `(_f (lambda (it) (,op it ,@(cdr args))) ,(car args)))

   Figure 16-5: More general defanaph.

     (defanaph alist)
     (defanaph aif :rule :first)
     (defanaph asetf :rule :place)

   One of the advantages of asetf is that it makes it possible to
define a large class of macros on generalized variables without
worrying about multiple evaluation.  For example, we could define incf
as:

     (defmacro incf (place &optional (val 1))
       `(asetf ,place (+ it ,val)))

and, say, pull (page 173) as:

     (defmacro pull (obj place &rest args)
       `(asetf ,place (delete ,obj it ,@args)))


File: onlisp.info,  Node: 17 Read-Macros,  Next: 18 Destructuring,  Prev: 16 Macro-Defining Macros,  Up: Top

17 17 Read-Macros
*****************

The three big moments in a Lisp expression's life are read-time,
compile-time, and runtime.  Functions are in control at runtime.
Macros give us a chance to perform transformations on programs at
compile-time.  This chapter discusses read-macros, which do their work
at read-time.

* Menu:

* 17-1 Macro Characters::       
* 17-2 Dispatching Macro Characters::  
* 17-3 Delimiters::             
* 17-4 When What Happens::      


File: onlisp.info,  Node: 17-1 Macro Characters,  Next: 17-2 Dispatching Macro Characters,  Prev: 17 Read-Macros,  Up: 17 Read-Macros

17.1 17-1 Macro Characters
==========================

In keeping with the general philosophy of Lisp, you have a great deal
of control over the reader.  Its behavior is controlled by properties
and variables that can all be changed on the fly.  The reader can be
programmed at several levels.  The easiest way to change its behavior
is by defining new macro characters.

   A macro character is a character which exacts special treatment
from the Lisp reader.  A lower-case a, for example, is ordinarily
handled just like a lower-case b, but a left parenthesis is something
different: it tells Lisp to begin reading a list.  Each such character
has a function associated with it that tells the Lisp reader what to
do when the character is encountered.  You can change the function
associated with an existing macro character, or define new macro
characters of your own.

   The built-in function set-macro-character provides one way to
define read-macros.  It takes a character and a function, and
thereafter when read encounters the character, it returns the result
of calling the function.

   One of the oldest read-macros in Lisp is ', the quote.  You could
do without ' by always writing (quote a) instead of 'a, but this would
be tiresome and would make your code harder to read.  The quote
read-macro makes it possible to use 'a as an abbreviation for (quote
a).  We could define it as in Figure 17-1.

      (set-macro-character #\'
            #'(lambda (stream char)
                (list 'quote (read stream t nil t))))

   Figure 17-1: Possible definition of '.

   When read encounters an instance of ' in a normal context (e.g.
not in "a'b" or |a'b|), it will return the result of calling this
function on the current stream and character.  (The function ignores
this second parameter, which will always be the quote character.)  So
when read sees 'a, it will return (quote a).

   The last three arguments to read control respectively whether
encountering an end-of-file should cause an error, what value to
return otherwise, and whether the call to read occurs within a call to
read.  In nearly all read-macros, the second and fourth arguments
should be t, and the third argument is therefore irrelevant.

   Read-macros and ordinary macros are both functions underneath.  And
like the functions that generate macro expansions, the functions
associated with macro characters shouldn't have side-effects, except
on the stream from which they read.  Common Lisp explicitly makes no
guarantees about when, or how often, the function associated with a
read-macro will be called.  (See CLTL2, p.  543.)

   Macros and read-macros see your program at different stages.
Macros get hold of the program when it has already been parsed into
Lisp objects by the reader, and read-macros operate on a program while
it is still text.  However, by invoking read on this text, a
read-macro can, if it chooses, get parsed Lisp objects as well.  Thus
read-macros are at least as powerful as ordinary macros.

   Indeed, read-macros are more powerful in at least two ways.  A
read-macro affects everything read by Lisp, while a macro will only be
expanded in code.  And since read-macros generally call read
recursively, an expression like

     ''a

becomes

     (quote (quote a))

whereas if we had tried to define an abbreviation for quote using a
normal macro,

     (defmacro q (obj)
       `(quote ,obj))
          (set-dispatch-macro-character #\# #\?
            #'(lambda (stream char1 char2)
                 `#'(lambda (&rest ,(gensym))
                       ,(read stream t nil t))))

   Figure 17-2: A read-macro for constant functions.

it would work in isolation,

     > (eq 'a (q a))
     T

but not when nested.  For example,

     (q (q a))

would expand into

     (quote (q a))


File: onlisp.info,  Node: 17-2 Dispatching Macro Characters,  Next: 17-3 Delimiters,  Prev: 17-1 Macro Characters,  Up: 17 Read-Macros

17.2 17-2 Dispatching Macro Characters
======================================

The sharp-quote, like other read-macros beginning with #, is an
example of a subspecies called dispatching read-macros.  These appear
as two characters, the first of which is called the dispatching
character.  The purpose of such read-macros is simply to make the most
of the ASCII character set; one can only have so many one-character
read-macros.

   You can (with make-dispatch-macro-character) define your own dis-
patching macro characters, but since # is already defined as one, you
may as well use it.  Some combinations beginning with # are explicitly
reserved for your use; others are available in that they do not yet
have a predefined meaning in Common Lisp.  The complete list appears
in CLTL2, p.  531.

   New dispatching macro character combinations can be defined by
calling the function set-dispatch-macro-character, like
set-macro-character except that it takes two character arguments.  One
of the combinations reserved to the programmer is #?.  Figure 17-2
shows how to define this combination as a read-macro for constant
functions.  Now #?2 will be read as a function which takes any number
of arguments and returns 2.  For example:

     > (mapcar #?2 '(a b c))
     (222)

          (set-macro-character #\] (get-macro-character #\)))

          (set-dispatch-macro-character #\# #\[
           #'(lambda (stream char1 char2)
                (let ((accum nil)
                        (pair (read-delimited-list #\] stream t)))
                   (do ((i (ceiling (car pair)) (1+ i)))
                        ((> i (floor (cadr pair)))
                          (list 'quote (nreverse accum)))
                      (push i accum)))))

   Figure 17-3: A read-macro defining delimiters.

   This example makes the new operator look rather pointless, but in
programs that use a lot of functional arguments, constant functions
are often needed.  In fact, some dialects provide a built-in function
called always for defining them.

   Note that it is perfectly ok to use macro characters in the
definition of this macro character: as with any Lisp expression, they
disappear when the definition is read.  It is also fine to use
macro-characters after the #?.  The definition of #?  calls read, so
macro-characters like ' and #' behave as usual:

     > (eq (funcall #?'a) 'a)
     T> (eq (funcall #?#'oddp) (symbol-function 'oddp))
     T


File: onlisp.info,  Node: 17-3 Delimiters,  Next: 17-4 When What Happens,  Prev: 17-2 Dispatching Macro Characters,  Up: 17 Read-Macros

17.3 17-3 Delimiters
====================

After simple macro characters, the most commonly defined macro
characters are list delimiters.  Another character combination
reserved for the user is #[.  Figure 17-3 gives an example of how this
character might be defined as a more elaborate kind of left
parenthesis.  It defines an expression of the form #[x y] to read as a
list of all the integers between x and y, inclusive:

     > #[2 7]
     (234567)

   The only new thing about this read-macro is the call to
read-delimited-list, a built-in function provided just for such cases.
Its first argument is the character to treat as the end of the list.
For ] to be recognized as a delimiter, it must first be given this
role, hence the preliminary call to set-macro-character.

          (defmacro defdelim (left right parms &body body)
            `(ddfn ,left ,right #'(lambda ,parms ,@body)))

          (let ((rpar (get-macro-character #\) )))
            (defun ddfn (left right fn)
              (set-macro-character right rpar)
              (set-dispatch-macro-character #\# left
                 #'(lambda (stream char1 char2)
                      (apply fn
                               (read-delimited-list right stream t))))))

   Figure 17-4: A macro for defining delimiter read-macros.

   Most potential delimiter read-macro definitions will duplicate a
lot of the code in Figure 17-3.  A macro could put a more abstract
interface on all this machinery.  Figure 17-4 shows how we might
define a utility for defining delimiter read-macros.  The defdelim
macro takes two characters, a parameter list, and a body of code.  The
parameter list and the body of code implicitly define a function.  A
call to defdelim defines the first character as a dispatching
read-macro which reads up to the second, then returns the result of
applying this function to what it
read.Incidentally,thebodyofthefunctioninFigure17-3alsocriesoutforautility-
for one we have already defined, in fact: mapa-b, from page 54.  Using
defdelim and mapa-b, the read-macro defined in Figure 17-3 could now
be written:

     (defdelim #\[ #\] (x y)
          (list 'quote (mapa-b #'identity (ceiling x) (floor y))))

   Another useful delimiter read-macro would be one for functional
composition.  Section 5-4 defined an operator for functional
composition:

     > (let ((f1 (compose #'list #'1+))
                  (f2 #'(lambda (x) (list (1+ x)))))
             (equal (funcall f1 7) (funcall f2 7)))
     T

   When we are composing built-in functions like list and 1+, there is
no reason to wait until runtime to evaluate the call to compose.
Section 5-7 suggested an alternative; by prefixing the sharp-dot
read-macro to a compose expression,

     #.(compose #'list #'1+)
      (defdelim #\{ #\} (&rest args)
            `(fn (compose ,@args)))

   Figure 17-5: A read-macro for functional composition.

we could cause it to be evaluated at read-time.

   Here we show a similar but cleaner solution.  The read-macro in
Figure 17-5 defines an expression of the form #{f 1 f 2 ...fn} to read
as the composition of f 1, f 2,...,fn.  Thus:

     > (funcall #{list 1+} 7)
     (8)

   It works by generating a call to fn (page 202), which will create
the function at compile-time.

* Menu:

* 17-4 When What Happens::      


File: onlisp.info,  Node: 17-4 When What Happens,  Prev: 17-3 Delimiters,  Up: 17 Read-Macros

17.4 17-4 When What Happens
===========================

Finally, it might be useful to clear up a possibly confusing issue.
If read-macros are invoked before ordinary macros, how is it that
macros can expand into expressions which contain read-macros?  For
example, the macro:

     (defmacro quotable ()
       '(list 'able))

   generates an expansion with a quote in it.  Or does it?  In fact,
what happens is that both quotes in the definition of this macro are
expanded when the defmacro expression is read, yielding

     (defmacro quotable ()
       (quote (list (quote able))))

   Usually, there is no harm in acting as if macroexpansions could
contain read- macros, because the definition of a read-macro will not
(or should not) change between read-time and compile-time.


File: onlisp.info,  Node: 18 Destructuring,  Next: 19 A Query Compiler,  Prev: 17 Read-Macros,  Up: Top

18 18 Destructuring
*******************

Destructuring is a generalization of assignment.  The operators setq
and setf do assignments to individual variables.  Destructuring
combines assignment with access: instead of giving a single variable
as the first argument, we give a pattern of variables, which are each
assigned the value occurring in the corresponding position in some
structure.

* Menu:

* 18-1 Destructuring on Lists::  
* 18-2 Other Structures::       
* 18-3 Reference::              
* 18-4 Matching::               


File: onlisp.info,  Node: 18-1 Destructuring on Lists,  Next: 18-2 Other Structures,  Prev: 18 Destructuring,  Up: 18 Destructuring

18.1 18-1 Destructuring on Lists
================================

As of CLTL2, Common Lisp includes a new macro called
destructuring-bind.  This macro was briefly introduced in Chapter 7.
Here we consider it in more detail.  Suppose that lst is a list of
three elements, and we want to bind x to the first, y to the second,
and z to the third.  In raw CLTL1 Common Lisp, we would have had to
say:

     (let ((x (first lst))
             (y (second lst))
             (z (third lst)))
       ...)

   With the new macro we can say instead

     (destructuring-bind (x y z) lst
       ...)

   which is not only shorter, but clearer as well.  Readers grasp
visual cues much faster than textual ones.  In the latter form we are
shown the relationship between x, y, and z; in the former, we have to
infer it.

   If such a simple case is made clearer by the use of destructuring,
imagine the improvement in more complex ones.  The first argument to
destructuring-bind can be an arbitrarily complex tree.  Imagine

     (destructuring-bind ((first last) (month day year) . notes)
                                 birthday
       ...)

   written using let and the list access functions.  Which raises
another point: destructuring makes it easier to write programs as well
as easier to read them.

   Destructuring did exist in CLTL1 Common Lisp.  If the patterns in
the examples above look familiar, it's because they have the same form
as macro parameter lists.  In fact, destructuring-bind is the code
used to take apart macro argument lists, now sold separately.  You can
put anything in the pattern that you would put in a macro parameter
list, with one unimportant exception (the &environment keyword).

   Establishing bindings en masse is an attractive idea.  The
following sections describe several variations upon this theme.


File: onlisp.info,  Node: 18-2 Other Structures,  Next: 18-3 Reference,  Prev: 18-1 Destructuring on Lists,  Up: 18 Destructuring

18.2 18-2 Other Structures
==========================

There is no reason to limit destructuring to lists.  Any complex
object is a candidate for it.  This section shows how to write macros
like destructuring-bind for other kinds of objects.

   The natural next step is to handle sequences generally.  Figure
18-1 contains a macro called dbind, which resembles
destructuring-bind, but works for any kind of sequence.  The second
argument can be a list, a vector, or any combination thereof:

     > (dbind (a b c) #(1 2 3)
             (list a b c))
     (123)
     > (dbind (a (b c) d) '( 1 #(2 3) 4)
             (list abcd))
     (1234)
     > (dbind (a (b . c) &rest d) '(1 "fribble" 2 3 4)
             (list abcd))
     (1 #\f "ribble" (2 3 4))

      (defmacro dbind (pat seq &body body)
            (let ((gseq (gensym)))
             `(let ((,gseq ,seq))
                ,(dbind-ex (destruc pat gseq #'atom) body))))

      (defun destruc (pat seq &optional (atom? #'atom) (n 0))
            (if (null pat)
               nil
               (let ((rest (cond ((funcall atom? pat) pat)
                                     ((eq (car pat) '&rest) (cadr pat))
                                     ((eq (car pat) '&body) (cadr pat))
                                     (t nil))))
                (if rest
                      `((,rest (subseq ,seq ,n)))
                      (let ((p (car pat))
                              (rec (destruc (cdr pat) seq atom? (1+ n))))
                       (if (funcall atom? p)
                              (cons `(,p (elt ,seq ,n))
                                    rec)
                              (let ((var (gensym)))
                                (cons (cons `(,var (elt ,seq ,n))
                                              (destruc p var atom?))
                                      rec))))))))

      (defun dbind-ex (binds body)
            (if (null binds)
               `(progn ,@body)
               `(let ,(mapcar #'(lambda (b)
                                      (if (consp (car b))
                                            (car b)
                                            b))
                                 binds)
                 ,(dbind-ex (mapcan #'(lambda (b)
                                              (if (consp (car b))
                                                   (cdr b)))
                                         binds)
                                body))))

   Figure 18-1: General sequence destructuring operator.

   The #( read-macro is for representing vectors, and #\ for
representing characters.  Since "abc" = #(#\a #\b #\c), the first
element of "fribble" is the character #\f.  For the sake of
simplicity, dbind supports only the &rest and &body keywords.

   Compared to most of the macros seen so far, dbind is big.  It's
worth studying the implementation of this macro, not only to
understand how it works, but also because it embodies a general lesson
about Lisp programming.  As section 3-4 mentioned, Lisp programs may
intentionally be written in a way that will make them easy to test.
In most code, we have to balance this desire against the need for
speed.  Fortunately, as Section 7-8 explained, speed is not so
important in expander code.  When writing code that generates
macroexpansions, we can make life easier for ourselves.  The expansion
of dbind is generated by two functions, destruc and dbind-ex.  Perhaps
they both could be combined into one function which would do
everything in a single pass.  But why bother?  As two separate
functions, they will be easier to test.  Why trade this advantage for
speed we don't need?

   The first function, destruc, traverses the pattern and associates
each variable with the location of the corresponding object at
runtime:

     > (destruc '(a b c) 'seq #'atom)
     ((A (ELT SEQ 0)) (B (ELT SEQ 1)) (C (ELT SEQ 2)))

   The optional third argument is the predicate used to distinguish
pattern structure from pattern content.

   To make access more efficient, a new variable (a gensym) will be
bound to each subsequence:

     > (destruc '(a (b . c) &rest d) 'seq)
     ((A (ELT SEQ 0))
      ((#:G2 (ELT SEQ 1)) (B (ELT #:G2 0)) (C (SUBSEQ #:G2 1)))
      (D (SUBSEQ SEQ 2)))

   The output of destruc is sent to dbind-ex, which generates the bulk
of the macroexpansion.  It translates the tree produced by destruc
into a nested series of lets:

     > (dbind-ex (destruc '(a (b . c) &rest d) 'seq) '(body))
     (LET ((A (ELT SEQ 0))
               (#:G4 (ELT SEQ 1))
               (D (SUBSEQ SEQ 2)))
       (LET ((B (ELT #:G4 0))
                  (C (SUBSEQ #:G4 1)))
             (PROGN BODY)))

      (defmacro with-matrix (pats ar &body body)
            (let ((gar (gensym)))
              `(let ((,gar ,ar))
                  (let ,(let ((row -1))
                             (mapcan
                                #'(lambda (pat)
                                     (incf row)
                                     (setq col -1)
                                     (mapcar #'(lambda (p)
                                                     `(,p (aref ,gar
                                                                      ,row
                                                                      ,(incf col))))
                                                 pat))
                                pats))
                     ,@body))))

      (defmacro with-array (pat ar &body body)
            (let ((gar (gensym)))
              `(let ((,gar ,ar))
                  (let ,(mapcar #'(lambda (p)
                                           `(,(car p) (aref ,gar ,@(cdr p))))
                                     pat)
                     ,@body))))

   Figure 18-2: Destructuring on arrays.

   Note that dbind, like destructuring-bind, assumes that it will find
all the list structure it is looking for.  Left-over variables are not
simply bound to nil,as with multiple-value-bind.  If the sequence
given at runtime does not have all the expected elements,
destructuring operators generate an error:

     > (dbind (a b c) (list 1 2))
     >>Error: 2 is not a valid index for the sequence (1 2)

   What other objects have internal structure?  There are arrays
generally, which differ from vectors in having more than one
dimension.  If we define a destructuring macro for arrays, how do we
represent the pattern?  For two-dimensional arrays, it is still
practical to use a list.  Figure 18-2 contains a macro, with-matrix,
for destructuring on two-dimensional arrays.

       (defmacro with-struct ((name . fields) struct &body body)
              (let ((gs (gensym)))
                 `(let ((,gs ,struct))
                     (let ,(mapcar #'(lambda (f)
                                             `(,f (,(symb name f) ,gs)))
                                       fields)
                       ,@body))))

   Figure 18-3: Destructuring on structures.

     > (setq ar (make-array '(3 3)))
     #<Simple-Array T (3 3) C2D39E>
     > (for (r 0 2)
               (for (c 0 2)
                  (setf (aref ar r c) (+ (* r 10) c))))
     NIL
     > (with-matrix ((a b c)
                               (def)
                               (g h i)) ar
               (list abcdefghi))
     (012101112202122)

   For large arrays or those with dimension 3 or higher, we want a
different kind of approach.  We are not likely to want to bind
variables to each element of a large array.  It will be more practical
to make the pattern a sparse representation of the array-containing
variables for only a few elements, plus coordinates to identify them.
The second macro in Figure 18-2 is built on this principle.  Here we
use it to get the diagonal of our previous array:

     > (with-array ((a 0 0) (d 1 1) (i 2 2)) ar
               (values a d i))
     01122

   With this new macro we have begun to move away from patterns whose
elements must occur in a fixed order.  We can make a similar sort of
macro to bind variables to fields in structures built by defstruct.
Such a macro is defined in Figure 18-3.  The first argument in the
pattern is taken to be the prefix associated with the structure, and
the rest are field names.  To build access calls, this macro uses symb
(page 58).

     > (defstruct visitor name title firm)
     VISITOR
     > (setq theo (make-visitor :name "Theodebert"
                                           :title 'king
                                           :firm 'franks))
     #S(VISITOR NAME "Theodebert" TITLE KING FIRM FRANKS)
     > (with-struct (visitor- name firm title) theo
             (list name firm title))
     ("Theodebert" FRANKS KING)


File: onlisp.info,  Node: 18-3 Reference,  Next: 18-4 Matching,  Prev: 18-2 Other Structures,  Up: 18 Destructuring

18.3 18-3 Reference
===================

CLOS brings with it a macro for destructuring on instances.  Suppose
tree is a class with three slots, species, age, and height, and that
my-tree is an instance of tree.  Within

     (with-slots (species age height) my-tree
       ...)

we can refer to the slots of my-tree as if they were ordinary
variables.  Within the body of the with-slots, the symbol height
refers to the height slot.  It is not simply bound to the value stored
there, but refers to the slot, so that if we write:

     (setq height 72)

   then the height slot of my-tree will be given the value 72.  This
macro works by defining height as a symbol-macro (Section 7-11) which
expands into a slot refer- ence.  In fact, it was to support macros
like with-slots that symbol-macrolet was added to Common Lisp.

   Whether or not with-slots is really a destructuring macro, it has
the same role pragmatically as destructuring-bind.  As conventional
destructuring is to call-by-value, this new kind is to call-by-name.
Whatever we call it, it looks to be useful.  What other macros can we
define on the same principle?

   We can create a call-by-name version of any destructuring macro by
making it expand into a symbol-macrolet rather than a let.  Figure
18-4 shows a version of dbind modified to behave like with-slots.  We
can use with-places as we do dbind:

     > (with-places (a b c) #(1 2 3)
             (list a b c))
     (123)

      (defmacro with-places (pat seq &body body)
         (let ((gseq (gensym)))
              `(let ((,gseq ,seq))
                     ,(wplac-ex (destruc pat gseq #'atom) body))))

      (defun wplac-ex (binds body)
         (if (null binds)
                `(progn ,@body)
                `(symbol-macrolet ,(mapcar #'(lambda (b)
                                                          (if (consp (car b))
                                                              (car b)
                                                              b))
                                                    binds)
                      ,(wplac-ex (mapcan #'(lambda (b)
                                                 (if (consp (car b))
                                                        (cdr b)))
                                            binds)
                                  body))))

   Figure 18-4: Reference destructuring on sequences.

   But the new macro also gives us the option to setf positions in
sequences, as we do slots in with-slots:

     > (let ((lst '(1 (2 3) 4)))
             (with-places (a (b . c) d) lst
               (setf a 'uno)
               (setf c '(tre)))
             lst)
     (UNO (2 TRE) 4)

   As in a with-slots, the variables now refer to the corresponding
locations in the structure.  There is one important difference,
however: you must use setf rather than setq to set these
pseudo-variables.  The with-slots macro must invoke a code-walker
(page 273) to transform setqs into setfs within its body.  Here,
writing a code-walker would be a lot of code for a small refinement.

   If with-places is more general than dbind, why not just use it all
the time?  While dbind associates a variable with a value, with-places
associates it with a set of instructions for finding a value.  Every
reference requires a lookup.  Where dbind would bind c to the value of
(elt x 2), with-places will make c a symbol-macro that expands into
(elt x 2).Soifc is evaluated n times in the body, that will entail n
calls to elt.  Unless you actually want to setf the variables created
by destructuring, dbind will be faster.

   The definition of with-places is only slightly changed from that of
dbind (Figure 18-1).  Within wplac-ex (formerly dbind-ex) the let has
become a symbol-macrolet.  By similar alterations, we could make a
call-by-name version of any normal destructuring macro.


File: onlisp.info,  Node: 18-4 Matching,  Prev: 18-3 Reference,  Up: 18 Destructuring

18.4 18-4 Matching
==================

As destructuring is a generalization of assignment, pattern-matching
is a gener- alization of destructuring.  The term "pattern-matching"
has many senses.  In this context, it means comparing two structures,
possibly containing variables, to see if there is some way of
assigning values to the variables which makes the two equal.  For
example, if ?x and ?y are variables, then the two lists

        (p ?x ?y c ?x)
        (
             pabca
                            )

   match when ?x = a and ?y = b.  And the lists

        (p ?x b ?y a)
        (p ?y b c a)

   match when ?x = ?y = c.

   Suppose a program works by exchanging messages with some outside
source.  To respond to a message, the program has to tell what kind of
message it is, and also to extract its specific content.  With a
matching operator we can combine the two steps.

   To be able to write such an operator we have to invent some way of
distin- guishing variables.  We can't just say that all symbols are
variables, because we will want symbols to occur as arguments within
patterns.  Here we will say that a pattern variable is a symbol
beginning with a question mark.  If it becomes in- convenient, this
convention could be changed simply by redefining the predicate var?.

   Figure 18-5 contains a pattern-matching function similar to ones
that appear in several introductions to Lisp.  We give match two
lists, and if they can be made to match, we will get back a list
showing how:

        > (match '(pabca)'(p?x?yc?x))
        ((?Y . B) (?X . A))
        T

          (defun match (x y &optional binds)
            (acond2
             ((or (eql x y) (eql x '_) (eql y '_)) (values binds t))
             ((binding x binds) (match it y binds))
             ((binding y binds) (match x it binds))
             ((varsym? x) (values (cons (cons x y) binds) t))
             ((varsym? y) (values (cons (cons y x) binds) t))
             ((and (consp x) (consp y) (match (car x) (car y) binds))
               (match (cdr x) (cdr y) it))
             (t (values nil nil))))

          (defun varsym? (x)
            (and (symbolp x) (eq (char (symbol-name x) 0) #\?)))

          (defun binding (x binds)
            (labels ((recbind (x binds)
                       (aif (assoc x binds)
                              (or (recbind (cdr it) binds)
                                   it))))
             (let ((b (recbind x binds)))
               (values (cdr b) b))))

   Figure 18-5: Matching function.

     > (match '(p ?x b ?y a) '(p ?y b c a))
     ((?Y . C) (?X . ?Y))
     T> (match '(a b c) '(a a a))
     NIL
     NIL

   As match compares its arguments element by element, it builds up
assignments of values to variables, called bindings, in the parameter
binds.  If the match is successful, match returns the bindings
generated, otherwise it returns nil.  Since not all successful matches
generate any bindings, match, like gethash, returns a second value to
indicate whether the match succeeded or failed:

     > (match '(p ?x) '(p ?x))
     NIL
     T

          (defmacro if-match (pat seq then &optional else)
            `(aif2 (match ',pat ,seq)
                     (let ,(mapcar #'(lambda (v)
                                             `(,v (binding ',v it)))
                                       (vars-in then #'atom))
                         ,then)
                     ,else))

          (defun vars-in (expr &optional (atom? #'atom))
            (if (funcall atom? expr)
                 (if (var? expr) (list expr))
                 (union (vars-in (car expr) atom?)
                          (vars-in (cdr expr) atom?))))

          (defun var? (x)
            (and (symbolp x) (eq (char (symbol-name x) 0) #\?)))

   Figure 18-6: Slow matching operator.

   When match returns nil and t as above, it indicates a successful
match which yielded no bindings.

   Like Prolog, match treats (underscore) as a wild-card.  It matches
everything, and has no effect on the bindings:

     > (match '(a ?x b) '(_ 1 _))
     ((?X . 1))
     T

   Given match, it is easy to write a pattern-matching version of
dbind.  Fig- ure 18-6 contains a macro called if-match.  Like dbind,
its first two arguments are a pattern and a sequence, and it
establishes bindings by comparing the pattern with the sequence.
However, instead of a body it has two more arguments: a then clause to
be evaluated, with new bindings, if the match succeeds; and an else
clause to be evaluated if the match fails.  Here is a simple function
which uses if-match:

     (defun abab (seq)
          (if-match (?x ?y ?x ?y) seq
                (values ?x ?y)
                nil))

   If the match succeeds, it will establish values for ?x and ?y,
which will be returned:

     > (abab '(hi ho hi ho))
     HI
     HO

   The function vars-in returns all the pattern variables in an
expression.  It calls var?  to test if something is a variable.  At
the moment, var?  is identical to varsym?  (Figure 18-5), which is
used to detect variables in binding lists.  We have two distinct
functions in case we want to use different representations for the two
kinds of variables.

   As defined in Figure 18-6, if-match is short, but not very
efficient.  It does too much work at runtime.  We traverse both
sequences at runtime, even though the first is known at compile-time.
Worse still, during the process of matching, we cons up lists to hold
the variable bindings.  If we take advantage of information known at
compile-time, we can write a version of if-match which performs no
unnecessary comparisons, and doesn't cons at all.

   If one of the sequences is known at compile-time, and only that one
contains variables, then we can go about things differently.  In a
call to match, either argument could contain variables.  By
restricting variables to the first argument of if-match, we make it
possible to tell at compile-time which variables will be involved in
the match.  Then instead of creating lists of variable bindings, we
could keep the values of variables in the variables themselves.

   The new version of if-match appears in Figure 18-7 and 18-8.  When
we can predict what code would be evaluated at runtime, we can simply
generate it at compile-time.  Here, instead of expanding into a call
to match, we generate code which performs just the right comparisons.

   If we are going to use the variable ?x to contain the binding of
?x, how do we represent a variable for which no binding has yet been
established by the match?  Here we will indicate that a pattern
variable is unbound by binding it to a gensym.  So if-match begins by
generating code which will bind all the variables in the pattern to
gensyms.  In this case, instead of expanding into a with-gensyms, it's
safe to make the gensyms once at compile-time and insert them directly
into the expansion.

   The rest of the expansion is generated by pat-match.  This macro
takes the same arguments as if-match; the only difference is that it
establishes no new bindings for pattern variables.  In some situations
this is an advantage, and Chapter 19 will use pat-match as an operator
in its own right.

   In the new matching operator, the distinction between pattern
content and pattern structure will be defined by the function simple?.
If we want to be able to use quoted literals in patterns, the
destructuring code (and vars-in)havetobe told not to go inside lists
whose first element is quote.  With the new matching operator, we will
be able to use lists as pattern elements, simply by quoting them.

      (defmacro if-match (pat seq then &optional else)
            `(let ,(mapcar #'(lambda (v) `(,v ',(gensym)))
                               (vars-in pat #'simple?))
                (pat-match ,pat ,seq ,then ,else)))

      (defmacro pat-match (pat seq then else)
            (if (simple? pat)
                 (match1 `((,pat ,seq)) then else)
                 (with-gensyms (gseq gelse)
                   `(labels ((,gelse () ,else))
                         ,(gen-match (cons (list gseq seq)
                                               (destruc pat gseq #'simple?))
                                      then
                                      `(,gelse))))))

      (defun simple? (x) (or (atom x) (eq (car x) 'quote)))

      (defun gen-match (refs then else)
            (if (null refs)
                 then
                 (let ((then (gen-match (cdr refs) then else)))
                   (if (simple? (caar refs))
                          (match1 refs then else)
                          (gen-match (car refs) then else)))))

   Figure 18-7: Fast matching operator.

   Like dbind, pat-match calls destruc to get a list of the calls that
will take apart its argument at runtime.  This list is passed on to
gen-match, which recursively generates matching code for nested
patterns, and thence to match1, which generates match code for each
leaf of the pattern tree.

   Most of the code which will appear in the expansion of an if-match
comes from match1, which is shown in Figure 18-8.  This function
considers four cases.  If the pattern argument is a gensym, then it is
one of the invisible variables created by destruc to hold sublists,
and all we need to do at runtime is test that it has the right length.
If the pattern element is a wildcard ( ), no code need be generated.
If the pattern element is a variable, match1 generates code to match
it against, or set it to, the corresponding part of the sequence given
at runtime.  Otherwise, the pattern element is taken to be a literal
value, and match1 generates code to compare it with the corresponding
part of the sequence.

      (defun match1 (refs then else)
         (dbind ((pat expr) . rest) refs
              (cond ((gensym? pat)
                       `(let ((,pat ,expr))
                            (if (and (typep ,pat 'sequence)
                                      ,(length-test pat rest))
                                ,then
                                ,else)))
                      ((eq pat '_) then)
                      ((var? pat)
                       (let ((ge (gensym)))
                           `(let ((,ge ,expr))
                             (if (or (gensym? ,pat) (equal ,pat ,ge))
                                   (let ((,pat ,ge)) ,then)
                                   ,else))))
                      (t `(if (equal ,pat ,expr) ,then ,else)))))

      (defun gensym? (s)
         (and (symbolp s) (not (symbol-package s))))

      (defun length-test (pat rest)
         (let ((fin (caadar (last rest))))
              (if (or (consp fin) (eq fin 'elt))
                     `(= (length ,pat) ,(length rest))
                     `(> (length ,pat) ,(- (length rest) 2)))))

   Figure 18-8: Fast matching operator (continued).

   Let's look at examples of how some parts of the expansion are
generated.  Suppose we begin with

     (if-match (?x 'a) seq
             (print ?x)
             nil)

   The pattern will be passed to destruc, with some gensym (call it g
for legibility) to represent the sequence:

     (destruc '(?x 'a) 'g #'simple?)

yielding:

        ((?x (elt g 0)) ((quote a) (elt g 1)))

   On the front of this list we cons (g seq):

        ((g seq) (?x (elt g 0)) ((quote a) (elt g 1)))

   and send the whole thing to gen-match.  Like the naive
implementation of length (page 22), gen-match first recurses all the
way to the end of the list, and then builds its return value on the
way back up.  When it has run out of elements, gen-match returns its
then argument, which will be ?x.  On the way back up the recursion,
this return value will be passed as the then argument to match1.Now we
will have a call like:

        (match1 '(((quote a) (elt g 1))) '(print ?x) ' else function )

yielding:

        (if (equal (quote a) (elt g 1))
                (print ?x)
                 else function )

   This will in turn become the then argument to another call to
match1, the value of which will become the then argument of the last
call to match1.  The full expansion of this if-match is shown in
Figure 18-9.

   In this expansion gensyms are used in two completely unrelated
ways.  The variables used to hold parts of the tree at runtime have
gensymed names, in order to avoid capture.  And the variable ?x is
initially bound to a gensym, to indicate that it hasn't yet been
assigned a value by matching.

   In the new if-match, the pattern elements are now evaluated instead
of being implicitly quoted.  This means that Lisp variables can be
used in patterns, as well as quoted expressions:

        > (let ((n 3))
                (if-match (?x n 'n '(a b)) '(13n(ab))
                   ?x))
        1

   Two further improvements appear because the new version calls
destruc (Figure 18-1).  The pattern can now contain &rest or &body
keywords (match doesn't bother with those).  And because destruc uses
the generic sequence operators elt and subseq, the new if-match will
work for any kind of sequence.  If abab is defined with the new
version, it can be used also on vectors and strings:

           (if-match (?x 'a) seq
                (print ?x))

   expands into:

           (let ((?x '#:g1))
             (labels ((#:g3 nil nil))
                (let ((#:g2 seq))
                  (if (and (typep #:g2 'sequence)
                               (= (length #:g2) 2))
                       (let ((#:g5 (elt #:g2 0)))
                            (if (or (gensym? x) (equal ?x #:g5))
                               (let ((?x #:g5))
                                   (if (equal 'a (elt #:g2 1))
                                        (print ?x)
                                        (#:g3)))
                               (#:g3)))
                       (#:g3)))))

   Figure 18-9: Expansion of an if-match.

     > (abab "abab")
     #\a
     #\b
     > (abab #(1 2 1 2))
     12
   In fact, patterns can be as complex as patterns to dbind:

     > (if-match (?x (1 . ?y) . ?x) '((a b) #(1 2 3) a b)
                 (values ?x ?y))
     (A B)
     #(2 3)

   Notice that, in the second return value, the elements of the vector
are displayed.  To have vectors printed this way, set *print-array* to
t.

   In this chapter we are beginning to cross the line into a new kind
of pro- gramming.  We began with simple macros for destructuring.  In
the final version of if-match we have something that looks more like
its own language.  The remaining chapters describe a whole class of
programs which operate on the same philosophy.


File: onlisp.info,  Node: 19 A Query Compiler,  Next: 20 Continuations,  Prev: 18 Destructuring,  Up: Top

19 19 A Query Compiler
**********************

Some of the macros defined in the preceding chapter were large ones.
To generate its expansion, if-match needed all the code in Figures
18-7 and 18-8, plus destruc from Figure 18-1.  Macros of this size
lead naturally to our last topic, embedded languages.  If small macros
are extensions to Lisp, large macros define sub-languages within
it-possibly with their own syntax or control structure.  We saw the
beginning of this in if-match, which had its own distinct
representation for variables.

   A language implemented within Lisp is called an embedded language.
Like "utility," the term is not a precisely defined one; if-match
probably still counts as a utility, but it is getting close to the
borderline.

   An embedded language is not a like a language implemented by a
traditional compiler or interpreter.  It is implemented within some
existing language, usually by transformation.  There need be no
barrier between the base language and the extension: it should be
possible to intermingle the two freely.  For the implementor, this can
mean a huge saving of effort.  You can embed just what you need, and
for the rest, use the base language.

   Transformation, in Lisp, suggests macros.  To some extent, you
could imple- ment embedded languages with preprocessors.  But
preprocessors usually operate only on text, while macros take
advantage of a unique property of Lisp: between the reader and the
compiler, your Lisp program is represented as lists of Lisp objects.
Transformations done at this stage can be much smarter.

   The best-known example of an embedded language is CLOS, the Common
Lisp Object System.  If you wanted to make an object-oriented version
of a conventional language, you would have to write a new compiler.
Not so in Lisp.  Tuning the compiler will make CLOS run faster, but in
principle the compiler doesn't have to be changed at all.  The whole
thing can be written in Lisp.

   The remaining chapters give examples of embedded languages.  This
chapter describes how to embed in Lisp a program to answer queries on
a database.  (You will notice in this program a certain family
resemblance to if-match.)  The first sections describe how to write a
system which interprets queries.  This program is then reimplemented
as a query compiler-in essence, as one big macro-making it both more
efficient and better integrated with Lisp.

* Menu:

* 19-1 The Database::           
* 19-2 Pattern-Matching Queries::  
* 19-3 A Query Interpreter::    
* 19-4 Restrictions on Binding::  
* 19-5 A Query Compiler::       


File: onlisp.info,  Node: 19-1 The Database,  Next: 19-2 Pattern-Matching Queries,  Prev: 19 A Query Compiler,  Up: 19 A Query Compiler

19.1 19-1 The Database
======================

For our present purposes, the format of the database doesn't matter
very much.  Here, for the sake of convenience, we will store
information in lists.  For example, we will represent the fact that
Joshua Reynolds was an English painter who lived from 1723 to 1792 by:

     (painter reynolds joshua english)
     (dates reynolds 1723 1792)

   There is no canonical way of reducing information to lists.  We
could just as well have used one big list:

     (painter reynolds joshua 1723 1792 english)

   It is up to the user to decide how to organize database entries.
The only restriction is that the entries (facts) will be indexed under
their first element (the predicate).  Within those bounds, any
consistent form will do, although some forms might make for faster
queries than others.

   Any database system needs at least two operations: one for
modifying the database, and one for examining it.  The code shown in
Figure 19-1 provides these operations in a basic form.  A database is
represented as a hash-table filled with lists of facts, hashed
according to their predicate.

   Although the database functions defined in Figure 19-1 support
multiple databases, they all default to operations on *default-db*.
As with packages in Common Lisp, programs which don't need multiple
databases need not even mention them.  In this chapter all the
examples will just use the *default-db*.

   We initialize the system by calling clear-db, which empties the
current database.  We can look up facts with a given predicate with
db-query, and insert new facts into a database entry with db-push.  As
explained in Section 12-1, a macro which expands into an invertible
reference will itself be invertible.  Since db-query is defined this
way, we can simply push new facts onto the db-query of their
predicates.  In Common Lisp, hash-table entries are initialized to nil

          (defun make-db (&optional (size 100))
            (make-hash-table :size size))

          (defvar *default-db* (make-db))

          (defun clear-db (&optional (db *default-db*))
            (clrhash db))

          (defmacro db-query (key &optional (db '*default-db*))
            `(gethash ,key ,db))

          (defun db-push (key val &optional (db *default-db*))
            (push val (db-query key db)))

          (defmacro fact (pred &rest args)
            `(progn (db-push ',pred ',args)
                    ',args))

   Figure 19-1: Basic database functions.

unless specified otherwise, so any key initially has an empty list
associated with it.  Finally, the macro fact adds a new fact to the
database.

     > (fact painter reynolds joshua english)
     (REYNOLDS JOSHUA ENGLISH)
     > (fact painter canale antonio venetian)
     (CANALE ANTONIO VENETIAN)
     > (db-query 'painter)
     ((CANALE ANTONIO VENETIAN)
          (REYNOLDS JOSHUA ENGLISH))
     T

   The t returned as the second value by db-query appears because
db-query expands into a gethash, which returns as its second value a
flag to distinguish between finding no entry and finding an entry
whose value is nil.


File: onlisp.info,  Node: 19-2 Pattern-Matching Queries,  Next: 19-3 A Query Interpreter,  Prev: 19-1 The Database,  Up: 19 A Query Compiler

19.2 19-2 Pattern-Matching Queries
==================================

Calling db-query is not a very flexible way of looking at the contents
of the database.  Usually the user wants to ask questions which depend
on more than just the first element of a fact.  A query language is a
language for expressing

       query         : ( symbol  argument *)
                     : (not  query )
                     : (and  query *)
                     : (or  query *)
       argument  : ? symbol
                     :  symbol
                     :  number

   Figure 19-2: Syntax of queries.

   more complicated questions.  In a typical query language, the user
can ask for all the values which satisfy some combination of
restrictions-for example, the last names of all the painters born in
1697.

   Our program will provide a declarative query language.  In a
declarative query language, the user specifies the constraints which
answers must satisfy, and leaves it to the system to figure out how to
generate them.  This way of expressing queries is close to the form
people use in everyday conversation.  With our program, we will be
able to express the sample query by asking for all the x such that
there is a fact of the form (painter x ...), and a fact of the form
(dates x 1697 ...).  We will be able to refer to all the painters born
in 1697 by writing:

     (and (painter ?x ?y ?z)
             (dates ?x 1697 ?w))

   As well as accepting simple queries consisting of a predicate and
some arguments, our program will be able to answer arbitrarily complex
queries joined together by logical operators like and and or.  The
syntax of the query language is shown in Figure 19-2.

   Since facts are indexed under their predicates, variables cannot
appear in the predicate position.  If you were willing to give up the
benefits of indexing, you could get around this restriction by always
using the same predicate, and making the first argument the de facto
predicate.

   Like many such systems, this program has a skeptic's notion of
truth: some facts are known, and everything else is false.  The not
operator succeeds if the fact in question is not present in the
database.  To a degree, you could represent explicit falsity by the
Wayne's World method:

     (edible motor-oil not)

   However, the not operator wouldn't treat these facts differently
from any others.

   In programming languages there is a fundamental distinction between
inter- preted and compiled programs.  In this chapter we examine the
same question with respect to queries.  A query interpreter accepts a
query and uses it to generate answers from the database.  A query
compiler accepts a query and generates a program which, when run,
yields the same result.  The following sections describe a query
interpreter and then a query compiler.


File: onlisp.info,  Node: 19-3 A Query Interpreter,  Next: 19-4 Restrictions on Binding,  Prev: 19-2 Pattern-Matching Queries,  Up: 19 A Query Compiler

19.3 19-3 A Query Interpreter
=============================

To implement a declarative query language we will use the
pattern-matching utilities defined in Section 18-4.  The functions
shown in Figure 19-3 interpret queries of the form shown in Figure
19-2.  The central function in this code is interpret-query, which
recursively works through the structure of a complex query, generating
bindings in the process.  The evaluation of complex queries proceeds
left-to-right, as in Common Lisp itself.

   When the recursion gets down to patterns for facts, interpret-query
calls lookup.  This is where the pattern-matching occurs.  The
function lookup takes a pattern consisting of a predicate and a list
of arguments, and returns a list of all the bindings which make the
pattern match some fact in the database.  It gets all the database
entries for the predicate, and calls match (page 239) to compare each
of them against the pattern.  Each successful match returns a list of
bindings, and lookup in turn returns a list of all these lists.

     > (lookup 'painter '(?x ?y english))
     (((?Y . JOSHUA) (?X . REYNOLDS)))

   These results are then filtered or combined depending on the
surrounding logical operators.  The final result is returned as a list
of sets of bindings.  Given the assertions shown in Figure 19-4, here
is the example from earlier in this chapter:

     > (interpret-query '(and (painter ?x ?y ?z)
                                        (dates ?x 1697 ?w)))
     (((?W . 1768) (?Z . VENETIAN) (?Y . ANTONIO) (?X . CANALE))
      ((?W . 1772) (?Z . ENGLISH) (?Y . WILLIAM) (?X . HOGARTH)))

   As a general rule, queries can be combined and nested without
restriction.  In a few cases there are subtle restrictions on the
syntax of queries, but these are best dealt with after looking at some
examples of how this code is used.

   The macro with-answer provides a clean way of using the query
interpreter within Lisp programs.  It takes as its first argument any
legal query; the rest of the arguments are treated as a body of code.
A with-answer expands into

      (defmacro with-answer (query &body body)
        (let ((binds (gensym)))
             `(dolist (,binds (interpret-query ',query))
                   (let ,(mapcar #'(lambda (v)
                                       `(,v (binding ',v ,binds)))
                                   (vars-in query #'atom))
                    ,@body))))

      (defun interpret-query (expr &optional binds)
        (case (car expr)
             (and (interpret-and (reverse (cdr expr)) binds))
             (or      (interpret-or (cdr expr) binds))
             (not (interpret-not (cadr expr) binds))
             (t       (lookup (car expr) (cdr expr) binds))))

      (defun interpret-and (clauses binds)
        (if (null clauses)
              (list binds)
              (mapcan #'(lambda (b)
                             (interpret-query (car clauses) b))
                         (interpret-and (cdr clauses) binds))))

      (defun interpret-or (clauses binds)
        (mapcan #'(lambda (c)
                         (interpret-query c binds))
                      clauses))

      (defun interpret-not (clause binds)
        (if (interpret-query clause binds)
              nil
              (list binds)))

      (defun lookup (pred args &optional binds)
        (mapcan #'(lambda (x)
                         (aif2 (match x args binds) (list it)))
                      (db-query pred)))

   Figure 19-3: Query interpreter.

      (clear-db)
      (fact painter hogarth william english)
      (fact painter canale antonio venetian)
      (fact painter reynolds joshua english)
      (fact dates hogarth 1697 1772)
      (fact dates canale 1697 1768)
      (fact dates reynolds 1723 1792)

   Figure 19-4: Assertion of sample facts.

code which collects all the sets of bindings generated by the query,
then iterates through the body with the variables in the query bound
as specified by each set of bindings.  Variables which appear in the
query of a with-answer can (usually) be used within its body.  When
the query is successful but contains no variables, with-answer
evaluates the body of code just once.

   With the database as defined in Figure 19-4, Figure 19-5 shows some
sample queries, accompanied by English translations.  Because
pattern-matching is done with match, it is possible to use the
underscore as a wild-card in patterns.

   To keep these examples short, the code within the bodies of the
queries does nothing more than print some result.  In general, the
body of a with-answer can consist of any Lisp expressions.


File: onlisp.info,  Node: 19-4 Restrictions on Binding,  Next: 19-5 A Query Compiler,  Prev: 19-3 A Query Interpreter,  Up: 19 A Query Compiler

19.4 19-4 Restrictions on Binding
=================================

There are some restrictions on which variables will be bound by a
query.  For example, why should the query

     (not (painter ?x ?y ?z))

assign any bindings to ?x and ?y at all?  There are an infinite number
of combi- nations of ?x and ?y which are not the name of some painter.
Thus we add the following restriction: the not operator will filter
out bindings which are already generated, as in

     (and (painter ?x ?y ?z) (not (dates ?x 1772 ?d)))

but you cannot expect it to generate bindings all by itself.  We have
to generate sets of bindings by looking for painters before we can
screen out the ones not born in 1772.  If we had put the clauses in
the reverse order:

     (and (not (dates ?x 1772 ?d)) (painter ?x ?y ?z))                        ; wrong

   The first name and nationality of every painter called Hogarth.

      > (with-answer (painter hogarth ?x ?y)
              (princ (list ?x ?y)))
      (WILLIAM ENGLISH)
      NIL

   The last name of every painter born in 1697.  (Our original
example.)

      > (with-answer (and (painter ?x _ _)
                                 (dates ?x 1697 _))
              (princ (list ?x)))
      (CANALE)(HOGARTH)
      NIL

   The last name and year of birth of everyone who died in 1772 or
1792.

      > (with-answer (or (dates ?x ?y 1772)
                               (dates ?x ?y 1792))
              (princ (list ?x ?y)))
      (HOGARTH 1697)(REYNOLDS 1723)
      NIL

   The last name of every English painter not born the same year as a
Venetian one.

      > (with-answer (and (painter ?x _ english)
                                 (dates ?x ?b _)
                                 (not (and (painter ?x2 _ venetian)
                                              (dates ?x2 ?b _))))
              (princ ?x))
      REYNOLDS
      NIL

   Figure 19-5: The query interpreter in use.

then we would get nil as the result if there were any painters born in
1772.  Even in the first example, we shouldn't expect to be able to
use the value of ?d within the body of a with-answer expression.

   Also, expressions of the form (or q1 ...  qn) are only guaranteed
to generate real bindings for variables which appear in all of the
qi.If a with-answer contained the query

     (or (painter ?x ?y ?z) (dates ?x ?b ?d))

   you could expect to use the binding of ?x, because no matter which
of the subqueries succeeds, it will generate a binding for ?x.  But
neither ?y nor ?b is guaranteed to get a binding from the query,
though one or the other will.  Pattern variables not bound by the
query will be nil for that iteration.


File: onlisp.info,  Node: 19-5 A Query Compiler,  Prev: 19-4 Restrictions on Binding,  Up: 19 A Query Compiler

19.5 19-5 A Query Compiler
==========================

The code in Figure 19-3 does what we want, but inefficiently.  It
analyzes the structure of the query at runtime, though it is known at
compile-time.  And it conses up lists to hold variable bindings, when
we could use the variables to hold their own values.  Both of these
problems can be solved by defining with-answer in a different way.

   Figure 19-6 defines a new version of with-answer.  The new version
con- tinues a trend which began with avg (page 182), and continued
with if-match (page 242): it does at compile-time much of the work
that the old version did at runtime.  The code in Figure 19-6 bears a
superficial resemblance to that in Figure 19-3, but none of these
functions are called at runtime.  Instead of gen- erating bindings,
they generate code, which becomes part of the expansion of
with-answer.  At runtime this code will generate all the bindings
which satisfy the query according to the current state of the
database.

   In effect, this program is one big macro.  Figure 19-7 shows the
macroexpan- sion of a with-answer.  Most of the work is done by
pat-match (page 242), which is itself a macro.  Now the only new
functions needed at runtime are the basic database functions shown in
Figure 19-1.

   When with-answer is called from the toplevel, query compilation has
little advantage.  The code representing the query is generated,
evaluated, then thrown away.  But when a with-answer expression
appears within a Lisp program, the code representing the query becomes
part of its macroexpansion.  So when the containing program is
compiled, the code for all the queries will be compiled inline in the
process.

   Although the primary advantage of the new approach is speed, it
also makes with-answer expressions better integrated with the code in
which they appear.  This shows in two specific improvements.  First,
the arguments within the query now get evaluated, so we can say:

        > (setq my-favorite-year 1723)
        1723
        > (with-answer (dates ?x my-favorite-year ?d)
                (format t "~A was born in my favorite year.~%" ?x))
        REYNOLDS was born in my favorite year.
        NIL

      (defmacro with-answer (query &body body)
        `(with-gensyms ,(vars-in query #'simple?)
              ,(compile-query query `(progn ,@body))))

      (defun compile-query (q body)
        (case (car q)
             (and (compile-and (cdr q) body))
             (or     (compile-or (cdr q) body))
             (not (compile-not (cadr q) body))
             (lisp `(if ,(cadr q) ,body))
             (t      (compile-simple q body))))

      (defun compile-simple (q body)
        (let ((fact (gensym)))
             `(dolist (,fact (db-query ',(car q)))
                   (pat-match ,(cdr q) ,fact ,body nil))))

      (defun compile-and (clauses body)
        (if (null clauses)
              body
              (compile-query (car clauses)
                                   (compile-and (cdr clauses) body))))

      (defun compile-or (clauses body)
        (if (null clauses)
              nil
              (let ((gbod (gensym))
                       (vars (vars-in body #'simple?)))
                    `(labels ((,gbod ,vars ,body))
                      ,@(mapcar #'(lambda (cl)
                                        (compile-query cl `(,gbod ,@vars)))
                                   clauses)))))

      (defun compile-not (q body)
        (let ((tag (gensym)))
             `(if (block ,tag
                      ,(compile-query q `(return-from ,tag nil))
                      t)
                    ,body)))

   Figure 19-6: Query compiler.

      (with-answer (painter ?x ?y ?z)
            (format t "~A ~A is a painter.~%" ?y ?x))

      is expanded by the query interpreter into:

      (dolist (#:g1 (interpret-query '(painter ?x ?y ?z)))
            (let ((?x (binding '?x #:g1))
                    (?y (binding '?y #:g1))
                    (?z (binding '?z #:g1)))
              (format t "~A ~A is a painter.~%" ?y ?x)))

      and by the query compiler into:

      (with-gensyms (?x ?y ?z)
            (dolist (#:g1 (db-query 'painter))
              (pat-match (?x ?y ?z) #:g1
                     (progn
                        (format t "~A ~A is a painter.~%" ?y ?x))
                     nil)))

   Figure 19-7: Two expansions of the same query.

   This could have been done in the query interpreter, but only at the
cost of calling eval explicitly.  And even then, it wouldn't have been
possible to refer to lexical variables in the query arguments.

   Since arguments within queries are now evaluated, any literal
argument (e.g.  english) that doesn't evaluate to itself should now be
quoted.  (See Figure 19-8.)

   The second advantage of the new approach is that it is now much
easier to include normal Lisp expressions within queries.  The query
compiler adds a lisp operator, which may be followed by any Lisp
expression.  Like the not operator, it cannot generate bindings by
itself, but it will screen out bindings for which the expression
returns nil.  The lisp operator is useful for getting at built-in
predicates like >:

     > (with-answer (and (dates ?x ?b ?d)
                                  (lisp (> (- ?d ?b) 70)))
             (format t "~A lived over 70 years.~%" ?x))
     CANALE lived over 70 years.
     HOGARTH lived over 70 years.
     NIL

   A well-implemented embedded language can have a seamless interface
with the

   The first name and nationality of every painter called Hogarth.

      > (with-answer (painter 'hogarth ?x ?y)
             (princ (list ?x ?y)))
      (WILLIAM ENGLISH)
      NIL

   The last name of every English painter not born in the same year as
a Venetian painter.

      > (with-answer (and (painter ?x _ 'english)
                                (dates ?x ?b _)
                                (not (and (painter ?x2 _ 'venetian)
                                              (dates ?x2 ?b _))))
             (princ ?x))
      REYNOLDS
      NIL

   The last name and year of death of every painter who died between
1770 and 1800 exclusive.

      > (with-answer (and (painter ?x _ _)
                                (dates ?x _ ?d)
                                (lisp (< 1770 ?d 1800)))
             (princ (list ?x ?d)))
      (REYNOLDS 1792)(HOGARTH 1772)
      NIL

   Figure 19-8: The query compiler in use.

base language on both sides.

   Aside from these two additions-the evaluation of arguments and the
new lisp operator-the query language supported by the query compiler
is identical to that supported by the interpreter.  Figure 19-8 shows
examples of the results generated by the query compiler with the
database as defined in Figure 19-4.

   Section 17-2 gave two reasons why it is better to compile an
expression than feed it, as a list, to eval.  The former is faster,
and allows the expression to be evaluated in the surrounding lexical
context.  The advantages of query compilation are exactly analogous.
Work that used to be done at runtime is now done at compile-time.  And
because the queries are compiled as a piece with the surrounding Lisp
code, they can take advantage of the lexical context.


File: onlisp.info,  Node: 20 Continuations,  Next: 21 Multiple Processes,  Prev: 19 A Query Compiler,  Up: Top

20 20 Continuations
*******************

A continuation is a program frozen in action: a single functional
object containing the state of a computation.  When the object is
evaluated, the stored computation is restarted where it left off.  In
solving certain types of problems it can be a great help to be able to
save the state of a program and restart it later.  In multiprocessing,
for example, a continuation conveniently represents a suspended
process.  In nondeterministic search programs, a continuation can
represent a node in the search tree.

   Continuations can be difficult to understand.  This chapter
approaches the topic in two steps.  The first part of the chapter
looks at the use of continuations in Scheme, which has built-in
support for them.  Once the behavior of continuations has been
explained, the second part shows how to use macros to build
continuations in Common Lisp programs.  Chapters 2124 will all make
use of the macros defined here.

* Menu:

* 20-1 Scheme Continuations::   
* 20-2 Continuation-Passing Macros::  
* 20-3 Code-Walkers and CPS Conversion::  


File: onlisp.info,  Node: 20-1 Scheme Continuations,  Next: 20-2 Continuation-Passing Macros,  Prev: 20 Continuations,  Up: 20 Continuations

20.1 20-1 Scheme Continuations
==============================

One of the principal ways in which Scheme differs from Common Lisp is
its explicit support for continuations.  This section shows how
continuations work in Scheme.  (Figure 20-1 lists some other
differences between Scheme and Common Lisp.)

   A continuation is a function representing the future of a
computation.  When- ever an expression is evaluated, something is
waiting for the value it will return.  For example, in

  1. Scheme makes no distinction between what Common Lisp calls the
     symbol-value and symbol-function of a symbol.  In Scheme, a
     variable has a single value, which can be either a function or
     some other sort of object.  Thus there is no need for sharp-quote
     or funcall in Scheme.  The Common Lisp:

           (let ((f #'(lambda (x) (1+ x))))
             (funcall f 2))

     would be in Scheme:

           (let ((f (lambda (x) (1+ x))))
             (f 2))

  2. Since Scheme has only one name-space, it doesn't need separate
     operators (e.g.  defun and setq) for assignments in each.
     Instead it has define, which is roughly equivalent to defvar, and
     set!, which takes the place of setq.  Global variables must be
     created with define before they can be set with set!.
  3. In Scheme, named functions are usually defined with define, which
     takes the place of defun as well as defvar.  The Common Lisp:

           (defun foo (x) (1+ x))

     has two possible Scheme translations:

           (define foo (lambda (x) (1+ x)))
           (define (foo x) (1+ x))

  4. In Common Lisp, the arguments to a function are evaluated
     left-to-right.  In Scheme, the order of evaluation is
     deliberately unspecified.  (And implementors delight in
     surprising those who forget this.)
  5. Instead of t and nil, Scheme has #t and #f.  The empty list, (),
     is true in some implementations and false in others.
  6. The default clause in cond and case expressions has the key else
     in Scheme, instead of t as in Common Lisp.
  7. Several built-in operators have different names: consp is pair?,
     null is null?, mapcar is (almost) map, and so on.  Ordinarily
     these should be obvious from the context.

   Figure 20-1: Some differences between Scheme and Common Lisp.

     (/ (- x 1) 2)

   when (-x1)is evaluated, the outer / expression is waiting for the
value, and something else is waiting for its value, and so on and so
on, all the way back to the toplevel-where print is waiting.

   We can think of the continuation at any given time as a function of
one argument.  If the previous expression were typed into the
toplevel, then when the subexpression (-x1)was evaluated, the
continuation would be:

     (lambda (val) (/ val 2))

   That is, the remainder of the computation could be duplicated by
calling this function on the return value.  If instead the expression
occurred in the following context

     (define (f1 w)
       (let ((y (f2 w)))
             (if (integer? y) (list 'a y) 'b)))

     (define (f2 x)
       (/ (- x 1) 2))

   and f1 were called from the toplevel, then when (- x 1) was
evaluated, the continuation would be equivalent to

     (lambda (val)
       (let ((y (/ val 2)))
             (if (integer? y) (list 'a y) 'b)))

   In Scheme, continuations are first-class objects, just like
functions.  You can ask Scheme for the current continuation, and it
will make you a function of one argument representing the future of
the computation.  You can save this object for as long as you like,
and when you call it, it will restart the computation that was taking
place when it was created.

   Continuations can be understood as a generalization of closures.  A
closure is a function plus pointers to the lexical variables visible
at the time it was created.  A continuation is a function plus a
pointer to the whole stack pending at the time it was created.  When a
continuation is evaluated, it returns a value using its own copy of
the stack, ignoring the current one.  If a continuation is created at
T 1 and evaluated at T2, it will be evaluated with the stack that was
pending at T1.

   Scheme programs have access to the current continuation via the
built-in operator call-with-current-continuation (call/cc for short).
When a program calls call/cc on a function of one argument:

     (call-with-current-continuation
       (lambda (cc)
             ...))

   the function will be passed another function representing the
current continuation.  By storing the value of cc somewhere, we save
the state of the computation at the point of the call/cc.

   In this example, we append together a list whose last element is
the value returned by a call/cc expression:

     > (define frozen)
     FROZEN
     > (append '(the call/cc returned)
                      (list (call-with-current-continuation
                              (lambda (cc)
                                (set! frozen cc)
                                'a))))
     (THE CALL/CC RETURNED A)

   The call/cc returns a, but first saves the continuation in the
global variable frozen.

   Calling frozen will restart the old computation at the point of the
call/cc.  Whatever value we pass to frozen will be returned as the
value of the call/cc:

     > (frozen 'again)
     (THE CALL/CC RETURNED AGAIN)

   Continuations aren't used up by being evaluated.  They can be
called repeatedly, just like any other functional object:

     > (frozen 'thrice)
     (THE CALL/CC RETURNED THRICE)
   When we call a continuation within some other computation, we see
more clearly what it means to return back up the old stack:

     > (+ 1 (frozen 'safely))
     (THE CALL/CC RETURNED SAFELY)

   Here, the pending + is ignored when frozen is called.  The latter
returns up the stack that was pending at the time it was first
created: through list, then append, to the toplevel.  If frozen
returned a value like a normal function call, the expression above
would have yielded an error when + tried to add 1 to a list.

   Continuations do not get unique copies of the stack.  They may
share variables with other continuations, or with the computation
currently in progress.  In this example, two continuations share the
same stack:

     > (define froz1)
     FROZ1
     > (define froz2)
     FROZ2
     > (let ((x 0))
             (call-with-current-continuation
                   (lambda (cc)
                    (set! froz1 cc)
                    (set! froz2 cc)))
             (set! x (1+ x))
             x)
     1

   so calls to either will return successive integers:

     > (froz2 ())
     2> (froz1 ())
     3

   Since the value of the call/cc expression will be discarded, it
doesn't matter what argument we give to froz1 and froz2.

   Now that we can store the state of a computation, what do we do
with it?  Chapters 2124 are devoted to applications which use
continuations.  Here we will consider a simple example which conveys
well the flavor of programming with saved states: we have a set of
trees, and we want to generate lists containing one element from each
tree, until we get a combination satisfying some condition.

   Trees can be represented as nested lists.  Page 70 described a way
to represent one kind of tree as a list.  Here we use another, which
allows interior nodes to have (atomic) values, and any number of
children.  In this representation, an interior node becomes a list;
its car contains the value stored at the node, and its cdr contains
the representations of the node's children.  For example, the two
trees shown in Figure 20-2 can be represented:

     (define t1 '(a (b (d h)) (c e (f i) g)))
     (define t2 '(1 (2 (3 6 7) 4 5)))

   Figure 20-3 contains functions which do depth-first traversals on
such trees.  In a real program we would want to do something with the
nodes as we encountered them.  Here we just print them.  The function
dft, given for comparison, does an ordinary depth-first traversal:

     > (dft t1)
     ABDHCEFIG()

   Figure 20-2: Two Trees.

   The function dft-node follows the same path through the tree, but
deals out nodes one at a time.  When dft-node reaches a node, it
follows the car of the node, and pushes onto *saved* a continuation to
explore the cdr.

     > (dft-node t1)
     A

   Calling restart continues the traversal, by popping the most
recently saved continuation and calling it.

     > (restart)
     B

   Eventually there will be no saved states left, a fact which restart
signals by returning done:

     ...> (restart)
     G> (restart)
     DONE

   Finally, the function dft2 neatly packages up what we just did by
hand:

     > (dft2 t1)
     ABDHCEFIG()

      (define (dft tree)
            (cond ((null? tree) ())
                    ((not (pair? tree)) (write tree))
                    (else (dft (car tree))
                             (dft (cdr tree)))))

      (define *saved* ())

      (define (dft-node tree)
            (cond ((null? tree) (restart))
                    ((not (pair? tree)) tree)
                    (else (call-with-current-continuation
                                (lambda (cc)
                                  (set! *saved*
                                          (cons (lambda ()
                                                     (cc (dft-node (cdr tree))))
                                                  *saved*))
                                  (dft-node (car tree)))))))

      (define (restart)
            (if (null? *saved*)
                 'done
                 (let ((cont (car *saved*)))
                    (set! *saved* (cdr *saved*))
                    (cont))))

      (define (dft2 tree)
            (set! *saved* ())
            (let ((node (dft-node tree)))
              (cond ((eq? node 'done) ())
                      (else (write node)
                                (restart)))))

   Figure 20-3: Tree traversal using continuations.

   Notice that there is no explicit recursion or iteration in the
definition of dft2: suc- cessive nodes are printed because the
continuations invoked by restart always return back through the same
cond clause in dft-node.

   This kind of program works like a mine.  It digs the initial shaft
by calling dft-node.  So long as the value returned is not done, the
code following the call to dft-node will call restart, which sends
control back down the stack again.  This process continues until the
return value signals that the mine is empty.  Instead of printing this
value, dft2 returns #f.  Search with continuations represents a novel
way of thinking about programs: put the right code in the stack, and
get the result by repeatedly returning up through it.

   If we only want to traverse one tree at a time, as in dft2, then
there is no reason to bother using this technique.  The advantage of
dft-node is that we can have several instances of it going at once.
Suppose we have two trees, and we want to generate, in depth-first
order, the cross-product of their elements.

     > (set! *saved* ())
     ()
     > (let ((node1 (dft-node t1)))
             (if (eq? node1 'done)
                  'done
                  (list node1 (dft-node t2))))
     (A 1)
     > (restart)
     (A 2)
     ...> (restart)
     (B 1)
   ...

   Using normal techniques, we would have had to take explicit steps
to save our place in the two trees.  With continuations, the state of
the two ongoing traversals is maintained automatically.  In a simple
case like this one, saving our place in the tree would not be so
difficult.  The trees are permanent data structures, so at least we
have some way of getting hold of "our place" in the tree.  The great
thing about continuations is that they can just as easily save our
place in the middle of any computation, even if there are no permanent
data structures associated with it.  The computation need not even
have a finite number of states, so long as we only want to restart a
finite number of them.

   As Chapter 24 will show, both of these considerations turn out to
be important in the implementation of Prolog.  In Prolog programs, the
"search trees" are not real data structures, but are implicit in the
way the program generates results.  And the trees are often infinite,
in which case we cannot hope to search the whole of one before
searching the next; we have no choice but to save our place, one way
or another.


File: onlisp.info,  Node: 20-2 Continuation-Passing Macros,  Next: 20-3 Code-Walkers and CPS Conversion,  Prev: 20-1 Scheme Continuations,  Up: 20 Continuations

20.2 20-2 Continuation-Passing Macros
=====================================

Common Lisp doesn't provide call/cc, but with a little extra effort we
can do the same things as we can in Scheme.  This section shows how to
use macros to build continuations in Common Lisp programs.  Scheme
continuations gave us two things:

  1. The bindings of all variables at the time the continuation was
     made.
  2. The state of the computation-what was going to happen from then
     on.

   In a lexically scoped Lisp, closures give us the first of these.
It turns out that we can also use closures to maintain the second, by
storing the state of the computation in variable bindings as well.

   The macros shown in Figure 20-4 make it possible to do function
calls while preserving continuations.  These macros replace the
built-in Common Lisp forms for defining functions, calling them, and
returning values.

   Functions which want to use continuations (or call functions which
do) should be defined with =defun instead of defun.  The syntax of
=defun is the same as that of defun, but its effect is subtly
different.  Instead of defining just a function, =defun defines a
function and a macro which expands into a call to it.  (The macro must
be defined first, in case the function calls itself.)  The function
will have the body that was passed to =defun, but will have an
additional parameter, *cont*, consed onto its parameter list.  In the
expansion of the macro, this function will receive *cont* along with
its other arguments.  So

        (=defun add1 (x) (=values (1+ x)))

        macroexpands into
        (progn (defmacro add1 (x)
                       `(=add1 *cont* ,x))
                    (defun =add1 (*cont* x)
                       (=values (1+ x))))

   When we call add1, we are actually calling not a function but a
macro.  The macro expands into a function call,(1) but with one extra
parameter: *cont*.So the current value of *cont* is always passed
implicitly in a call to an operator defined with =defun.

   What is *cont* for?  It will be bound to the current continuation.
The definition of =values shows how this continuation will be used.
Any function defined using =defun must return with =values, or call
some other function

      (setq *cont* #'identity)

      (defmacro =lambda (parms &body body)
         `#'(lambda (*cont* ,@parms) ,@body))

      (defmacro =defun (name parms &body body)
         (let ((f (intern (concatenate 'string
                                                "=" (symbol-name name)))))
             `(progn
                  (defmacro ,name ,parms
                     `(,',f *cont* ,,@parms))
                  (defun ,f (*cont* ,@parms) ,@body))))

      (defmacro =bind (parms expr &body body)
         `(let ((*cont* #'(lambda ,parms ,@body))) ,expr))

      (defmacro =values (&rest retvals)
         `(funcall *cont* ,@retvals))

      (defmacro =funcall (fn &rest args)
         `(funcall ,fn *cont* ,@args))

      (defmacro =apply (fn &rest args)
         `(apply ,fn *cont* ,@args))

   Figure 20-4: Continuation-passing macros.

   which does so.  The syntax of =values is the same as that of the
Common Lisp form values.  It can return multiple values if there is an
=bind with the same number of arguments waiting for them, but can't
return multiple values to the toplevel.

   The parameter *cont* tells a function defined with =defun what to
do with its return value.  When =values is macroexpanded it will
capture *cont*, and use it to simulate returning from the function.
The expression

     > (=values (1+ n))

   expands into

     (funcall *cont* (1+ n))

   At the toplevel, the value of *cont* is identity, which just
returns whatever is passed to it.  When we call (add1 2) from the
toplevel, the call gets macroex- panded into the equivalent of

     (funcall #'(lambda (*cont* n) (=values (1+ n))) *cont* 2)

   The reference to *cont* will in this case get the global binding.
The =values expression will thus macroexpand into the equivalent of:

     (funcall #'identity (1+ n))

   which just adds 1 to n and returns the result.

   In functions like add1, we go through all this trouble just to
simulate what Lisp function call and return do anyway:

     > (=defun bar (x)
             (=values (list 'a (add1 x))))
     BAR
     > (bar 5)
     (A 6)

   The point is, we have now brought function call and return under
our own control, and can do other things if we wish.

   It is by manipulating *cont* that we will get the effect of
continuations.  Although *cont* has a global value, this will rarely
be the one used: *cont* will nearly always be a parameter, captured by
=values and the macros defined by =defun.  Within the body of add1,
for example, *cont* is a parameter and not the global variable.  This
distinction is important because these macros wouldn't work if *cont*
were not a local variable.  That's why *cont* is given its initial
value in a setq instead of a defvar: the latter would also proclaim it
to be special.

   The third macro in Figure 20-4, =bind, is intended to be used in
the same way as multiple-value-bind.  It takes a list of parameters,
an expression, and a body of code: the parameters are bound to the
values returned by the expression, and the code body is evaluated with
those bindings.  This macro should be used whenever additional
expressions have to be evaluated after calling a function defined with
=defun.

     > (=defun message ()
             (=values 'hello 'there))
     MESSAGE



     > (=defun baz ()
             (=bind (m n) (message)
               (=values (list m n))))
     BAZ
     > (baz)
     (HELLO THERE)

   Notice that the expansion of an =bind creates a new variable called
*cont*.  The body of baz macroexpands into:

     (let ((*cont* #'(lambda (m n)
                               (=values (list m n)))))
       (message))

which in turn becomes:

     (let ((*cont* #'(lambda (m n)
                               (funcall *cont* (list m n)))))
       (=message *cont*))

   The new value of *cont* is the body of the =bind expression, so
when message "returns" by funcalling *cont*, the result will be to
evaluate the body of code.  However (and this is the key point),
within the body of the =bind:

     #'(lambda (m n)
             (funcall *cont* (list m n)))

   the *cont* that was passed as an argument to =baz is still visible,
so when the body of code in turn evaluates an =values, it will be able
to return to the original calling function.  The closures are knitted
together: each binding of *cont* is a closure containing the previous
binding of *cont*, forming a chain which leads all the way back up to
the global value.

   We can see the same phenomenon on a smaller scale here:

     > (let ((f #'identity))
             (let ((g #'(lambda (x) (funcall f (list 'a x)))))
               #'(lambda (x) (funcall g (list 'b x)))))
     #<Interpreted-Function BF6326>
     > (funcall * 2)
     (A (B 2))

   This example creates a function which is a closure containing a
reference to g, which is itself a closure containing a reference to f.
Similar chains of closures were built by the network compiler on page
80.

  1. The parameter list of a function defined with =defun must consist
     solely of parameter names.
  2. Functions which make use of continuations, or call other
     functions which do, must be defined with =lambda or =defun.
  3. Such functions must terminate either by returning values with
     =values,or by calling another function which obeys this
     restriction.
  4. If an =bind, =values, =apply,or=funcall expression occurs in a
     segment of code, it must be a tail call.  Any code to be
     evaluated after an =bind should be put in its body.  So if we
     want to have several =binds one after another, they must be
     nested:

      (=defun foo (x)
            (=bind (y) (bar x)
              (format t "Ho ")
              (=bind (z) (baz x)
                 (format t "Hum.")
                 (=values x y z))))

   Figure 20-5: Restrictions on continuation-passing macros.

   The remaining macros, =apply and =funcall, are for use with
functions defined by =lambda.  Note that "functions" defined with
=defun, because they are actually macros, cannot be given as arguments
to apply or funcall.  The way around this problem is analogous to the
trick mentioned on page 110.  It is to package up the call inside
another =lambda:

     > (=defun add1 (x)
             (=values (1+ x)))
     ADD1
     > (let ((fn (=lambda (n) (add1 n))))
             (=bind (y) (=funcall fn 9)
                (format nil "9 + 1 = ~A" y)))
     "9+1=10"

   Figure 20-5 summarizes all the restrictions imposed by the
continuation- passing macros.  Functions which neither save
continuations, nor call other func- tions which do, need not use these
special macros.  Built-in functions like list, for example, are
exempt.

   Figure 20-6 contains the code from Figure 20-3, translated from
Scheme into Common Lisp, and using the continuation-passing macros
instead of Scheme

      (defun dft (tree)
            (cond ((null tree) nil)
                  ((atom tree) (princ tree))
                  (t (dft (car tree))
                     (dft (cdr tree)))))

      (setq *saved* nil)

      (=defun dft-node (tree)
            (cond ((null tree) (restart))
                  ((atom tree) (=values tree))
                  (t (push #'(lambda () (dft-node (cdr tree)))
                              *saved*)
                     (dft-node (car tree)))))

      (=defun restart ()
            (if *saved*
               (funcall (pop *saved*))
               (=values 'done)))

      (=defun dft2 (tree)
            (setq *saved* nil)
            (=bind (node) (dft-node tree)
             (cond ((eq node 'done) (=values nil))
                    (t (princ node)
                        (restart)))))

   Figure 20-6: Tree traversal using continuation-passing macros.

   continuations.  With the same example tree, dft2 works just as
before:

     > (setq t1 '(a (b (d h)) (c e (f i) g))
                t2 '(1 (2 (3 6 7) 4 5)))
     (1 (2 (3 6 7) 4 5))
     > (dft2 t1)
     ABDHCEFIG
     NIL

   Saving states of multiple traversals also works as in Scheme,
though the example becomes a bit longer:

     > (=bind (node1) (dft-node t1)
             (if (eq node1 'done)
                  'done
                  (=bind (node2) (dft-node t2)
                    (list node1 node2))))
     (A 1)
     > (restart)
     (A 2)
     ...> (restart)
     (B 1)
     ...

   By knitting together a chain of lexical closures, Common Lisp
programs can build their own continuations.  Fortunately, the closures
are knitted together by the macros in the sweatshop of Figure 20-4,
and the user can have the finished garment without giving a thought to
its origins.

   Chapters 2124 all rely on continuations in some way.  These
chapters will show that continuations are an abstraction of unusual
power.  They may not be overly fast, especially when implemented on
top of the language as macros, but the abstractions we can build upon
them make certain programs much faster to write, and there is a place
for that kind of speed too.

   ---------- Footnotes ----------

   (1) Functions created by =defun are deliberately given interned
names, to make it possible to trace them.  If tracing were never
necessary, it would be safer to gensym the names.


File: onlisp.info,  Node: 20-3 Code-Walkers and CPS Conversion,  Prev: 20-2 Continuation-Passing Macros,  Up: 20 Continuations

20.3 20-3 Code-Walkers and CPS Conversion
=========================================

The macros described in the previous section represent a compromise.
They give us the power of continuations, but only if we write our
programs in a certain way.  Rule 4 in Figure 20-5 means that we always
have to write

     (=bind (x) (fn y)
            (list 'a x))

rather than

     (list 'a                                                                ; wrong
                (=bind (x) (fn y) x))

   A true call/cc imposes no such restrictions on the programmer.  A
call/cc can grab the continuation at any point in a program of any
shape.  We could implement an operator with the full power of call/cc,
but it would be a lot more work.  This section outlines how it could
be done.

   A Lisp program can be transformed into a form called
"continuation-passing style."  Programs which have undergone complete
CPS conversion are impossible to read, but one can grasp the spirit of
this process by looking at code which has been partially transformed.
The following function to reverse lists:

     (defun rev (x)
       (if (null x)
               nil
               (append (rev (cdr x)) (list (car x)))))

yields an equivalent continuation-passing version:

     (defun rev2 (x)
       (revc x #'identity))

     (defun revc (x k)
       (if (null x)
               (funcall k nil)
               (revc (cdr x)
                       #'(lambda (w)
                              (funcall k (append w (list (car x))))))))

   In the continuation-passing style,functions get an additional
parameter (here k) whose value will be the continuation.  The
continuation is a closure representing what should be done with the
current value of the function.  On the first recursion, the
continuation is identity; what should be done is that the function
should just return its current value.  On the second recursion, the
continuation will be equivalent to:

     #'(lambda (w)
             (identity (append w (list (car x)))))

   which says that what should be done is to append the car of the
list to the current value, and return it.

   Once you can do CPS conversion, it is easy to write call/cc.  In a
program which has undergone CPS conversion, the entire current
continuation is always present, and call/cc can be implemented as a
simple macro which calls some function with it as an argument.

   To do CPS conversion we need a code-walker, a program that
traverses the trees representing the source code of a program.
Writing a code-walker for Common Lisp is a serious undertaking.  To be
useful, a code-walker has to do more than simply traverse expressions.
It also has to know a fair amount about what the expressions mean.  A
code-walker can't just think in terms of symbols, for example.  A
symbol could represent, among other things, itself, a function, a
variable, a block name, or a tag for go.  The code-walker has to use
the context to distinguish one kind of symbol from another, and act
accordingly.

   Since writing a code-walker would be beyond the scope of this book,
the macros described in this chapter are the most practical
alternative.  The macros in this chapter split the work of building
continuations with the user.  If the user writes programs in something
sufficiently close to CPS, the macros can do the rest.  That's what
rule 4 really amounts to: if everything following an =bind expression
is within its body, then between the value of *cont* and the code in
the body of the =bind, the program has enough information to construct
the current continuation.

   The =bind macro is deliberately written to make this style of
programming feel natural.  In practice the restrictions imposed by the
continuation-passing macros are bearable.


File: onlisp.info,  Node: 21 Multiple Processes,  Next: 22 Nondeterminism,  Prev: 20 Continuations,  Up: Top

21 21 Multiple Processes
************************

The previous chapter showed how continuations allow a running program
to get hold of its own state, and store it away to be restarted later.
This chapter deals with a model of computation in which a computer
runs not one single program, but a collection of independent
processes.  The concept of a process corresponds closely with our
concept of the state of a program.  By writing an additional layer of
macros on top of those in the previous chapter, we can embed
multiprocessing in Common Lisp programs.

* Menu:

* 21-1 The Process Abstraction::  
* 21-2 Implementation::         
* 21-3 The Less-than-Rapid Prototype::  


File: onlisp.info,  Node: 21-1 The Process Abstraction,  Next: 21-2 Implementation,  Prev: 21 Multiple Processes,  Up: 21 Multiple Processes

21.1 21-1 The Process Abstraction
=================================

Multiple processes are a convenient way of expressing programs which
must do several things at once.  A traditional processor executes one
instruction at a time.  To say that multiple processes do more than
one thing at once is not to say that they somehow overcome this
hardware limitation: what it means is that they allow us to think at a
new level of abstraction, in which we don't have to specify exactly
what the computer is doing at any given time.  Just as virtual memory
allows us to act as though the computer had more memory than it
actually does, the notion of a process allows us to act as if the
computer could run more than one program at a time.

   The study of processes is traditionally in the domain of operating
systems.  But the usefulness of processes as an abstraction is not
limited to operating systems.  They are equally useful in other
real-time applications, and in simulations.

   Much of the work done on multiple processes has been devoted to
avoiding certain types of problems.  Deadlock is one classic problem
with multiple pro- cesses: two processes both stand waiting for the
other to do something, like two people who each refuse to cross a
threshold before the other.  Another problem is the query which
catches the system in an inconsistent state-say, a balance inquiry
which arrives while the system is transferring funds from one account
to another.  This chapter deals only with the process abstraction
itself; the code presented here could be used to test algorithms for
preventing deadlock or inconsistent states, but it does not itself
provide any protection against these problems.

   The implementation in this chapter follows a rule implicit in all
the programs in this book: disturb Lisp as little as possible.  In
spirit, a program ought to be as much as possible like a modification
of the language, rather than a separate application written in it.
Making programs harmonize with Lisp makes them more robust, like a
machine whose parts fit together well.  It also saves effort;
sometimes you can make Lisp do a surprising amount of your work for
you.

   The aim of this chapter is to make a language which supports
multiple pro- cesses.  Our strategy will be to turn Lisp into such a
language, by adding a few new operators.  The basic elements of our
language will be as follows:

   Functions will be defined with the =defun or =lambda macros from
the previous chapter.

   Processes will be instantiated from function calls.  There is no
limit on the number of active processes, or the number of processes
instantiated from any one function.  Each process will have a
priority, initially given as an argument when it is created.

   Wait expressions may occur within functions.  A wait expression
will take a variable, a test expression, and a body of code.  If a
process encounters a wait, the process will be suspended at that point
until the test expression returns true.  Once the process restarts,
the body of code will be evaluated, with the variable bound to the
value of the test expression.  Test expressions should not ordinarily
have side-effects, because there are no guarantees about when, or how
often, they will be evaluated.

   Scheduling will be done by priority.  Of all the processes able to
restart, the system will run the one with the highest priority.

   The default process will run if no other process can.  It is a
read-eval-print loop.

   Creation and deletion of most objects will be possible on the fly.
From run- ning processes it will be possible to define new functions,
and to instantiate and kill processes.


      (defstruct proc pri state wait)

      (proclaim '(special *procs* *proc*))

      (defvar *halt* (gensym))

      (defvar *default-proc*
                   (make-proc :state #'(lambda (x)
                                                (format t "~%>> ")
                                                (princ (eval (read)))
                                                (pick-process))))

      (defmacro fork (expr pri)
         `(prog1 ',expr
                    (push (make-proc
                                :state #'(lambda (,(gensym))
                                               ,expr
                                               (pick-process))
                                :pri      ,pri)
                             *procs*)))

      (defmacro program (name args &body body)
         `(=defun ,name ,args
             (setq *procs* nil)
             ,@body
             (catch *halt* (loop (pick-process)))))

   Figure 21-1: Process structure and instantiation.

   Continuations make it possible to store the state of a Lisp
program.  Being able to store several states at once is not very far
from having multiple processes.  Starting with the macros defined in
the previous chapter, we need less than 60 lines of code to implement
multiple processes.


File: onlisp.info,  Node: 21-2 Implementation,  Next: 21-3 The Less-than-Rapid Prototype,  Prev: 21-1 The Process Abstraction,  Up: 21 Multiple Processes

21.2 21-2 Implementation
========================

Figures 21-1 and 21-2 contain all the code needed to support multiple
processes.  Figure 21-1 contains code for the basic data structures,
the default process, initial- ization, and instantiation of processes.
Processes, or procs, have the following structure:

   pri is the priority of the process, which should be a positive
number.

   state is a continuation representing the state of a suspended
process.  A process is restarted by funcalling its state.

   wait is usually a function which must return true in order for the
process to be restarted, but initially the wait of a newly created
process is nil.  A process with a null wait can always be restarted.

   The program uses three global variables: *procs*, the list of
currently sus- pended processes; *proc*, the process now running; and
*default-proc*, the default process.

   The default process runs only when no other process can.  It
simulates the Lisp toplevel.  Within this loop, the user can halt the
program, or type expressions which enable suspended processes to
restart.  Notice that the default process calls eval explicitly.  This
is one of the few situations in which it is legitimate to do so.
Generally it is not a good idea to call eval at runtime, for two
reasons:

  1. It's inefficient: eval is handed a raw list, and either has to
     compile it on the spot, or evaluate it in an interpreter.  Either
     way is slower than compiling the code beforehand, and just
     calling it.

  2. It's less powerful, because the expression is evaluated with no
     lexical con- text.  Among other things, this means that you can't
     refer to ordinary variables visible outside the expression being
     evaluated.

   Usually, calling eval explicitly is like buying something in an
airport gift-shop.  Having waited till the last moment, you have to
pay high prices for a limited selection of second-rate goods.

   Cases like this are rare instances when neither of the two
preceding arguments applies.  We couldn't possibly have compiled the
expressions beforehand.  We are just now reading them; there is no
beforehand.  Likewise, the expression can't refer to surrounding
lexical variables, because expressions typed at the toplevel are in
the null lexical environment.  In fact, the definition of this
function simply reflects its English description: it reads and
evaluates what the user types.

   The macro fork instantiates a process from a function call.
Functions are defined as usual with =defun:

     (=defun foo (x)
       (format t "Foo was called with ~A.~%" x)
       (=values (1+ x)))

   Now when we call fork with a function call and a priority number:

     (fork (foo 2) 25)

a new process is pushed onto *procs*.  The new process has a priority
of 25,a proc-wait of nil, since it hasn't been started yet, and a
proc-state consisting of a call to foo with the argument 2.

   The macro program allows us to create a group of processes and run
them together.  The definition:

     (program two-foos (a b)
       (fork (foo a) 99)
       (fork (foo b) 99))

macroexpands into the two fork expressions, sandwiched between code
which clears out the suspended processes, and other code which
repeatedly chooses a process to run.  Outside this loop, the macro
establishes a tag to which control can be thrown to end the program.
As a gensym, this tag will not conflict with tags established by user
code.  A group of processes defined as a program returns no particular
value, and is only meant to be called from the toplevel.

   After the processes are instantiated, the process scheduling code
takes over.  This code is shown in Figure 21-2.  The function
pick-process selects and runs the highest priority process which is
able to restart.  Selecting this process is the job of
most-urgent-process.  A suspended process is eligible to run if it has
no wait function, or its wait function returns true.  Among eligible
processes, the one with the highest priority is chosen.  The winning
process and the value returned by its wait function (if there is one)
are returned to pick-process.  There will always be some winning
process, because the default process always wants to run.

   The remainder of the code in Figure 21-2 defines the operators used
to switch control between processes.  The standard wait expression is
wait, as used in the function pedestrian in Figure 21-3.  In this
example, the process waits until there is something in the list
*open-doors*, then prints a message:

     > (ped)
     >> (push 'door2 *open-doors*)
     Entering DOOR2
     >> (halt)
     NIL

   A wait is similar in spirit to an =bind (page 267), and carries the
same restriction that it must be the last thing to be evaluated.
Anything we want to happen after the wait must be put in its body.
Thus, if we want to have a process wait several times, the wait
expressions must be nested.  By asserting facts aimed at one another,
processes can cooperate in reaching some goal, as in Figure 21-4.

      (defun pick-process ()
            (multiple-value-bind (p val) (most-urgent-process)
             (setq *proc* p
                       *procs* (delete p *procs*))
             (funcall (proc-state p) val)))

      (defun most-urgent-process ()
            (let ((proc1 *default-proc*) (max -1) (val1 t))
             (dolist (p *procs*)
               (let ((pri (proc-pri p)))
                  (if (> pri max)
                        (let ((val (or (not (proc-wait p))
                                           (funcall (proc-wait p)))))
                          (when val
                            (setq proc1 p
                                    max     pri
                                    val1 val))))))
             (values proc1 val1)))

      (defun arbitrator (test cont)
            (setf (proc-state *proc*) cont
                  (proc-wait *proc*) test)
            (push *proc* *procs*)
            (pick-process))

      (defmacro wait (parm test &body body)
            `(arbitrator #'(lambda () ,test)
                           #'(lambda (,parm) ,@body)))

      (defmacro yield (&body body)
            `(arbitrator nil #'(lambda (,(gensym)) ,@body)))

      (defun setpri (n) (setf (proc-pri *proc*) n))

      (defun halt (&optional val) (throw *halt* val))

      (defun kill (&optional obj &rest args)
            (if obj
               (setq *procs* (apply #'delete obj *procs* args))
               (pick-process)))

   Figure 21-2: Process scheduling.

      (defvar *open-doors* nil)

      (=defun pedestrian ()
           (wait d (car *open-doors*)
             (format t "Entering ~A~%" d)))

      (program ped ()
           (fork (pedestrian) 1))

   Figure 21-3: One process with one wait.

   Processes instantiated from visitor and host, if given the same
door, will exchange control via messages on a blackboard:

     > (ballet)
     Approach DOOR2. Open DOOR2. Enter DOOR2. Close DOOR2.
     Approach DOOR1. Open DOOR1. Enter DOOR1. Close DOOR1.
     >>

   There is another, simpler type of wait expression: yield, whose
only purpose is to give other higher-priority processes a chance to
run.  A process might want to yield after executing a setpri
expression, which resets the priority of the current process.  As with
a wait, any code to be executed after a yield must be put within its
body.

   The program in Figure 21-5 illustrates how the two operators work
together.  Initially, the barbarians have two aims: to capture Rome
and to plunder it.  Captur- ing the city has (slightly) higher
priority, and so will run first.  However, after the city has been
reduced, the priority of the capture process decreases to 1.  Then
there is a vote, and plunder, as the highest-priority process, starts
running.

     > (barbarians)
     Liberating ROME.
     Nationalizing ROME.
     Refinancing ROME.
     Rebuilding ROME.
     >>

   Only after the barbarians have looted Rome's palaces and ransomed
the patricians, does the capture process resume, and the barbarians
turn to fortifying their own position.

   Underlying wait expressions is the more general arbitrator.  This
function stores the current process, and then calls pick-process to
start some process

      (defvar *bboard* nil)

      (defun claim          (&rest f) (push f *bboard*))

      (defun unclaim (&rest f) (pull f *bboard* :test #'equal))

      (defun check          (&rest f) (find f *bboard* :test #'equal))

      (=defun visitor (door)
            (format t "Approach ~A. " door)
            (claim 'knock door)
            (wait d (check 'open door)
              (format t "Enter ~A. " door)
              (unclaim 'knock door)
              (claim 'inside door)))

      (=defun host (door)
            (wait k (check 'knock door)
              (format t "Open ~A. " door)
              (claim 'open door)
              (wait g (check 'inside door)
                 (format t "Close ~A.~%" door)
                 (unclaim 'open door))))

      (program ballet ()
            (fork (visitor 'door1) 1)
            (fork (host 'door1) 1)
            (fork (visitor 'door2) 1)
            (fork (host 'door2) 1))

   Figure 21-4: Synchronization with a blackboard.

(perhaps the same one) running again.  It will be given two arguments:
a test function and a continuation.  The former will be stored as the
proc-wait of the process being suspended, and called later to
determine if it can be restarted.  The latter will become the
proc-state, and calling it will restart the suspended process.

   The macros wait and yield build this continuation function simply
by wrap- ping their bodies in lambda-expressions.  For example,

     (wait d (car *bboard*) (=values d))

      (=defun capture (city)
         (take city)
         (setpri 1)
         (yield
             (fortify city)))

      (=defun plunder (city)
         (loot city)
         (ransom city))

      (defun take (c)           (format t "Liberating ~A.~%" c))
      (defun fortify (c) (format t "Rebuilding ~A.~%" c))
      (defun loot (c)           (format t "Nationalizing ~A.~%" c))
      (defun ransom (c) (format t "Refinancing ~A.~%" c))

      (program barbarians ()
         (fork (capture 'rome) 100)
         (fork (plunder 'rome) 98))

   Figure 21-5: Effect of changing priorities.

expands into:

     (arbitrator #'(lambda () (car *bboard*))
                      #'(lambda (d) (=values d)))

   If the code obeys the restrictions listed in Figure 20-5, making a
closure of the wait's body will preserve the whole current
continuation.  With its =values expanded the second argument becomes:

     #'(lambda (d) (funcall *cont* d))

   Since the closure contains a reference to *cont*, the suspended
process with this wait function will have a handle on where it was
headed at the time it was suspended.

   The halt operator stops the whole program, by throwing control back
to the tag established by the expansion of program.  It takes an
optional argument, which will be returned as the value of the program.
Because the default process is always willing to run, the only way
programs end is by explicit halts.  It doesn't matter what code
follows a halt, since it won't be evaluated.

   Individual processes can be killed by calling kill.  If given no
arguments, this operator kills the current process.  In this case,
kill is like a wait expression which neglects to store the current
process.  If kill is given arguments, they become the arguments to a
delete on the list of processes.  In the current code, there is not
much one can say in a kill expression, because processes do not have
many properties to refer to.  However, a more elaborate system would
associate more information with processes-time stamps, owners, and so
on.  The default process can't be killed, because it isn't kept in the
list *procs*.


File: onlisp.info,  Node: 21-3 The Less-than-Rapid Prototype,  Prev: 21-2 Implementation,  Up: 21 Multiple Processes

21.3 21-3 The Less-than-Rapid Prototype
=======================================

Processes simulated with continuations are not going to be nearly as
efficient as real operating system processes.  What's the use, then,
of programs like the one in this chapter?

   Such programs are useful in the same way that sketches are.  In
exploratory programming or rapid prototyping, the program is not an
end in itself so much as a vehicle for working out one's ideas.  In
many other fields, something which serves this purpose is called a
sketch.  An architect could, in principle, design an entire building
in his head.  However, most architects seem to think better with
pencils in their hands: the design of a building is usually worked out
in a series of preparatory sketches.

   Rapid prototyping is sketching software.  Like an architect's first
sketches, software prototypes tend to be drawn with a few sweeping
strokes.  Considerations of cost and efficiency are ignored in an
initial push to develop an idea to the full.  The result, at this
stage, is likely to be an unbuildable building or a hopelessly
inefficient piece of software.  But the sketches are valuable all the
same, because

  1. They convey information briefly.
  2. They offer a chance to experiment.

   The program described in this chapter is, like those in succeeding
chapters, a sketch.  It suggests the outlines of multiprocessing in a
few, broad strokes.  And though it would not be efficient enough for
use in production software, it could be quite useful for experimenting
with other aspects of multiple processes, like scheduling algorithms.

   Chapters 2224 present other applications of continuations.  None of
them is efficient enough for use in production software.  Because Lisp
and rapid proto- typing evolved together, Lisp includes a lot of
features specifically intended for prototypes: inefficient but
convenient features like property lists, keyword param- eters, and,
for that matter, lists.  Continuations probably belong in this
category.  They save more state than a program is likely to need.  So
our continuation-based implementation of Prolog, for example, is a
good way to understand the language, but an inefficient way to
implement it.

   This book is concerned more with the kinds of abstractions one can
build in Lisp than with efficiency issues.  It's important to realize,
though, that Lisp is a language for writing production software as
well as a language for writing prototypes.  If Lisp has a reputation
for slowness, it is largely because so many programmers stop with the
prototype.  It is easy to write fast programs in Lisp.  Unfortunately,
it is very easy to write slow ones.  The initial version of a Lisp
program can be like a diamond: small, clear, and very expensive.
There may be a great temptation to leave it that way.

   In other languages, once you succeed in the arduous task of getting
your program to work, it may already be acceptably efficient.  If you
tile a floor with tiles the size of your thumbnail, you don't waste
many.  Someone used to developing software on this principle may find
it difficult to overcome the idea that when a program works, it's
finished.  "In Lisp you can write programs in no time at all," he may
think, "but boy, are they slow."  In fact, neither is the case.  You
can get fast programs, but you have to work for them.  In this
respect, using Lisp is like living in a rich country instead of a poor
one: it may seem unfortunate that one has to work to stay thin, but
surely this is better than working to stay alive, and being thin as a
matter of course.

   In less abstract languages, you work for functionality.  In Lisp
you work for speed.  Fortunately, working for speed is easier: most
programs only have a few critical sections in which speed matters.


File: onlisp.info,  Node: 22 Nondeterminism,  Next: 23 Parsing with ATNs,  Prev: 21 Multiple Processes,  Up: Top

22 22 Nondeterminism
********************

Programming languages save us from being swamped by a mass of detail.
Lisp is a good language because it handles so many details itself,
enabling programmers to make the most of their limited tolerance for
complexity.  This chapter describes how macros can make Lisp handle
another important class of details: the details of transforming a
nondeterministic algorithm into a deterministic one.

   This chapter is divided into five parts.  The first explains what
nondeterminism is.  The second describes a Scheme implementation of
nondeterministic choose and fail which uses continuations.  The third
part presents Common Lisp versions of choose and fail which build upon
the continuation-passing macros of Chapter 20.  The fourth part shows
how the cut operator can be understood independently of Prolog.  The
final part suggests refinements of the original nondeterministic
operators.

   The nondeterministic choice operators defined in this chapter will
be used to write an ATN compiler in Chapter 23 and an embedded Prolog
in Chapter 24.

* Menu:

* 22-1 The Concept::            
* 22-2 Search::                 
* 22-3 Scheme Implementation::  
* 22-4 Common Lisp Implementation::  
* 22-5 Cuts::                   
* 22-6 True Nondeterminism::    


File: onlisp.info,  Node: 22-1 The Concept,  Next: 22-2 Search,  Prev: 22 Nondeterminism,  Up: 22 Nondeterminism

22.1 22-1 The Concept
=====================

A nondeterministic algorithm is one which relies on a certain sort of
supernatural foresight.  Why talk about such algorithms when we don't
have access to computers with supernatural powers?  Because a
nondeterministic algorithm can be simulated by a deterministic one.
For purely functional programs-that is, those with no
side-effects-simulating nondeterminism is particularly
straightforward.  In purely functional programs, nondeterminism can be
implemented by search with backtracking.

   This chapter shows how to simulate nondeterminism in functional
programs.  If we have a simulator for nondeterminism, we can expect it
to produce results whenever a truly nondeterministic machine would.
In many cases, writing a program which depends on supernatural insight
to solve a problem is easier than writing one which doesn't, so such a
simulator would be a good thing to have.

   In this section we will define the class of powers that
nondeterminism allows us; the next section demonstrates their utility
in some sample programs.  The examples in these first two sections are
written in Scheme.  (Some differences between Scheme and Common Lisp
are summarized on page 259.)

   A nondeterministic algorithm differs from a deterministic one
because it can use the two special operators choose and fail.  Choose
is a function which takes a finite set and returns one element.  To
explain how choose chooses, we must first introduce the concept of a
computational future.

   Here we will represent choose as a function choose which takes a
list and returns one element.  For each element, there is a set of
futures the computation could have if that element were chosen.  In
the following expression

     (let ((x (choose '(1 2 3))))
       (if (odd? x)
              (+ x 1)
              x))

there are three possible futures for the computation when it reaches
the point of the choose:

  1. If choose returns 1, the computation will go through the
     then-clause of the if, and will return 2.

  2. If choose returns 2, the computation will go through the
     else-clause of the if, and will return 2.

  3. If choose returns 3, the computation will go through the
     then-clause of the if, and will return 4.

   In this case, we know exactly what the future of the computation
will be as soon as we see what choose returns.  In the general case,
each choice is associated with a set of possible futures, because
within some futures there could be additional chooses.  For example,
with

     (let ((x (choose '(2 3))))
       (if (odd? x)
              (choose '(a b))
              x))

there are two sets of futures at the time of the first choose:

  1. If choose returns 2, the computation will go through the
     else-clause of the if, and will return 2.
  2. If choose returns 3, the computation will go through the
     then-clause of the if.  At this point, the path of the
     computation splits into two possible futures, one in which a is
     returned, and one in which b is.

   The first set has one future and the second set has two, so the
computation has three possible futures.

   The point to remember is, if choose is given a choice of several
alternatives, each one is associated with a set of possible futures.
Which choice will it return?  We can assume that choose works as
follows:

  1. It will only return a choice for which some future does not
     contain a call to fail.
  2. A choose over zero alternatives is equivalent to a fail.

   So, for example, in

     (let ((x (choose '(1 2))))
       (if (odd? x)
                (fail)
                x))

each of the possible choices has exactly one future.  Since the future
for a choice of 1 contains a call to fail, only 2 can be chosen.  So
the expression as a whole is deterministic: it always returns 2.

   However, the following expression is not deterministic:

     (let ((x (choose '(1 2))))
       (if (odd? x)
                (let ((y (choose '(a b))))
                       (if (eq? y 'a)
                          (fail)
                          y))
                x))

   At the first choose, there are two possible futures for a choice of
1, and one for a choice of 2.  Within the former, though, the future
is really deterministic, because a choice of a would result in a call
to fail.  So the expression as a whole could return either b or 2.

   Finally, there is only one possible value for the expression

     (let ((x (choose '(1 2))))
       (if (odd? x)
                (choose '())
                x))

   because if 1 is chosen, the future goes through a choose with no
choices.  This example is thus equivalent to the last but one.

   It may not be clear yet from the preceding examples, but we have
just got ourselves an abstraction of astounding power.  In
nondeterministic algorithms we are allowed to say "choose an element
such that nothing we do later will result in a call to fail."  For
example, this is a perfectly legitimate nondeterministic algorithm for
discovering whether you have a known ancestor called Igor:

     Function Ig(n)
       if name(n) = `Igor'
             then return n
       else if parents(n)
             then return Ig(choose(parents(n)))
       else fail

   The fail operator is used to influence the value returned by
choose.If we ever encounter a fail, choose would have chosen
incorrectly.  By definition choose guesses correctly.  So if we want
to guarantee that the computation will never pursue a certain path,
all we need do is put a fail somewhere in it, and that path will never
be followed.  Thus, as it works recursively through generations of
ancestors, the function Ig is able to choose at each step a path which
leads to an Igor-to guess whether to follow the mother's or father's
line.

   It is as if a program can specify that choose pick some element
from a set of alternatives, use the value returned by choose for as
long as it wants, and then retroactively decide, by using fail as a
veto, what it wants choose to have picked.  And, presto, it turns out
that that's just what choose did return.  Hence the model in which
choose has foresight.

   In reality choose cannot have supernatural powers.  Any
implementation of choose must simulate correct guessing by
backtracking when it discovers mistakes, like a rat finding its way
through a maze.  But all this backtracking can be done beneath the
surface.  Once you have some form of choose and fail, you get to write
algorithms like the one above, as if it really were possible to guess
what ancestor to follow.  By using choose it is possible to write an
algorithm to search some problem space just by writing an algorithm to
traverse it.

      (define (descent n1 n2)
            (if (eq? n1 n2)
                  (list n2)
                  (let ((p (try-paths (kids n1) n2)))
                        (if p (cons n1 p) #f))))

      (define (try-paths ns n2)
            (if (null? ns)
                  #f
                  (or (descent (car ns) n2)
                         (try-paths (cdr ns) n2))))

                              Figure 22-1: Deterministic tree search.


      (define (descent n1 n2)
            (cond ((eq? n1 n2) (list n2))
                        ((null? (kids n1)) (fail))
                        (else (cons n1 (descent (choose (kids n1)) n2)))))

   Figure 22-2: Nondeterministic tree search.


File: onlisp.info,  Node: 22-2 Search,  Next: 22-3 Scheme Implementation,  Prev: 22-1 The Concept,  Up: 22 Nondeterminism

22.2 22-2 Search
================

Many classic problems can be formulated as search problems, and for
such prob- lems nondeterminism often turns out to be a useful
abstraction.  Suppose nodes is bound to a list of nodes in a tree, and
(kids n) is a function which returns the descendants of node n,or#f if
there are none.  We want to write a function (descent n1 n2) which
returns a list of nodes on some path from n1 to its de- scendant n2,
if there is one.  Figure 22-1 shows a deterministic version of this
function.

   Nondeterminism allows the programmer to ignore the details of
finding a path.  It's possible simply to tell choose to find a node n
such that there is a path from n to our destination.  Using
nondeterminism we can write the simpler version of descent shown in
Figure 22-2.

   The version shown in Figure 22-2 does not explicitly search for a
node on the right path.  It is written on the assumption that choose
has chosen an n with the desired properties.  If we are used to
looking at deterministic programs, we may not perceive that choose has
to work as if it could guess what n would make it

      (define (two-numbers)
          (list (choose '(012345))
                   (choose '(012345))))

      (define (parlor-trick sum)
          (let ((nums (two-numbers)))
             (if (= (apply + nums) sum)
                   `(the sum of ,@nums)
                   (fail))))

   Figure 22-3: Choice in a subroutine.

through the computation which follows without failing.

   Perhaps a more convincing example of the power of choose is its
ability to guess what will happen even in calling functions.  Figure
22-3 contains a pair of functions to guess two numbers which sum to a
number given by the caller.  The first function, two-numbers,
nondeterministically chooses two numbers and returns them in a list.
When we call parlor-trick, it calls two-numbers for a list of two
integers.  Note that, in making its choice, two-numbers doesn't have
access to the number entered by the user.

   If the two numbers guessed by choose don't sum to the number
entered by the user, the computation fails.  We can rely on choose
having avoided computational paths which fail, if there are any which
don't.  Thus we can assume that if the caller gives a number in the
right range, choose will have guessed right, as indeed it does:(1)

     > (parlor-trick 7)
     (THE SUM OF 2 5)

   In simple searches, the built-in Common Lisp function find-if would
do just as well.  Where is the advantage of nondeterministic choice?
Why not just iterate through the list of alternatives in search of the
element with the desired properties?  The crucial difference between
choose and conventional iteration is that its extent with respect to
fails is unbounded.  Nondeterministic choose can see arbitrarily far
into the future; if something is going to happen at any point in the
future which would have invalidated some guess choose might make, we
can assume that choose knows to avoid guessing it.  As we saw in
parlor-trick, the fail operator works even after we return from the
function in which the choose occurs.

   This kind of failure happens in the search done by Prolog, for
example.  Nondeterminism is useful in Prolog because one of the
central features of this language is its ability to return answers to
a query one at a time.  By following this course instead of returning
all the valid answers at once, Prolog can handle recursive rules which
would otherwise yield infinitely large sets of answers.

   The initial reaction to descent may be like the initial reaction to
a merge sort: where does the work get done?  As in a merge sort, the
work gets done implicitly, but it does get done.  Section 22-3
describes an implementation of choose in which all the code examples
presented so far are real running programs.

   These examples show the value of nondeterminism as an abstraction.
The best programming language abstractions save not just typing, but
thought.  In automata theory, some proofs are difficult even to
conceive of without relying on nonde- terminism.  A language which
allows nondeterminism may give programmers a similar advantage.

   ---------- Footnotes ----------

   (1) Since the order of argument evaluation is unspecified in Scheme
(as opposed to Common Lisp, which specifies left-to-right), this call
might also return (THE SUM OF 5 2).


File: onlisp.info,  Node: 22-3 Scheme Implementation,  Next: 22-4 Common Lisp Implementation,  Prev: 22-2 Search,  Up: 22 Nondeterminism

22.3 22-3 Scheme Implementation
===============================

This section explains how to use continuations to simulate
nondeterminism.  Figure 22-4 contains Scheme implementations of choose
and fail.  Beneath the surface, choose and fail simulate
nondeterminism by backtracking.  A backtracking search program must
somehow store enough information to pursue other alterna- tives if the
chosen one fails.  This information is stored in the form of
continuations on the global list *paths*.

   The function choose is passed a list of alternatives in
choices.Ifchoices is empty, then choose calls fail, which sends the
computation back to the previous choose.If choices is (first .  rest),
choose first pushes onto *paths* a continuation in which choose is
called on rest, then returns first.

   The function fail is simpler: it just pops a continuation off
*paths* and calls it.  If there aren't any saved paths left, then fail
returns the symbol .  However, it won't do simply to return it as a
function ordinarily returns values, or it will be returned as the
value of the most recent choose.  What we really want to do is return
 right to the toplevel.  We do this by binding cc to the continuation
where fail is defined, which presumably is the toplevel.  By calling
cc, fail can return straight there.

   The implementation in Figure 22-4 treats *paths* as a stack, always
fail- ing back to the most recent choice point.  This strategy, known
as chronological backtracking, results in depth-first search of the
problem space.  The word "non- determinism" is often used as if it
were synonymous with the depth-first imple-

      (define *paths* ())
      (define failsym '@)

      (define (choose choices)
         (if (null? choices)
              (fail)
              (call-with-current-continuation
                 (lambda (cc)
                    (set! *paths*
                            (cons (lambda ()
                                       (cc (choose (cdr choices))))
                                    *paths*))
                 (car choices)))))

      (define fail)

      (call-with-current-continuation
         (lambda (cc)
             (set! fail
                    (lambda ()
                      (if (null? *paths*)
                            (cc failsym)
                            (let ((p1 (car *paths*)))
                              (set! *paths* (cdr *paths*))
                              (p1)))))))

   Figure 22-4: Scheme implementation of choose and fail.

mentation.  Floyd's classic paper on nondeterministic algorithms uses
the term in this sense, and this is also the kind of nondeterminism we
find in nondetermin- istic parsers and in Prolog.  However, it should
be noted that the implementation given in Figure 22-4 is not the only
possible implementation, nor even a correct one.  In principle, choose
ought to be able to choose an object which meets any computable
specification.  But a program which used these versions of choose and
fail to search a graph might not terminate, if the graph contained
cycles.

   In practice, nondeterminism usually means using a depth-first
implementation equivalent to the one in Figure 22-4, and leaving it to
the user to avoid loops in the search space.  However, for readers who
are interested, the last section in this chapter describes how to
implement true choose and fail.


File: onlisp.info,  Node: 22-4 Common Lisp Implementation,  Next: 22-5 Cuts,  Prev: 22-3 Scheme Implementation,  Up: 22 Nondeterminism

22.4 22-4 Common Lisp Implementation
====================================

This section describes how to write a form of choose and fail in
Common Lisp.  As the previous section showed, call/cc makes it easy to
simulate nondetermin- ism in Scheme.  Continuations provide the direct
embodiment of our theoretical concept of a computational future.  In
Common Lisp, we can use instead the continuation-passing macros of
Chapter 20.  With these macros we will be able to provide a form of
choose slightly uglier than the Scheme version presented in the
previous section, but equivalent in practice.

   Figure 22-5 contains a Common Lisp implementation of fail, and two
versions of choose.  The syntax of a Common Lisp choose is slightly
different from the Scheme version.  The Scheme choose took one
argument: a list of choices from which to select a value.  The Common
Lisp version has the syntax of a progn.  It can be followed by any
number of expressions, from which it chooses one to evaluate:

     > (defun do2 (x)
             (choose (+ x 2) (* x 2) (expt x 2)))
     DO2
     > (do2 3)
     5> (fail)
     6
   At the toplevel, we see more clearly the backtracking which
underlies nondeter- ministic search.  The variable *paths* is used to
store paths which have not yet been followed.  When the computation
reaches a choose expression with several alternatives, the first
alternative is evaluated, and the remaining choices are stored on
*paths*.  If the program later on encounters a fail, the last stored
choice will be popped off *paths* and restarted.  When there are no
more paths left to restart, fail returns a special value:

     > (fail)
     9> (fail)
 

   In Figure 22-5 the constant failsym, which represents failure, is
defined to be the symbol .  If you wanted to be able to have  as an
ordinary return value, you could make failsym a gensym instead.

   The other nondeterministic choice operator, choose-bind, has a
slightly different form.  It should be given a symbol, a list of
choices, and a body of code.  It will do a choose on the list of
choices, bind the symbol to the value chosen, and evaluate the body of
code:

      (defparameter *paths* nil)
      (defconstant failsym '@)

      (defmacro choose (&rest choices)
         (if choices
                `(progn
                   ,@(mapcar #'(lambda (c)
                                    `(push #'(lambda () ,c) *paths*))
                               (reverse (cdr choices)))
                   ,(car choices))
                '(fail)))

      (defmacro choose-bind (var choices &body body)
         `(cb #'(lambda (,var) ,@body) ,choices))

      (defun cb (fn choices)
         (if choices
               (progn
                 (if (cdr choices)
                     (push #'(lambda () (cb fn (cdr choices)))
                             *paths*))
                 (funcall fn (car choices)))
               (fail)))

      (defun fail ()
         (if *paths*
                (funcall (pop *paths*))
                failsym))

   Figure 22-5: Nondeterministic operators in Common Lisp.

     > (choose-bind x '(marrakesh strasbourg vegas)
             (format nil "Let's go to ~A." x))
     "Let's go to MARRAKESH."
     > (fail)
     "Let's go to STRASBOURG."

   It is only for convenience that the Common Lisp implementation
provides two choice operators.  You could get the effect of choose
from choose-bind by always translating

     (choose (foo) (bar))

into

     (choose-bind x '(1 2)
        (case x
             (1 (foo))
             (2 (bar))))

but programs are easier to read if we have a separate operator for
this case.(1)

   The Common Lisp choice operators store the bindings of relevant
variables using closures and variable capture.  As macros, choose and
choose-bind get expanded within the lexical environment of the
containing expressions.  Notice that what they push onto *paths* is a
closure over the choice to be saved, locking in all the bindings of
the lexical variables referred to within it.  For example, in the
expression

     (let ((x 2))
        (choose
             (+x1)
             (+ x 100)))

the value of x will be needed when the saved choices are restarted.
This is why choose is written to wrap its arguments in
lambda-expressions.  The expression above gets macroexpanded into:

     (let ((x 2))
        (progn
             (push #'(lambda () (+ x 100))
                     *paths*)
             (+ x 1)))

   The object which gets stored on *paths* is a closure containing a
pointer to x.It is the need to preserve variables in closures which
dictates the difference between the syntax of the Scheme and Common
Lisp choice operators.

   If we use choose and fail together with the continuation-passing
macros of Chapter 20, a pointer to our continuation variable *cont*
will get saved as well.  By defining functions with =defun, calling
them with =bind, and having them return values with =values, we will
be able to use nondeterminism in any Common Lisp program.

   With these macros, we can successfully run the example in which the
nonde- terministic choice occurs in a subroutine.  Figure 22-6 shows
the Common Lisp version of parlor-trick, which works as it did in
Scheme:

      (=defun two-numbers ()
         (choose-bind n1 '(012345)
              (choose-bind n2 '(0 12345)
                (=values n1 n2))))

      (=defun parlor-trick (sum)
         (=bind (n1 n2) (two-numbers)
              (if (= (+ n1 n2) sum)
                  `(the sum of ,n1 ,n2)
                  (fail))))

   Figure 22-6: Common Lisp choice in a subroutine.

     > (parlor-trick 7)
     (THE SUM OF 2 5)

   This works because the expression

     (=values n1 n2)

gets macroexpanded into

     (funcall *cont* n1 n2)

within the choose-binds.  Each choose-bind is in turn macroexpanded
into a closure, which keeps pointers to all the variables referred to
in the body, including *cont*.

   The restrictions on the use of choose, choose-bind, and fail are
the same as the restrictions given in Figure 20-5 for code which uses
the continuation- passing macros.  Where a choice expression occurs,
it must be the last thing to be evaluated.  Thus if we want to make
sequential choices, in Common Lisp the choices have to be nested:

     > (choose-bind first-name '(henry william)
             (choose-bind last-name '(james higgins)
               (=values (list first-name last-name))))
     (HENRY JAMES)
     > (fail)
     (HENRY HIGGINS)
     > (fail)
     (WILLIAM JAMES)

which will, as usual, result in depth-first search.

   The operators defined in Chapter 20 claimed the right to be the
last expressions evaluated.  This right is now preempted by the new
layer of macros; an =values expression should appear within a choose
expression, and not vice versa.  That is,

     (choose (=values 1) (=values 2))

will work, but

     (=values (choose 1 2))                                                      ; wrong

will not.  (In the latter case, the expansion of the choose would be
unable to capture the instance of *cont* in the expansion of the
=values.)

   As long as we respect the restrictions outlined here and in Figure
20-5, non- deterministic choice in Common Lisp will now work as it
does in Scheme.  Fig- ure 22-7 shows a Common Lisp version of the
nondeterministic tree search pro- gram given in Figure 22-2.  The
Common Lisp descent is a direct translation, though it comes out
slightly longer and uglier.

   We now have Common Lisp utilities which make it possible to do
nondeter- ministic search without explicit backtracking.  Having taken
trouble to write this code, we can reap the benefits by writing in
very few lines programs which would otherwise be large and messy.  By
building another layer of macros on top of those presented here, we
will be able to write an ATN compiler in one page of code (Chapter
23), and a sketch of Prolog in two (Chapter 24).

   Common Lisp programs which use choose should be compiled with tail-
recursion optimization-not just to make them faster, but to avoid
running out of stack space.  Programs which "return" values by calling
continuation functions never actually return until the final fail.
Without the optimization of tail-calls, the stack would just grow and
grow.

   ---------- Footnotes ----------

   (1) If desired, the exported interface to this code could consist
of just a single operator, because (fail) is equivalent to (choose).


File: onlisp.info,  Node: 22-5 Cuts,  Next: 22-6 True Nondeterminism,  Prev: 22-4 Common Lisp Implementation,  Up: 22 Nondeterminism

22.5 22-5 Cuts
==============

This section shows how to use cuts in Scheme programs which do
nondetermin- istic choice.  Though the word cut comes from Prolog, the
concept belongs to nondeterminism generally.  You might want to use
cuts in any program that made nondeterministic choices.

   Cuts are easier to understand when considered independently of
Prolog.  Let's imagine a real-life example.  Suppose that the
manufacturer of Chocoblob candies decides to run a promotion.  A small
number of boxes of Chocoblobs will also contain tokens entitling the
recipient to valuable prizes.  To ensure fairness, no two of the
winning boxes are sent to the same city.

      > (=defun descent (n1 n2)
             (cond ((eq n1 n2) (=values (list n2)))
                     ((kids n1) (choose-bind n (kids n1)
                                       (=bind (p) (descent n n2)
                                           (=values (cons n1 p)))))
                     (t (fail))))
      DESCENT
      > (defun kids (n)
             (case n
                (a '(b c))
                (b '(d e))
                (c '(d f))
                (f '(g))))
      KIDS
      > (descent 'a 'g)
      (ACFG)
      > (fail)
      @> (descent 'a 'd)
      (ABD)
      > (fail)
      (ACD)
      > (fail)
      @> (descent 'a 'h)
  

   Figure 22-7: Nondeterministic search in Common Lisp

   After the promotion has begun, it emerges that the tokens are small
enough to be swallowed by children.  Hounded by visions of lawsuits,
Chocoblob lawyers begin a frantic search for all the special boxes.
Within each city, there are multiple stores that sell Chocoblobs;
within each store, there are multiple boxes.  But the lawyers may not
have to open every box: once they find a coin-containing box in a
given city, they do not have to search any of the other boxes in that
city, because each city has at most one special box.  To realize this
is to do a cut.

   What's cut is a portion of the search tree.  For Chocoblobs, the
search tree exists physically: the root node is at the company's head
office; the children of this node are the cities where the special
boxes were sent; the children of those nodes are the stores in each
city; and the children of each store represent the boxes in

          (define (find-boxes)
            (set! *paths* ())
            (let ((city (choose '(la ny bos))))
              (newline)
              (let* ((store (choose '(1 2)))
                        (box (choose '(1 2))))
                 (let ((triple (list city store box)))
                    (display triple)
                    (if (coin? triple)
                         (display 'c))
                    (fail)))))

          (define (coin? x)
            (member x '((la 1 2) (ny 1 1) (bos 2 2))))

   Figure 22-8: Exhaustive Chocoblob search.

that store.  When the lawyers searching this tree find one of the
boxes containing a coin, they can prune off all the unexplored
branches descending from the city they're in now.

   Cuts actually take two operations: you can do a cut when you know
that part of the search tree is useless, but first you have to mark
the tree at the point where it can be cut.  In the Chocoblob example,
common sense tells us that the tree is marked as we enter each city.
It's hard to describe in abstract terms what a Prolog cut does,
because the marks are implicit.  With an explicit mark operator, the
effect of a cut will be more easily understood.

   Figure 22-8 shows a program that nondeterministically searches a
smaller version of the Chocoblob tree.  As each box is opened, the
program displays a list of (city store box).  If the box contains a
coin, a c is printed after it:

     > (find-boxes)
     (LA 1 1)(LA 1 2)C(LA 2 1)(LA 2 2)
     (NY 1 1)C(NY 1 2)(NY 2 1)(NY 2 2)
     (BOS 1 1)(BOS 1 2)(BOS 2 1)(BOS 2 2)C
 

   To implement the optimized search technique discovered by the
Chocoblob lawyers, we need two new operators: mark and cut.  Figure
22-9 shows one way to define them.  Whereas nondeterminism itself can
be understood independently of any particular implementation, pruning
the search tree is an optimization tech- nique, and depends very much
on how choose is implemented.  The mark and

      (define (mark) (set! *paths* (cons fail *paths*)))

      (define (cut)
         (cond ((null? *paths*))
                  ((equal? (car *paths*) fail)
                    (set! *paths* (cdr *paths*)))
                  (else
                    (set! *paths* (cdr *paths*))
                    (cut))))

   Figure 22-9: Marking and pruning search trees.

      (define (find-boxes)
         (set! *paths* ())
         (let ((city (choose '(la ny bos))))
             (mark)                                                                    ;
             (newline)
             (let* ((store (choose '(1 2)))
                       (box (choose '(1 2))))
               (let ((triple (list city store box)))
                  (display triple)
                  (if (coin? triple)
                        (begin (cut) (display 'c)))                                    ;
                  (fail)))))

   Figure 22-10: Pruned Chocoblob search.

cut defined in Figure 22-9 are suitable for use with the depth-first
implementation of choose (Figure 22-4).

   The general idea is for mark to store markers in *paths*,the list
of unexplored choice-points.  Calling cut pops *paths* all the way
down to the most recent marker.  What should we use as a marker?  We
could use e.g.  the symbol m,but that would require us to rewrite fail
to ignore the ms when it encountered them.  Fortunately, since
functions are data objects too, there is at least one marker that will
allow us to use fail as is: the function fail itself.  Then if fail
happens on a marker, it will just call itself.

   Figure 22-10 shows how these operators would be used to prune the
search tree in the Chocoblob case.  (Changed lines are indicated by
semicolons.)  We call mark upon choosing a city.  At this point,
*paths* contains one continuation,

   Figure 22-11: A directed graph with a loop.

representing the search of the remaining cities.

   If we find a box with a coin in it, we call cut, which sets *paths*
back to the value it had at the time of the mark.  The effects of the
cut are not visible until the next call to fail.  But when it comes,
after the display, the next fail sends the search all the way up to
the topmost choose, even if there would otherwise have been live
choice-points lower in the search tree.  The upshot is, as soon as we
find a box with a coin in it, we resume the search at the next city:

     > (find-boxes)
     (LA 1 1)(LA 1 2)C
     (NY 1 1)C
     (BOS 1 1)(BOS 1 2)(BOS 2 1)(BOS 2 2)C
 

   In this case, we open seven boxes instead of twelve.

