This is onlisp.info, produced by makeinfo version 6.3 from onlisp.texi.

INFO-DIR-SECTION Common LISP
START-INFO-DIR-ENTRY
* On Lisp: (onlisp).                *On Lisp* by Paul Graham.
END-INFO-DIR-ENTRY


File: onlisp.info,  Node: 22-6 True Nondeterminism,  Prev: 22-5 Cuts,  Up: 22 Nondeterminism

22.6 22-6 True Nondeterminism
=============================

A deterministic graph-searching program would have to take explicit
steps to avoid getting caught in a circular path.  Figure 22-11 shows
a directed graph containing a loop.  A program searching for a path
from node a to node e risks getting caught in the circular path a, b,
c .  Unless a deterministic searcher used randomization, breadth-first
search, or checked explicitly for circular paths, the search might
never terminate.  The implementation of path shown in Figure 22-12
avoids circular paths by searching breadth-first.

   In principle, nondeterminism should save us the trouble of even
considering circular paths.  The depth-first implementation of choose
and fail given in Sec- tion 22-3 is vulnerable to the problem of
circular paths, but if we were being picky, we would expect
nondeterministic choose to be able to select an object

      (define (path node1 node2)
         (bf-path node2 (list (list node1))))

      (define (bf-path dest queue)
         (if (null? queue)
              '          (let* ((path (car queue))
                        (node (car path)))
                 (if (eq? node dest)
                       (cdr (reverse path))
                       (bf-path dest
                                  (append (cdr queue)
                                                (map (lambda (n)
                                                      (cons n path))
                                                    (neighbors node))))))))

   Figure 22-12: Deterministic search.

      (define (path node1 node2)
         (cond ((null? (neighbors node1)) (fail))
                    ((memq node2 (neighbors node1)) (list node2))
                    (else (let ((n (true-choose (neighbors node1))))
                           (cons n (path n node2))))))

   Figure 22-13: Nondeterministic search.

   which meets any computable specification, and this case is no
exception.  Using a correct choose, we should be able to write the
shorter and clearer version of path shown in Figure 22-13.

   This section shows how to implement versions choose and fail which
are safe even from circular paths.  Figure 22-14 contains a Scheme
implementation of true nondeterministic choose and fail.  Programs
which use these versions of choose and fail should find solutions
whenever the equivalent nondeterministic algorithms would, subject to
hardware limitations.

   The implementation of true-choose defined in Figure 22-14 works by
treat- ing the list of stored paths as a queue.  Programs using
true-choose will search their state-space breadth-first.  When the
program reaches a choice-point, contin- uations to follow each choice
are appended to the end of the list of stored paths.

      (define *paths* ())
      (define failsym '@)

      (define (true-choose choices)
            (call-with-current-continuation
              (lambda (cc)
                 (set! *paths* (append *paths*
                                              (map (lambda (choice)
                                                       (lambda () (cc choice)))
                                                     choices)))
                 (fail))))

      (define fail)

      (call-with-current-continuation
            (lambda (cc)
              (set! fail
                      (lambda ()
                         (if (null? *paths*)
                              (cc failsym)
                              (let ((p1 (car *paths*)))
                                 (set! *paths* (cdr *paths*))
                                 (p1)))))))

   Figure 22-14: Correct choose in Scheme.

   (Scheme's map returns the same values as Common Lisp's mapcar.)
After this there is a call to fail, which is unchanged.

   This version of choose would allow the implementation of path
defined in Figure 22-13 to find a path-indeed, the shortest path-from
a to e in the graph displayed in Figure 22-11.

   Although for the sake of completeness this chapter has provided
correct ver- sions of choose and fail, the original implementations
will usually suffice.  The value of a programming language abstraction
is not diminished just because its implementation isn't formally
correct.  In some languages we act as if we had access to all the
integers, even though the largest one may be only 32767.  As long as
we know how far we can push the illusion, there is little danger to
it- little enough, at least, to make the abstraction a bargain.  The
conciseness of the programs presented in the next two chapters is due
largely to their use of nondeterministic choose and fail.


File: onlisp.info,  Node: 23 Parsing with ATNs,  Next: 24 Prolog,  Prev: 22 Nondeterminism,  Up: Top

23 23 Parsing with ATNs
***********************

This chapter shows how to write a nondeterministic parser as an
embedded lan- guage.  The first part explains what ATN parsers are,
and how they represent grammar rules.  The second part presents an ATN
compiler which uses the nonde- terministic operators defined in the
previous chapter.  The final sections present a small ATN grammar, and
show it in action parsing sample input.

* Menu:

* 23-1 Background::             
* 23-2 The Formalism::          
* 23-3 Nondeterminism::         
* 23-4 An ATN Compiler::        
* 23-5 A Sample ATN::           


File: onlisp.info,  Node: 23-1 Background,  Next: 23-2 The Formalism,  Prev: 23 Parsing with ATNs,  Up: 23 Parsing with ATNs

23.1 23-1 Background
====================

Augmented Transition Networks, or ATNs, are a form of parser described
by Bill Woods in 1970.  Since then they have become a widely used
formalism for parsing natural language.  In an hour you can write an
ATN grammar which parses interesting English sentences.  For this
reason, people are often held in a sort of spell when they first
encounter them.

   In the 1970s, some people thought that ATNs might one day be
components of truly intelligent-seeming programs.  Though few hold
this position today, ATNs have found a niche.  They aren't as good as
you are at parsing English, but they can still parse an impressive
variety of sentences.

   ATNs are useful if you observe the following four restrictions:

  1. Use them in a semantically limited domain-in a front-end to a
     particular database, for example.
  2. Don't feed them very difficult input.  Among other things, don't
     expect them to understand wildly ungrammatical sentences the way
     people can.
  3. Only use them for English, or other languages in which word order
     deter- mines grammatical structure.  ATNs would not be useful in
     parsing inflected languages like Latin.
  4. Don't expect them to work all the time.  Use them in applications
     where it's helpful if they work ninety percent of the time, not
     those where it's critical that they work a hundred percent of the
     time.

   Within these limits there are plenty of useful applications.  The
canonical example is as the front-end of a database.  If you attach an
ATN-driven interface to such a system, then instead of making a formal
query, users can ask questions in a constrained form of English.


File: onlisp.info,  Node: 23-2 The Formalism,  Next: 23-3 Nondeterminism,  Prev: 23-1 Background,  Up: 23 Parsing with ATNs

23.2 23-2 The Formalism
=======================

To understand what ATNs do, we should recall their full name:
augmented transi- tion networks.  A transition network is a set of
nodes joined together by directed arcs-essentially, a flow-chart.  One
node is designated the start node, and some other nodes are designated
terminal nodes.  Conditions are attached to each arc, which have to be
met before the arc can be followed.  There will be an input sentence,
with a pointer to the current word.  Following some arcs will cause
the pointer to be advanced.  To parse a sentence on a transition
network is to find a path from the start node to some terminal node,
along which all the conditions can be met.

   ATNs add two features to this model:

  1. ATNs have registers-named slots for storing away information as
     the parse proceeds.  As well as performing tests, arcs can modify
     the contents of the registers.
  2. ATNs are recursive.  Arcs may require that, in order to follow
     them, the parse must successfully make it through some
     sub-network.

   Terminal nodes use the information which has accumulated in the
registers to build list structures, which they return in much the same
way that functions return values.  In fact, with the exception of
being nondeterministic, ATNs behave a lot like a functional
programming language.

   The ATN defined in Figure 23-1 is nearly the simplest possible.  It
parses noun- verb sentences of the form "Spot runs."  The network
representation of this ATN is shown in Figure 23-2.

   What does this ATN do when given the input (spot runs)?  The first
node has one outgoing arc, a cat, or category arc, leading to node s2.
It says, effectively,

      (defnode s
         (cat noun s2
             (setr subj *)))

      (defnode s2
         (cat verb s3
             (setr v *)))

      (defnode s3
         (up `(sentence
                   (subject ,(getr subj))
                   (verb ,(getr v)))))

   Figure 23-1: A very small ATN.

   Figure 23-2: Graph of a small ATN.

you can follow me if the current word is a noun, and if you do, you
must store the current word (indicated by *)inthesubj register.  So we
leave this node with spot stored in the subj register.

   There is always a pointer to the current word.  Initially it points
to the first word in the sentence.  When cat arcs are followed, this
pointer is moved forward one.  So when we get to node s2, the current
word is the second, runs.  The second arc is just like the first,
except that it is looking for a verb.  It finds runs, stores it in
register v, and proceeds to s3.

   The final node, s3, has only a pop, or terminal, arc.  (Nodes with
pop arcs have dashed borders.)  Because we arrive at the pop arc just
as we run out of input, we have a successful parse.  The pop arc
returns the backquoted expression within it:

     (sentence (subject spot)
                   (verb runs))

   An ATN corresponds to the grammar of the language it is designed to
parse.  A decent-sized ATN for parsing English will have a main
network for parsing sentences, and sub-networks for parsing
noun-phrases, prepositional phrases, modi- fier groups, and so on.
The need for recursion is obvious when we consider that noun-phrases
may contain prepositional phrases which may contain noun-phrases, ad
infinitum, as in

     "the key on the table in the hall of the house on the hill"


File: onlisp.info,  Node: 23-3 Nondeterminism,  Next: 23-4 An ATN Compiler,  Prev: 23-2 The Formalism,  Up: 23 Parsing with ATNs

23.3 23-3 Nondeterminism
========================

Although we didn't see it in this small example, ATNs are
nondeterministic.  A node can have several outgoing arcs, more than
one of which could be followed with a given input.  For example, a
reasonably good ATN should be able to parse both imperative and
declarative sentences.  Thus the first node could have outgoing cat
arcs for both nouns (in statements) and verbs (in commands).

   What if the first word of the sentence is "time," which is both a
noun and a verb?  How does the parser know which arc to follow?  When
ATNs are described as nondeterministic, it means that users can assume
that the parser will correctly guess which arc to follow.  If some
arcs lead only to failed parses, they won't be followed.

   In reality the parser cannot look into the future.  It simulates
correct guessing by backtracking when it runs out of arcs, or input.
But all the machinery of backtracking is inserted automatically into
the code generated by the ATN compiler.  We can write ATNs as if the
parser really could guess which arcs to follow.

   Like many (perhaps most) programs which use nondeterminism, ATNs
use the depth-first implementation.  Experience parsing English
quickly teaches one that any given sentence has a slew of legal
parsings, most of them junk.  On a conventional single-processor
machine, one is better off trying to get good parses quickly.  Instead
of getting all the parses at once, we get just the most likely.  If it
has a reasonable interpretation, then we have saved the effort of
finding other parses; if not, we can call fail to get more.

   To control the order in which parses are generated, the programmer
needs to have some way of controlling the order in which choose tries
alternatives.  The depth-first implementation isn't the only way of
controlling the order of the search.  Any implementation except a
randomizing one imposes some kind of order.  How- ever, ATNs, like
Prolog, have the depth-first implementation conceptually built-in.  In
an ATN, the arcs leaving a node are tried in the order in which they
were defined.  This convention allows the programmer to order arcs by
priority.


File: onlisp.info,  Node: 23-4 An ATN Compiler,  Next: 23-5 A Sample ATN,  Prev: 23-3 Nondeterminism,  Up: 23 Parsing with ATNs

23.4 23-4 An ATN Compiler
=========================

Ordinarily, an ATN-based parser needs three components: the ATN
itself, an inter- preter for traversing it, and a dictionary which can
tell it, for example, that "runs" is a verb.  Dictionaries are a
separate topic-here we will use a rudimentary hand- made one.  Nor
will we need to deal with a network interpreter, because we will
translate the ATN directly into Lisp code.  The program described here
is called an ATN compiler because it transforms a whole ATN into code.
Nodes are transformed into functions, and arcs become blocks of code
within them.

   Chapter 6 introduced the use of functions as a form of
representation.  This practice usually makes programs faster.  Here it
means that there will be no overhead of interpreting the network at
runtime.  The disadvantage is that there is less to inspect when
something goes wrong, especially if you're using a Common Lisp
implementation which doesn't provide function-lambda-expression.

   Figure 23-3 contains all the code for transforming ATN nodes into
Lisp code.  The macro defnode is used to define nodes.  It generates
little code itself, just a choose over the expressions generated for
each of the arcs.  The two parameters of a node-function get the
following values: pos is the current input pointer (an integer), and
regs is the current set of registers (a list of assoc-lists).

   The macro defnode defines a macro with the same name as the
corresponding node.  Node s will be defined as macro s.  This
convention enables arcs to know how to refer to their destination
nodes-they just call the macro with that name.  It also means that you
shouldn't give nodes the names of existing functions or macros, or
these will be redefined.

   Debugging ATNs requires some sort of trace facility.  Because nodes
become functions, we don't have to write our own.  We can use the
built-in Lisp function trace.  As mentioned on page 266, using =defun
to define nodes means that we can trace parses going through node mods
by saying (trace =mods).

   The arcs within the body of a node are simply macro calls,returning
code which gets embedded in the node function being made by defnode.
The parser uses nondeterminism at each node by executing a choose over
the code representing each of the arcs leaving that node.  A node with
several outgoing arcs, say

     (defnode foo
       <arc 1>
       <arc 2>)

gets translated into a function definition of the following form:

     (=defun foo (pos regs)
       (choose
             <translation of arc 1>
             <translation of arc 2>))

      (defmacro defnode (name &rest arcs)
            `(=defun ,name (pos regs) (choose ,@arcs)))

      (defmacro down (sub next &rest cmds)
            `(=bind (* pos regs) (,sub pos (cons nil regs))
               (,next pos ,(compile-cmds cmds))))

      (defmacro cat (cat next &rest cmds)
            `(if (= (length *sent*) pos)
                (fail)
                (let ((* (nth pos *sent*)))
                  (if (member ',cat (types *))
                        (,next (1+ pos) ,(compile-cmds cmds))
                        (fail)))))

      (defmacro jump (next &rest cmds)
            `(,next pos ,(compile-cmds cmds)))

      (defun compile-cmds (cmds)
            (if (null cmds)
               'regs
               `(,@(car cmds) ,(compile-cmds (cdr cmds)))))

      (defmacro up (expr)
            `(let ((* (nth pos *sent*)))
               (=values ,expr pos (cdr regs))))

      (defmacro getr (key &optional (regs 'regs))
            `(let ((result (cdr (assoc ',key (car ,regs)))))
               (if (cdr result) result (car result))))

      (defmacro set-register (key val regs)
            `(cons (cons (cons ,key ,val) (car ,regs))
                  (cdr ,regs)))

      (defmacro setr (key val regs)
            `(set-register ',key (list ,val) ,regs))

      (defmacro pushr (key val regs)
            `(set-register ',key
                             (cons ,val (cdr (assoc ',key (car ,regs))))
                             ,regs))

   Figure 23-3: Compilation of nodes and arcs.

      (defnode s
         (down np s/subj
             (setr mood 'decl)
             (setr subj *))
         (cat v v
             (setr mood 'imp)
             (setr subj '(np (pron you)))
             (setr aux nil)
             (setr v *)))

is macroexpanded into:

      (=defun s (pos regs)
         (choose
             (=bind (* pos regs) (np pos (cons nil regs))
              (s/subj pos
                         (setr mood 'decl
                                 (setr subj * regs))))
             (if (= (length *sent*) pos)
                 (fail)
                 (let ((* (nth pos *sent*)))
                    (if (member 'v (types *))
                         (v (1+ pos)
                             (setr mood 'imp
                                     (setr subj '(np (pron you))
                                             (setr aux nil
                                                        (setr v * regs)))))
                         (fail))))))

   Figure 23-4: Macroexpansion of a node function.

   Figure 23-4 shows the macroexpansion of the first node in the
sample ATN of Figure 23-11.  When called at runtime, node functions
like s nondeterministically choose an arc to follow.  The parameter
pos will be the current position in the input sentence, and regs the
current registers.

   Cat arcs, as we saw in our original example, insist that the
current word of input belong to a certain grammatical category.
Within the body of a cat arc, the symbol * will be bound to the
current word of input.

   Push arcs, defined with down, require successful calls to
sub-networks.  They take two destination nodes, the sub-network
destination sub, and the next node in the current network, next.
Notice that whereas the code generated for a cat arc simply calls the
next node in the network, the code generated for a push arc uses
=bind.  The push arc must successfully return from the sub-network
before continuing on to the node which follows it.  A clean set of
registers (nil) gets consed onto the front of regs before they are
passed to the sub-network.  In the bodies of other types of arcs, the
symbol * will be bound to the current word of input, but in push arcs
it will be bound to the expression returned by the sub-network.

   Jump arcs are like short-circuits.  The parser skips right across
to the destination node-no tests are required, and the input pointer
isn't advanced.

   The final type of arc is the pop arc, defined with up.  Pop arcs
are unusual in that they don't have a destination.  Just as a Lisp
return leads not to a subroutine but the calling function, a pop arc
leads not to a new node but back to the "calling" push arc.  The
=values in a pop arc "returns" a value to the =bind in the most recent
push arc.  But, as Section 20-2 explained, what's happening is not a
normal Lisp return: the body of the =bind has been wrapped up into a
continuation and passed down as a parameter through any number of
arcs, until the =values of the pop arc finally calls it on the
"return" values.

   Chapter 22 described two versions of nondeterministic choose: a
fast choose (page 293) that wasn't guaranteed to terminate when there
were loops in the search space, and a slower true-choose (page 304)
which was safe from such loops.  There can be cycles in an ATN, of
course, but as long as at least one arc in each cycle advances the
input pointer, the parser will eventually run off the end of the
sentence.  The problem arises with cycles which don't advance the
input pointer.  Here we have two alternatives:

  1. Use the slower, correct nondeterministic choice operator (the
     depth-first version given on page 396).
  2. Use the fast choose, and specify that it is an error to define
     networks containing cycles which could be traversed by following
     just jump arcs.

   The code defined in Figure 23-3 takes the second approach.

   The last four definitions in Figure 23-3 define the macros used to
read and set registers within arc bodies.  In this program, register
sets are represented as assoc-lists.  An ATN deals not with sets of
registers, but sets of sets of registers.  When the parser moves down
to a sub-network, it gets a clean set of registers pushed on top of
the existing ones.  Thus the whole collection of registers, at any
given time, is a list of assoc-lists.

   The predefined register operators work on the current, or topmost,
set of registers: getr reads a register; setr sets one; and pushr
pushes a value into one.  Both getr and pushr use the primitive
register manipulation macro set-register.

   Note that registers don't have to be declared.  If set-register is
sent a certain name, it will create a register with that name.

   The register operators are all completely nondestructive.  Cons,
cons, cons, says set-register.  This makes them slow and generates a
lot of garbage, but, as explained on page 261, objects used in a part
of a program where continuations are made should not be destructively
modified.  An object in one thread of control may be shared by another
thread which is currently suspended.  In this case, the registers
found in one parse will share structure with the registers in many of
the other parses.  If speed became an issue, we could store registers
in vectors instead of assoc-lists, and recycle used vectors into a
common pool.

   Push, cat, and jump arcs can all contain bodies of expressions.
Ordinarily these will be just setrs.  By calling compile-cmds on their
bodies, the expansion functions of these arc types string a series of
setrs into a single expression:

     > (compile-cmds '((setr a b) (setr c d)))
     (SETR A B (SETR C D REGS))

   Each expression has the next expression inserted as its last
argument, except the last, which gets regs.  So a series of
expressions in the body of an arc will be transformed into a single
expression returning the new registers.

   This approach allows users to insert arbitrary Lisp code into the
bodies of arcs by wrapping it in a progn.  For example:

     > (compile-cmds '((setr a b)
                             (progn (princ "ek!"))
                             (setr c d)))
     (SETR A B (PROGN (PRINC "ek!") (SETR C D REGS)))

   Certain variables are left visible to code occurring in arc bodies.
The sentence will be in the global *sent*.  Two lexical variables will
also be visible: pos, containing the current input pointer, and regs,
containing the current registers.  This is another example of
intentional variable capture.  If it were desirable to prevent the
user from referring to these variables, they could be replaced with
gensyms.

   The macro with-parses,defined in Figure 23-5,gives us a way of
invoking an ATN. It should be called with the name of a start node, an
expression to be parsed, and a body of code describing what to do with
the returned parses.  The body of code within a with-parses expression
will be evaluated once for each successful parse.  Within the body,
the symbol parse will be bound to the current parse.  Superficially
with-parses resembles operators like dolist, but underneath it uses
backtracking search instead of simple iteration.  A with-parses
expression will return , because that's what fail returns when it runs
out of choices.

          (defmacro with-parses (node sent &body body)
            (with-gensyms (pos regs)
              `(progn
                   (setq *sent* ,sent)
                   (setq *paths* nil)
                   (=bind (parse ,pos ,regs) (,node 0 '(nil))
                     (if (= ,pos (length *sent*))
                          (progn ,@body (fail))
                          (fail))))))

   Figure 23-5: Toplevel macro.

   Before going on to look at a more representative ATN, let's look at
a parsing generated from the tiny ATN defined earlier.  The ATN
compiler (Figure 23-3) generates code which calls types to determine
the grammatical roles of a word, so first we have to give it some
definition:

     (defun types (w)
          (cdr (assoc w '((spot noun) (runs verb)))))

   Now we just call with-parses with the name of the start node as the
first argument:

     > (with-parses s '(spot runs)
             (format t "Parsing: ~A~%" parse))
     Parsing: (SENTENCE (SUBJECT SPOT) (VERB RUNS))
 


File: onlisp.info,  Node: 23-5 A Sample ATN,  Prev: 23-4 An ATN Compiler,  Up: 23 Parsing with ATNs

23.5 23-5 A Sample ATN
======================

Now that the whole ATN compiler has been described, we can go on to
try out some parses using a sample network.  In order to make an ATN
parser handle a richer variety of sentences, you make the ATNs
themselves more complicated, not the ATN compiler.  The compiler
presented here is a toy mainly in the sense that it's slow, not in the
sense of having limited power.

   The power (as distinct from speed) of a parser is in the grammar,
and here limited space really will force us to use a toy version.
Figures 23-8 through 23-11 define the ATN (or set of ATNs) represented
in Figure 23-6.  This network is just big enough to yield several
parsings for the classic parser fodder "Time flies like an arrow."

   Figure 23-6: Graph of a larger ATN.

      (defun types (word)
         (case word
             ((do does did) '(aux v))
             ((time times) '(n v))
             ((fly flies) '(n v))
             ((like) '(v prep))
             ((liked likes) '(v))
             ((a an the) '(det))
             ((arrow arrows) '(n))
             ((i you he she him her it) '(pron))))

   Figure 23-7: Nominal dictionary.

   We need a slightly larger dictionary to parse more complex input.
The function types (Figure 23-7) provides a dictionary of the most
primitive sort.  It defines a 22-word vocabulary, and associates each
word with a list of one or more simple grammatical roles.

          (defnode mods
            (cat n mods/n
              (setr mods *)))

          (defnode mods/n
            (cat n mods/n
              (pushr mods *))
            (up `(n-group ,(getr mods))))

   Figure 23-8: Sub-network for strings of modifiers.

   The components of an ATN are themselves ATNs.  The smallest ATN in
our set is the one in Figure 23-8.  It parses strings of modifiers,
which in this case means just strings of nouns.  The first node, mods,
accepts a noun.  The second node, mods/n, can either look for more
nouns, or return a parsing.

   Section 3-4 explained how writing programs in a functional style
makes them easier to test:

  1. In a functional program, components can be tested individually.
  2. In Lisp, functions can be tested interactively, in the toplevel
     loop.

   Together these two principles allow interactive development: when
we write functional programs in Lisp, we can test each piece as we
write it.

   ATNs are so like functional programs-in this implementation, they
macroex- pand into functional programs-that the possibility of
interactive development applies to them as well.  We can test an ATN
starting from any node, simply by giving its name as the first
argument to with-parses:

     > (with-parses mods '(time arrow)
             (format t "Parsing: ~A~%" parse))
     Parsing: (N-GROUP (ARROW TIME))
 

   The next two networks have to be discussed together,because they
are mutually recursive.  The network defined in Figure 23-9, which
begins with the node np, is used to parse noun phrases.  The network
defined in Figure 23-10 parses prepositional phrases.  Noun phrases
may contain prepositional phrases and vice versa, so the two networks
each contain a push arc which calls the other.

   The noun phrase network contains six nodes.  The first node, np has
three choices.  If it reads a pronoun, then it can move to node pron,
which pops out of the network:

          (defnode np
           (cat det np/det
              (setr det *))
           (jump np/det
              (setr det nil))
           (cat pron pron
              (setr n *)))

          (defnode pron
           (up `(np (pronoun ,(getr n)))))

          (defnode np/det
           (down mods np/mods
              (setr mods *))
           (jump np/mods
              (setr mods nil)))

          (defnode np/mods
           (cat n np/n
              (setr n *)))

          (defnode np/n
           (up `(np (det ,(getr det))
                     (modifiers ,(getr mods))
                     (noun ,(getr n))))
           (down pp np/pp
              (setr pp *)))

          (defnode np/pp
           (up `(np (det ,(getr det))
                     (modifiers ,(getr mods))
                     (noun ,(getr n))
                     ,(getr pp))))

   Figure 23-9: Noun phrase sub-network.

     > (with-parses np '(it)
             (format t "Parsing: ~A~%" parse))
     Parsing: (NP (PRONOUN IT))
 

          (defnode pp
            (cat prep pp/prep
                (setr prep *)))

          (defnode pp/prep
            (down np pp/np
                (setr op *)))

          (defnode pp/np
            (up `(pp (prep ,(getr prep))
                        (obj ,(getr op)))))

   Figure 23-10: Prepositional phrase sub-network.

   Both the other arcs lead to node np/det: one arc reads a determiner
(e.g.  "the"), and the other arc simply jumps, reading no input.  At
node np/det, both arcs lead to np/mods; np/det has the option of
pushing to sub-network mods to pick up a string of modifiers, or
jumping.  Node np-mods reads a noun and continues to np/n.  This node
can either pop a result, or push to the prepositional phrase network
to try to pick up a prepositional phrase.  The final node, np/pp, pops
a result.

   Different types of noun phrases will have different parse paths.
Here are two parsings on the noun phrase network:

     > (with-parses np '(arrows)
             (pprint parse))
     (NP (DET NIL)
             (MODIFIERS NIL)
             (NOUN ARROWS))
     @> (with-parses np '(a time fly like him)
             (pprint parse))
     (NP (DET A)
             (MODIFIERS (N-GROUP TIME))
             (NOUN FLY)
             (PP (PREP LIKE)
                  (OBJ (NP (PRONOUN HIM)))))
 

   The first parse succeeds by jumping to np/det, jumping again to
np/mods, reading a noun, then popping at np/n.  The second never
jumps, pushing first for

      (defnode s
         (down np s/subj
             (setr mood 'decl)
             (setr subj *))
         (cat v v
             (setr mood 'imp)
             (setr subj '(np (pron you)))
             (setr aux nil)
             (setr v *)))

      (defnode s/subj
         (cat v v
             (setr aux nil)
             (setr v *)))

      (defnode v
         (up `(s (mood ,(getr mood))
                    (subj ,(getr subj))
                    (vcl (aux ,(getr aux))
                          (v ,(getr v)))))
         (down np s/obj
             (setr obj *)))

      (defnode s/obj
         (up `(s (mood ,(getr mood))
                    (subj ,(getr subj))
                    (vcl (aux ,(getr aux))
                          (v ,(getr v)))
                    (obj ,(getr obj)))))

   Figure 23-11: Sentence network.

a string of modifiers, and again for a prepositional phrase.  As is
often the case with parsers, expressions which are syntactically
well-formed are such nonsense semantically that it's difficult for
humans even to detect the syntactic structure.  Here the noun phrase
"a time fly like him" has the same form as "a Lisp hacker like him."

   Now all we need is a network for recognizing sentence structure.
The network shown in Figure 23-11 parses both commands and statements.
The start node is conventionally called s.  The first node leaving it
pushes for a noun phrase,

      > (with-parses s '(time flies like an arrow)
               (pprint parse))

      (S (MOOD DECL)
             (SUBJ (NP (DET NIL)
                           (MODIFIERS (N-GROUP TIME))
                           (NOUN FLIES)))
             (VCL (AUX NIL)
                    (V LIKE))
             (OBJ (NP (DET AN)
                          (MODIFIERS NIL)
                          (NOUN ARROW))))

      (S (MOOD IMP)
             (SUBJ (NP (PRON YOU)))
             (VCL (AUX NIL)
                    (V TIME))
             (OBJ (NP (DET NIL)
                          (MODIFIERS NIL)
                          (NOUN FLIES)
                          (PP (PREP LIKE)
                               (OBJ (NP (DET AN)
                                           (MODIFIERS NIL)
                                           (NOUN ARROW)))))))
  

   Figure 23-12: Two parsings for a sentence.

which will be the subject of the sentence.  The second outgoing arc
reads a verb.  When a sentence is syntactically ambiguous, both arcs
could succeed, ultimately yielding two or more parsings, as in Figure
23-12.  The first parsing is analogous to "Island nations like a
navy," and the second is analogous to "Find someone like a policeman."
More complex ATNs are able to find six or more parsings for "Time
flies like an arrow."

   The ATN compiler in this chapter is presented more as a
distillation of the idea of an ATN than as production software.  A few
obvious changes would make this code much more efficient.  When speed
is important, the whole idea of simulating nondeterminism with
closures may be too slow.  But when it isn't essential, the
programming techniques described here lead to very concise programs.


File: onlisp.info,  Node: 24 Prolog,  Next: 25 Object-Oriented Lisp,  Prev: 23 Parsing with ATNs,  Up: Top

24 24 Prolog
************

This chapter describes how to write Prolog as an embedded language.
Chapter 19 showed how to write a program which answered complex
queries on databases.  Here we add one new ingredient: rules, which
make it possible to infer facts from those already known.  A set of
rules defines a tree of implications.  In order to use rules which
would otherwise imply an unlimited number of facts, we will search
this implication tree nondeterministically.

   Prolog makes an excellent example of an embedded language.  It
combines three ingredients: pattern-matching, nondeterminism, and
rules.  Chapters 18 and 22 give us the first two independently.  By
building Prolog on top of the pattern-matching and nondeterministic
choice operators we have already, we will have an example of a real,
multi-layer bottom-up system.  Figure 24-1 shows the layers of
abstraction involved.

   The secondary aim of this chapter is to study Prolog itself.  For
experienced programmers, the most convenient explanation of Prolog may
be a sketch of its implementation.  Writing Prolog in Lisp is
particularly interesting, because it brings out the similarities
between the two languages.

* Menu:

* 24-1 Concepts::               
* 24-2 An Interpreter::         
* 24-3 Rules::                  
* 24-4 The Need for Nondeterminism::  
* 24-5 New Implementation::     
* 24-6 Adding Prolog Features::  
* 24-7 Examples::               
* 24-8 The Senses of Compile::  


File: onlisp.info,  Node: 24-1 Concepts,  Next: 24-2 An Interpreter,  Prev: 24 Prolog,  Up: 24 Prolog

24.1 24-1 Concepts
==================

Chapter 19 showed how to write a database system which would accept
complex queries containing variables, and generate all the bindings
which made the query true in the database.  In the following example,
(after calling clear-db) we assert two facts and then query the
database:

   Figure 24-1: Layers of abstraction.

     > (fact painter reynolds)
     (REYNOLDS)
     > (fact painter gainsborough)
     (GAINSBOROUGH)
     > (with-answer (painter ?x)
              (print ?x))
     GAINSBOROUGH
     REYNOLDS
     NIL

   Conceptually, Prolog is the database program with the addition of
rules, which make it possible to satisfy a query not just by looking
it up in the database, but by inferring it from other known facts.
For example, if we have a rule like:

     If       (hungry ?x) and (smells-of ?x turpentine)
     Then (painter ?x)

then the query (painter ?x) will be satisfied for ?x = raoul when the
database contains both (hungry raoul) and (smells-of raoul
turpentine),even if it doesn't contain (painter raoul).

   In Prolog, the if-part of a rule is called the body, and the
then-part the head.  (In logic, the names are antecedent and
consequent, but it is just as well to have separate names, to
emphasize that Prolog inference is not the same as logical
implication.)  When trying to establish bindings(1) for a query, the
program looks first at the head of a rule.  If the head matches the
query that the program is trying to answer, the program will then try
to establish bindings for the body of the rule.  Bindings which
satisfy the body will, by definition, satisfy the head.

   The facts used in the body of the rule may in turn be inferred from
other rules:

     If      (gaunt ?x) or (eats-ravenously ?x)
     Then (hungry ?x)

   and rules may be recursive, as in:

     If      (surname ?f ?n) and (father ?f ?c)
     Then (surname ?c ?n)

   Prolog will be able to establish bindings for a query if it can
find some path through the rules which leads eventually to known
facts.  So it is essentially a search engine: it traverses the tree of
logical implications formed by the rules, looking for a successful
path.

   Though rules and facts sound like distinct types of objects, they
are conceptu- ally interchangeable.  Rules can be seen as virtual
facts.  If we want our database to reflect the discovery that big,
fierce animals are rare, we could look for all the x such that there
are facts (species x), (big x), and (fierce x), and add a new fact
(rare x).  However, by defining a rule to say

     If      (species ?x) and (big ?x) and (fierce ?x)
     Then (rare ?x)

   we get the same effect, without actually having to add all the
(rare x) to the database.  We can even define rules which imply an
infinite number of facts.  Thus rules make the database smaller at the
expense of extra processing when it comes time to answer questions.

   Facts, meanwhile, are a degenerate case of rules.  The effect of
any fact F could be duplicated by a rule whose body was always true:

     If      true
     Then F

   To simplify our implementation, we will take advantage of this
principle and represent facts as bodyless rules.

   ---------- Footnotes ----------

   (1) Many of the concepts used in this chapter, including this sense
of bindings, are explained in Section 18-4.


File: onlisp.info,  Node: 24-2 An Interpreter,  Next: 24-3 Rules,  Prev: 24-1 Concepts,  Up: 24 Prolog

24.2 24-2 An Interpreter
========================

Section 18-4 showed two ways to define if-match.  The first was simple
but inefficient.  Its successor was faster because it did much of its
work at compile- time.  We will follow a similar strategy here.  In
order to introduce some of the topics involved, we will begin with a
simple interpreter.  Later we will show how to write the same program
much more efficiently.

      (defmacro with-inference (query &body body)
       `(progn
              (setq *paths* nil)
              (=bind (binds) (prove-query ',(rep_ query) nil)
                 (let ,(mapcar #'(lambda (v)
                                        `(,v (fullbind ',v binds)))
                                   (vars-in query #'atom))
                   ,@body
                   (fail)))))

      (defun rep_ (x)
            (if (atom x)
                 (if (eq x '_) (gensym "?") x)
                 (cons (rep_ (car x)) (rep_ (cdr x)))))

      (defun fullbind (x b)
            (cond ((varsym? x) (aif2 (binding x b)
                                            (fullbind it b)
                                            (gensym)))
                   ((atom x) x)
                   (t (cons (fullbind (car x) b)
                               (fullbind (cdr x) b)))))

      (defun varsym? (x)
            (and (symbolp x) (eq (char (symbol-name x) 0) #\?)))

   Figure 24-2: Toplevel macro.

   Figures 24-2­24-4 contain the code for a simple Prolog interpreter.
It ac- cepts the same queries as the query interpreter of Section
19-3, but uses rules instead of the database to generate bindings.
The query interpreter was invoked through a macro called with-answer.
The interface to the Prolog interpreter will be through a similar
macro, called with-inference.  Like with-answer, with-inference is
given a query and a series of Lisp expressions.  Variables in the
query are symbols beginning with a question mark:

     (with-inference (painter ?x)
       (print ?x))

   A call to with-inference expands into code that will evaluate the
Lisp expres- sions for each set of bindings generated by the query.
The call above, for example, will print each x for which it is
possible to infer (painter x).

   Figure 24-2 shows the definition of with-inference, together with
the func- tion it calls to retrieve bindings.  One notable difference
between with-answer and with-inference is that the former simply
collected all the valid bindings.  The new program searches
nondeterministically.  We see this in the definition of
with-inference: instead of expanding into a loop, it expands into code
which will return one set of bindings, followed by a fail to restart
the search.  This gives us iteration implicitly, as in:

     > (choose-bind x '(0 1 2 3456789)
             (princ x)
             (if (= x 6) x (fail)))
     0123456
     6

   The function fullbind points to another difference between
with-answer and with-inference.  Tracing back through a series of
rules can build up binding lists in which the binding of a variable is
a list of other variables.  To make use of the results of a query we
now need a recursive function for retrieving bindings.  This is the
purpose of fullbind:

     > (setq b '((?x . (?y . ?z)) (?y . foo) (?z . nil)))
     ((?X ?Y . ?Z) (?Y . FOO) (?Z))
     > (values (binding '?x b))
     (?Y . ?Z)
     > (fullbind '?x b)
     (FOO)

   Bindings for the query are generated by a call to prove-query in
the expansion of with-inference.  Figure 24-3 shows the definition of
this function and the functions it calls.  This code is structurally
isomorphic to the query interpreter described in Section 19-3.  Both
programs use the same functions for matching, but where the query
interpreter used mapping or iteration, the Prolog interpreter uses
equivalent chooses.

   Using nondeterministic search instead of iteration does make the
interpretation of negated queries a bit more complex.  Given a query
like

     (not (painter ?x))

the query interpreter could just try to establish bindings for
(painter ?x), returning nil if any were found.  With nondeterministic
search we have to be more careful: we don't want the interpretation of
(painter ?x) to fail back outside the scope of the not, nor do we want
it to leave saved paths that might

      (=defun prove-query (expr binds)
            (case (car expr)
              (and (prove-and (cdr expr) binds))
              (or     (prove-or (cdr expr) binds))
              (not (prove-not (cadr expr) binds))
              (t      (prove-simple expr binds))))

      (=defun prove-and (clauses binds)
            (if (null clauses)
                 (=values binds)
                 (=bind (binds) (prove-query (car clauses) binds)
                     (prove-and (cdr clauses) binds))))

      (=defun prove-or (clauses binds)
            (choose-bind c clauses
              (prove-query c binds)))

      (=defun prove-not (expr binds)
            (let ((save-paths *paths*))
              (setq *paths* nil)
              (choose (=bind (b) (prove-query expr binds)
                           (setq *paths* save-paths)
                           (fail))
                         (progn
                           (setq *paths* save-paths)
                           (=values binds)))))

      (=defun prove-simple (query binds)
            (choose-bind r *rlist*
              (implies r query binds)))

   Figure 24-3: Interpretation of queries.

be restarted later.  So now the test for (painter ?x) is done with a
temporarily empty list of saved states, and the old list is restored
on the way out.

   Another difference between this program and the query interpreter
is in the interpretation of simple patterns-expressions such as
(painter ?x) which con- sist just of a predicate and some arguments.
When the query interpreter generated bindings for a simple pattern, it
called lookup (page 251).  Now, instead of calling lookup, we have to
get any bindings implied by the rules.

      (defvar *rlist* nil)

      (defmacro <- (con &rest ant)
         (let ((ant (if (= (length ant) 1)
                            (car ant)
                            `(and ,@ant))))
             `(length (conc1f *rlist* (rep_ (cons ',ant ',con))))))

      (=defun implies (r query binds)
         (let ((r2 (change-vars r)))
             (aif2 (match query (cdr r2) binds)
                   (prove-query (car r2) it)
                   (fail))))

      (defun change-vars (r)
         (sublis (mapcar #'(lambda (v)
                                     (cons v (symb '? (gensym))))
                                 (vars-in r #'atom))
                   r))

   Figure 24-4: Code involving rules.

       rule        : (<-  sentence  query )
       query       : (not  query )
                   : (and  query *)
                   : (or  query *)
                   :  sentence
       sentence  : ( symbol  argument *)
       argument  :  variable
                   :  symbol
                   :  number
       variable  : ? symbol

   Figure 24-5: Syntax of rules.

   Code for defining and using rules is shown in Figure 24-4.  The
rules are kept in a global list, *rlist*.  Each rule is represented as
a dotted pair of body and head.  At the time a rule is defined, all
the underscores are replaced with unique variables.

   The definition of <- follows three conventions often used in
programs of this type:

  1. New rules are added to the end rather than the front of the list,
     so that they will be applied in the order that they were defined.
  2. Rules are expressed head first, since that's the order in which
     the program examines them.
  3. Multiple expressions in the body are within an implicit and.

   The outermost call to length in the expansion of <- is simply to
avoid printing a huge list when <- is called from the toplevel.

   The syntax of rules is given in Figure 24-5.  The head of a rule
must be a pattern for a fact: a list of a predicate followed by zero
or more arguments.  The body may be any query that could be handled by
the query interpreter of Chapter 19.  Here is the rule from earlier in
this chapter:

     (<- (painter ?x) (and (hungry ?x)
                                      (smells-of ?x turpentine)))

or just

     (<- (painter ?x) (hungry ?x)
                                (smells-of ?x turpentine))

   As in the query interpreter, arguments like turpentine do not get
evaluated, so they don't have to be quoted.

   When prove-simple is asked to generate bindings for a query, it
nondeter- ministically chooses a rule and sends both rule and query to
implies.  The latter function then tries to match the query with the
head of the rule.  If the match succeeds, implies will call
prove-query to establish bindings for the body.  Thus we recursively
search the tree of implications.

   The function change-vars replaces all the variables in a rule with
fresh ones.  An ?x used in one rule is meant to be independent of one
used in another.  In order to avoid conflicts with existing bindings,
change-vars is called each time a rule is used.

   For the convenience of the user, it is possible to use
(underscore)as a wildcard variable in rules.  When a rule is defined,
the function rep is called to change each underscore into a real
variable.  Underscores can also be used in the queries given to
with-inference.


File: onlisp.info,  Node: 24-3 Rules,  Next: 24-4 The Need for Nondeterminism,  Prev: 24-2 An Interpreter,  Up: 24 Prolog

24.3 24-3 Rules
===============

This section shows how to write rules for our Prolog.  To start with,
here are the two rules from Section 24-1:

     (<- (painter ?x) (hungry ?x)
                            (smells-of ?x turpentine))

     (<- (hungry ?x) (or (gaunt ?x) (eats-ravenously ?x)))

   If we also assert the following facts:

     (<- (gaunt raoul))
     (<- (smells-of raoul turpentine))
     (<- (painter rubens))

   Then we will get the bindings they generate according to the order
in which they were defined:

     > (with-inference (painter ?x)
             (print ?x))
     RAOUL
     RUBENS
 

   The with-inferencemacro has exactly the same restrictions on
variable binding as with-answer.  (See Section 19-4.)

   We can write rules which imply that facts of a given form are true
for all possible bindings.  This happens, for example, when some
variable occurs in the head of a rule but not in the body.  The rule

     (<- (eats ?x ?f) (glutton ?x))

   Says that if ?x is a glutton, then ?x eats everything.  Because ?f
doesn't occur in the body, we can prove any fact of the form (eats ?x
y) simply by establishing a binding for ?x.  If we make a query with a
literal value as the second argument to eats,

     > (<- (glutton hubert))
     7> (with-inference (eats ?x spinach)
             (print ?x))
     HUBERT
 

then any literal value will work.  When we give a variable as the
second argument:

     > (with-inference (eats ?x ?y)
             (print (list ?x ?y)))
     (HUBERT #:G229)
 

we get a gensym back.  Returning a gensym as the binding of a variable
in the query is a way of signifying that any value would be true
there.  Programs can be written explicitly to take advantage of this
convention:

     > (progn
             (<- (eats monster bad-children))
             (<- (eats warhol candy)))
     9> (with-inference (eats ?x ?y)
             (format t "~A eats ~A.~%"
                       ?x
                       (if (gensym? ?y) 'everything ?y)))
     HUBERT eats EVERYTHING.
     MONSTER eats BAD-CHILDREN.
     WARHOL eats CANDY.
 

   Finally, if we want to specify that facts of a certain form will be
true for any arguments, we make the body a conjunction with no
arguments.  The expression (and) will always behave as a true fact.
In the macro <- (Figure 24-4), the body defaults to (and), so for such
rules we can simply omit the body:

     > (<- (identical ?x ?x))
     10
     > (with-inference (identical a ?x)
             (print ?x))
     A 

   For readers with some knowledge of Prolog, Figure 24-6 shows the
translation from Prolog syntax into that of our program.  The
traditional first Prolog program is append, which would be written as
at the end of Figure 24-6.  In an instance of appending, two shorter
lists are joined together to form a single larger one.  Any two of
these lists define what the third should be.  The Lisp function append
takes the two shorter lists as arguments and returns the longer one.
Prolog append is more general; the two rules in Figure 24-6 define a
program which, given any two of the lists involved, can find the
third.

   Our syntax differs from traditional Prolog syntax as follows:

  1. Variables are represented by symbols beginning with question
     marks instead of capital letters.  Common Lisp is not
     case-sensitive by default, so it would be more trouble than it's
     worth to use capitals.
  2. []becomes nil.
  3. Expressions of the form [x | y] become (x .  y).
  4. Expressions of the form [x, y, ...]  become (xy...).
  5. Predicates are moved inside parentheses, and no commas separate
     argu- ments: pred(x, y, ...)  becomes (pred x y ...).

   Thus the Prolog definition of append:

          append([ ], Xs, Xs).
          append([X | Xs], Ys, [X | Zs]) <- append(Xs, Ys, Zs).

   becomes:

          (<- (append nil ?xs ?xs))
          (<- (append (?x . ?xs) ?ys (?x . ?zs))
               (append ?xs ?ys ?zs))

   Figure 24-6: Prolog syntax equivalence.

     > (with-inference (append ?x (c d) (a b c d))
             (format t "Left: ~A~%" ?x))
     Left: (A B)
     @> (with-inference (append (a b) ?x (a b c d))
             (format t "Right: ~A~%" ?x))
     Right: (C D)
     @> (with-inference (append (a b) (c d) ?x)
             (format t "Whole: ~A~%" ?x))
     Whole: (ABCD)
 

   Not only that, but given only the last list, it can find all the
possibilities for the first two:

     > (with-inference (append ?x ?y (a b c))
             (format t "Left: ~A Right: ~A~%" ?x ?y))
     Left: NIL Right: (A B C)
     Left: (A) Right: (B C)
     Left: (A B) Right: (C)
     Left: (A B C) Right: NIL
 

   The case of append points to a great difference between Prolog and
other languages.  A collection of Prolog rules does not have to yield
a specific value.  It can instead yield constraints, which, when
combined with constraints generated by other parts of the program,
yield a specific value.  For example, if we define member thus:

     (<- (member ?x (?x . ?rest)))
     (<- (member ?x (_ . ?rest)) (member ?x ?rest))

then we can use it to test for list membership, as we would use the
Lisp function member:

     > (with-inference (member a (a b)) (print t))
     T 

but we can also use it to establish a constraint of membership, which,
combined with other constraints, yields a specific list.  If we also
have a predicate cara

     (<- (cara (a _)))

which is true of any two-element list whose car is a, then between
that and member we have enough constraint for Prolog to construct a
definite answer:

     > (with-inference (and (cara ?lst) (member b ?lst))
             (print ?lst))
     (A B)
 

   This is a rather trivial example, but bigger programs can be
constructed on the same principle.  Whenever we want to program by
combining partial solutions, Prolog may be useful.  Indeed, a
surprising variety of problems can be expressed in such terms: Figure
24-14, for example, shows a sorting algorithm expressed as a
collection of constraints on the solution.


File: onlisp.info,  Node: 24-4 The Need for Nondeterminism,  Next: 24-5 New Implementation,  Prev: 24-3 Rules,  Up: 24 Prolog

24.4 24-4 The Need for Nondeterminism
=====================================

Chapter 22 explained the relation between deterministic and
nondeterministic search.  A deterministic search program could take a
query and generate all the solutions which satisfied it.  A
nondeterministic search program will use choose to generate solutions
one at a time, and if more are needed, will call fail to restart the
search.

   When we have rules which all yield finite sets of bindings, and we
want all of them at once, there is no reason to prefer
nondeterministic search.  The difference between the two strategies
becomes apparent when we have queries which would generate an infinite
number of bindings, of which we want a finite subset.  For example,
the rules

     (<- (all-elements ?x nil))
     (<- (all-elements ?x (?x . ?rest))
             (all-elements ?x ?rest))

imply all the facts of the form (all-elements xy), where every member
of y is equal to x.  Without backtracking we could handle queries
like:

     (all-elements a (a a a))
     (all-elements a (a a b))
     (all-elements ?x (a a a))

   However, the query (all-elements a ?x) is satisfied for an infinite
number of possible ?x: nil, (a), (a a), and so on.  If we try to
generate answers for this query by iteration, the iteration will never
terminate.  Even if we only wanted one of the answers, we would never
get a result from an implementation which had to generate all the
bindings for the query before it could begin to iterate through the
Lisp expressions following it.

   This is why with-inference interleaves the generation of bindings
with the evaluation of its body.  Where queries could lead to an
infinite number of answers, the only successful approach will be to
generate answers one at a time, and return to pick up new ones by
restarting the suspended search.  Because it uses choose and fail, our
program can handle this case:

     > (block nil
             (with-inference (all-elements a ?x)
               (if (= (length ?x) 3)
                    (return ?x)
                    (princ ?x))))
     NIL(A)(A A)
     (AAA)

   Like any other Prolog implementation, ours simulates nondeterminism
by doing depth-first search with backtracking.  In theory, "logic
programs" run under true nondeterminism.  In fact, Prolog
implementations always use depth-first search.  Far from being
inconvenienced by this choice, typical Prolog programs depend on it.
In a truly nondeterministic world, the query

     (and (all-elements a ?x) (length ?x 3))

has an answer, but it takes you arbitrarily long to find out what it
is.

   Not only does Prolog use the depth-first implementation of
nondeterminism, it uses a version equivalent to that defined on page
293.  As explained there, this implementation is not always guaranteed
to terminate.  So Prolog programmers must take deliberate steps to
avoid loops in the search space.  For example, if we had defined
member in the reverse order

     (<- (member ?x (_ . ?rest)) (member ?x ?rest))
     (<- (member ?x (?x . ?rest)))

then logically it would have the same meaning, but as a Prolog program
it would have a different effect.  The original definition of member
would yield an infinite stream of answers in response to the query
(member 'a ?x), but the reversed definition will yield an infinite
recursion, and no answers.


File: onlisp.info,  Node: 24-5 New Implementation,  Next: 24-6 Adding Prolog Features,  Prev: 24-4 The Need for Nondeterminism,  Up: 24 Prolog

24.5 24-5 New Implementation
============================

In this section we will see another instance of a familiar pattern.
In Section 18-4, we found after writing the initial version that
if-match could be made much faster.  By taking advantage of
information known at compile-time, we were able to write a new version
which did less work at runtime.  We saw the same phenomenon on a
larger scale in Chapter 19.  Our query interpreter was replaced by an
equivalent but faster version.  The same thing is about to happen to
our Prolog interpreter.

   Figures 24-7, 24-8, and 24-10 define Prolog in a different way.
The macro with-inference used to be just the interface to a Prolog
interpreter.  Now it is most of the program.  The new program has the
same general shape as the old one, but of the functions defined in
Figure 24-8, only prove is called at runtime.  The others are called
by with-inference in order to generate its expansion.

   Figure 24-7 shows the new definition of with-inference.Asinif-match
or with-answer, pattern variables are initially bound to gensyms to
indicate that they haven't yet been assigned real values by matching.
Thus the function varsym?, which match and fullbind use to detect
variables, has to be changed to look for gensyms.

      (defmacro with-inference (query &rest body)
         (let ((vars (vars-in query #'simple?)) (gb (gensym)))
             `(with-gensyms ,vars
                (setq *paths* nil)
                (=bind (,gb) ,(gen-query (rep_ query))
                     (let ,(mapcar #'(lambda (v)
                                           `(,v (fullbind ,v ,gb)))
                                     vars)
                      ,@body)
                     (fail)))))

      (defun varsym? (x)
         (and (symbolp x) (not (symbol-package x))))

   Figure 24-7: New toplevel macro.

   To generate the code to establish bindings for the query,
with-inference calls gen-query (Figure 24-8).  The first thing
gen-query does is look to see whether its first argument is a complex
query beginning with an operator like and or or.  This process
continues recursively until it reaches simple queries, which are
expanded into calls to prove.  In the original implementation, such
logical structure was analyzed at runtime.  A complex expression
occurring in the body of a rule had to be analyzed anew each time the
rule was used.  This is wasteful because the logical structure of
rules and queries is known beforehand.  The new implementation
decomposes complex expressions at compile-time.

   As in the previous implementation, a with-inference expression
expands into code which iterates through the Lisp code following the
query with the pattern variables bound to successive values
established by the rules.  The expansion of with-inference concludes
with a fail, which will restart any saved states.

   The remaining functions in Figure 24-8 generate expansions for
complex queries-queries joined together by operators like and, or, and
not.Ifwehave a query like

     (and (big ?x) (red ?x))

then we want the Lisp code to be evaluated only with those ?x for
which both conjuncts can be proved.  So to generate the expansion of
an and, we nest the expansion of the second conjunct within that of
the first.  When (big ?x) succeeds we try (red ?x), and if that
succeeds, we evaluate the Lisp expressions.  So the whole expression
expands as in Figure 24-9.

      (defun gen-query (expr &optional binds)
            (case (car expr)
             (and (gen-and (cdr expr) binds))
             (or (gen-or (cdr expr) binds))
             (not (gen-not (cadr expr) binds))
             (t     `(prove (list ',(car expr)
                                      ,@(mapcar #'form (cdr expr)))
                             ,binds))))

      (defun gen-and (clauses binds)
            (if (null clauses)
               `(=values ,binds)
               (let ((gb (gensym)))
                    `(=bind (,gb) ,(gen-query (car clauses) binds)
                        ,(gen-and (cdr clauses) gb)))))

      (defun gen-or (clauses binds)
            `(choose
              ,@(mapcar #'(lambda (c) (gen-query c binds))
                            clauses)))

      (defun gen-not (expr binds)
            (let ((gpaths (gensym)))
             `(let ((,gpaths *paths*))
                   (setq *paths* nil)
                   (choose (=bind (b) ,(gen-query expr binds)
                             (setq *paths* ,gpaths)
                             (fail))
                            (progn
                             (setq *paths* ,gpaths)
                             (=values ,binds))))))

      (=defun prove (query binds)
             (choose-bind r *rules* (=funcall r query binds)))

      (defun form (pat)
            (if (simple? pat)
               pat
               `(cons ,(form (car pat)) ,(form (cdr pat)))))

   Figure 24-8: Compilation of queries.

      (with-inference (and (big ?x) (red ?x))
         (print ?x))

expands into:

      (with-gensyms (?x)
         (setq *paths* nil)
         (=bind (#:g1) (=bind (#:g2) (prove (list 'big ?x) nil)
                                (=bind (#:g3) (prove (list 'red ?x) #:g2)
                                   (=values #:g3)))
             (let ((?x (fullbind ?x #:g1)))
                (print ?x))
             (fail)))

   Figure 24-9: Expansion of a conjunction.

   An and means nesting; an or means a choose.  Given a query like

     (or (big ?x) (red ?x))

we want the Lisp expressions to be evaluated for values of ?x
established by either subquery.  The function gen-or expands into a
choose over the gen-query of each of the arguments.  As for not,
gen-not is almost identical to prove-not (Figure 24-3).

   Figure 24-10 shows the code for defining rules.  Rules are
translated directly into Lisp code generated by rule-fn.  Since <- now
expands rules into Lisp code, compiling a file full of rule
definitions will cause rules to be compiled functions.

   When a rule-function is sent a pattern, it tries to match it with
the head of the rule it represents.  If the match succeeds, the
rule-function will then try to establish bindings for the body.  This
task is essentially the same as that done by with-inference, and in
fact rule-fn ends by calling gen-query.  The rule-function eventually
returns the bindings established for the variables occurring in the
head of the rule.


File: onlisp.info,  Node: 24-6 Adding Prolog Features,  Next: 24-7 Examples,  Prev: 24-5 New Implementation,  Up: 24 Prolog

24.6 24-6 Adding Prolog Features
================================

The code already presented can run most "pure" Prolog programs.  The
final step is to add extras like cuts, arithmetic, and I/O.

   Putting a cut in a Prolog rule causes the search tree to be pruned.
Ordinarily, when our program encounters a fail, it backtracks to the
last choice point.  The

      (defvar *rules* nil)

      (defmacro <- (con &rest ant)
            (let ((ant (if (= (length ant) 1)
                               (car ant)
                               `(and ,@ant))))
              `(length (conc1f *rules*
                                    ,(rule-fn (rep_ ant) (rep_ con))))))

      (defun rule-fn (ant con)
            (with-gensyms (val win fact binds)
              `(=lambda (,fact ,binds)
                  (with-gensyms ,(vars-in (list ant con) #'simple?)
                     (multiple-value-bind
                          (,val ,win)
                          (match ,fact
                                   (list ',(car con)
                                          ,@(mapcar #'form (cdr con)))
                                   ,binds)
                       (if ,win
                            ,(gen-query ant val)
                            (fail)))))))

   Figure 24-10: Code for defining rules.

implementation of choose in Section 22-4 stores choice points in the
global variable *paths*.  Calling fail restarts the search at the most
recent choice point, which is the car of *paths*.  Cuts introduce a
new complication.  When the program encounters a cut, it will throw
away some of the most recent choice points stored on
*paths*-specifically, all those stored since the last call to prove.

   The effect is to make rules mutually exclusive.  We can use cuts to
get the effect of a case statement in Prolog programs.  For example,
if we define minimum this way:

     (<- (minimum ?x ?y ?x) (lisp (<= ?x ?y)))
     (<- (minimum ?x ?y ?y) (lisp (> ?x ?y)))

it will work correctly, but inefficiently.  Given the query

     (minimum 1 2 ?x)

   Prolog will immediately establish that ?x = 1 from the first rule.
A human would stop here, but the program will waste time looking for
more answers from the second rule, because it has been given no
indication that the two rules are mutually exclusive.  On the average,
this version of minimum will do 50% more work than it needs to.  We
can fix the problem by adding a cut after the first test:

     (<- (minimum ?x ?y ?x) (lisp (<= ?x ?y)) (cut))
     (<- (minimum ?x ?y ?y))

   Now when Prolog has finished with the first rule, it will fail all
the way out of the query instead of moving on to the next rule.

   It is trivially easy to modify our program to handle cuts.  On each
call to prove, the current state of *paths* is passed as a parameter.
If the program encounters a cut, it just sets *paths* back to the old
value passed in the parameter.  Figures 24-11 and 24-12 show the code
which has to be modified to handle cuts.  (Changed lines are marked
with semicolons.  Not all the changes are due to cuts.)

   Cuts which merely make a program more efficient are called green
cuts.  The cut in minimum was a green cut.  Cuts which make a program
behave differently are called red cuts.  For example, if we define the
predicate artist as follows:

     (<- (artist ?x) (sculptor ?x) (cut))
     (<- (artist ?x) (painter ?x))

the result is that, if there are any sculptors, then the query can end
there.  If there are no sculptors then painters get to be considered
as artists:

     > (progn (<- (painter 'klee))
                 (<- (painter 'soutine)))
     4> (with-inference (artist ?x)
             (print ?x))
     KLEE
     SOUTINE
 

   But if there are sculptors, the cut stops inference with the first
rule:

     > (<- (sculptor 'hepworth))
     5> (with-inference (artist ?x)
             (print ?x))
     HEPWORTH
 

      (defun rule-fn (ant con)
            (with-gensyms (val win fact binds paths)                     ;
             `(=lambda (,fact ,binds ,paths)                             ;
                   (with-gensyms ,(vars-in (list ant con) #'simple?)
                    (multiple-value-bind
                        (,val ,win)
                        (match ,fact
                                  (list ',(car con)
                                         ,@(mapcar #'form (cdr con)))
                                  ,binds)
                      (if ,win
                           ,(gen-query ant val paths)                    ;
                           (fail)))))))

      (defmacro with-inference (query &rest body)
            (let ((vars (vars-in query #'simple?)) (gb (gensym)))
             `(with-gensyms ,vars
                   (setq *paths* nil)
                   (=bind (,gb) ,(gen-query (rep_ query) nil '*paths*) ;
                    (let ,(mapcar #'(lambda (v)
                                          `(,v (fullbind ,v ,gb)))
                                     vars)
                      ,@body)
                    (fail)))))

      (defun gen-query (expr binds paths)                                ;
            (case (car expr)
             (and (gen-and (cdr expr) binds paths))                      ;
             (or      (gen-or (cdr expr) binds paths))                   ;
             (not (gen-not (cadr expr) binds paths))                     ;
             (lisp (gen-lisp (cadr expr) binds))                         ;
             (is      (gen-is (cadr expr) (third expr) binds))           ;
             (cut `(progn (setq *paths* ,paths)                          ;
                              (=values ,binds)))                         ;
             (t       `(prove (list ',(car expr)
                                      ,@(mapcar #'form (cdr expr)))
                              ,binds *paths*))))                         ;

      (=defun prove (query binds paths)                                  ;
             (choose-bind r *rules*
               (=funcall r query binds paths)))                          ;

   Figure 24-11: Adding support for new operators.

      (defun gen-and (clauses binds paths)                              ;
        (if (null clauses)
              `(=values ,binds)
              (let ((gb (gensym)))
               `(=bind (,gb) ,(gen-query (car clauses) binds paths);
                  ,(gen-and (cdr clauses) gb paths)))))                 ;

      (defun gen-or (clauses binds paths)                               ;
        `(choose
              ,@(mapcar #'(lambda (c) (gen-query c binds paths))        ;
                         clauses)))

      (defun gen-not (expr binds paths)                                 ;
        (let ((gpaths (gensym)))
             `(let ((,gpaths *paths*))
               (setq *paths* nil)
               (choose (=bind (b) ,(gen-query expr binds paths)         ;
                           (setq *paths* ,gpaths)
                           (fail))
                         (progn
                           (setq *paths* ,gpaths)
                           (=values ,binds))))))

      (defmacro with-binds (binds expr)
        `(let ,(mapcar #'(lambda (v) `(,v (fullbind ,v ,binds)))
                           (vars-in expr))
              ,expr))

      (defun gen-lisp (expr binds)
        `(if (with-binds ,binds ,expr)
               (=values ,binds)
               (fail)))

      (defun gen-is (expr1 expr2 binds)
        `(aif2 (match ,expr1 (with-binds ,binds ,expr2) ,binds)
                 (=values it)
                 (fail)))

   Figure 24-12: Adding support for new operators.

            rule       : (<-  sentence  query )
            query      : (not  query )
                       : (and  query *)
                       : (lisp  lisp expression )
                       : (is  variable  lisp expression )
                       : (cut)
                       : (fail)
                       :  sentence
            sentence  : ( symbol  argument *)
            argument  :  variable
                       :  lisp expression
            variable  : ? symbol

   Figure 24-13: New syntax of rules.

   The cut is sometimes used in conjunction with the Prolog fail
operator.  Our function fail does exactly the same thing.  Putting a
cut in a rule makes it like a one-way street: once you enter, you're
committed to using only that rule.  Putting a cut-fail combination in
a rule makes it like a one-way street in a dangerous neighborhood:
once you enter, you're committed to leaving with nothing.  A typical
example is in the implementation of not-equal:

     (<- (not-equal ?x ?x) (cut) (fail))
     (<- (not-equal ?x ?y))

   The first rule here is a trap for impostors.  If we're trying to
prove a fact of the form (not-equal 1 1), it will match with the head
of the first rule and thus be doomed.  The query (not-equal 1 2), on
the other hand, will not match the head of the first rule, and will go
on to the second, where it succeeds:

     > (with-inference (not-equal 'a 'a)
              (print t))
     @> (with-inference (not-equal '(a a) '(a b))
              (print t))
     T 

   The code shown in Figures 24-11 and 24-12 also gives our program
arithmetic, I/O, and the Prolog is operator.  Figure 24-13 shows the
complete syntax of rules and queries.

   We add arithmetic (and more) by including a trapdoor to Lisp.  Now
in addition to operators like and and or,wehavethelisp operator.  This
may be followed by any Lisp expression, which will be evaluated with
the variables within it bound to the bindings established for them by
the query.  If the expression evaluates to nil, then the lisp
expression as a whole is equivalent to a (fail); otherwise it is
equivalent to (and).

   As an example of the use of the lisp operator, consider the Prolog
definition of ordered, which is true of lists whose elements are
arranged in ascending order:
     (<- (ordered (?x)))
     (<- (ordered (?x ?y . ?ys))
             (lisp (<= ?x ?y))
             (ordered (?y . ?ys)))

   In English, a list of one element is ordered, and a list of two or
more elements is ordered if the first element of the list is less than
or equal to the second, and the list from the second element on is
ordered.

     > (with-inference (ordered '(1 2 3))
             (print t))
     T@> (with-inference (ordered '(1 3 2))
             (print t))
 

   By means of the lisp operator we can provide other features offered
by typical Prolog implementations.  Prolog I/O predicates can be
duplicated by putting Lisp I/O calls within lisp expressions.  The
Prolog assert, which as a side- effect defines new rules, can be
duplicated by calling the <- macro within lisp expressions.

   The is operator offers a form of assignment.  It takes two
arguments, a pattern and a Lisp expression, and tries to match the
pattern with the result returned by the expression.  If the match
fails, then the program calls fail; otherwise it proceeds with the new
bindings.  Thus, the expression (is ?x 1) has the effect of setting ?x
to 1, or more precisely, insisting that ?x be 1.  We need is to
calculate-for example, to calculate factorials:

     (<- (factorial 0 1))
     (<- (factorial ?n ?f)
             (lisp (> ?n 0))
             (is ?n1 (- ?n 1))
             (factorial ?n1 ?f1)
             (is ?f (* ?n ?f1)))

   We use this definition by making a query with a number n as the
first argument and a variable as the second:

     > (with-inference (factorial 8 ?x)
                  (print ?x))
     40320
 

   Note that the variables used in a lisp expression, or in the second
argument to is, must have established bindings for the expression to
return a value.  This restriction holds in any Prolog.  For example,
the query:

     (with-inference (factorial ?x 120)                                          ; wrong
          (print ?x))

   won't work with this definition of factorial, because ?n will be
unknown when the lisp expression is evaluated.  So not all Prolog
programs are like append: many insist, like factorial, that certain of
their arguments be real values.


File: onlisp.info,  Node: 24-7 Examples,  Next: 24-8 The Senses of Compile,  Prev: 24-6 Adding Prolog Features,  Up: 24 Prolog

24.7 24-7 Examples
==================

This final section shows how to write some example Prolog programs in
our implementation.  The rules in Figure 24-14 define quicksort.
These rules imply facts of the form (quicksort xy), where x is a list
and y is a list of the same elements sorted in ascending order.
Variables may appear in the second argument position:

          > (with-inference (quicksort '(3 2 1) ?x)
                  (print ?x))
          (123)
      

   An I/O loop is a test for our Prolog, because it makes use of the
cut, lisp, and is operators.  The code is shown in Figure 24-15.
These rules should be invoked by trying to prove (echo), with no
arguments.  That query will match the first rule, which will bind ?x
to the result returned by read, and then try to establish (echo ?x).
The new query can match either of the second two rules.  If ?x = done,
then the query will terminate in the second rule.  Otherwise the query
will only match the third rule, which prints the value read, and
starts the process over again.

      (setq *rules* nil)

      (<- (append nil ?ys ?ys))
      (<- (append (?x . ?xs) ?ys (?x . ?zs))
             (append ?xs ?ys ?zs))

      (<- (quicksort (?x . ?xs) ?ys)
             (partition ?xs ?x ?littles ?bigs)
             (quicksort ?littles ?ls)
             (quicksort ?bigs ?bs)
             (append ?ls (?x . ?bs) ?ys))
      (<- (quicksort nil nil))

      (<- (partition (?x . ?xs) ?y (?x . ?ls) ?bs)
             (lisp (<= ?x ?y))
             (partition ?xs ?y ?ls ?bs))
      (<- (partition (?x . ?xs) ?y ?ls (?x . ?bs))
             (lisp (> ?x ?y))
             (partition ?xs ?y ?ls ?bs))
      (<- (partition nil ?y nil nil))

   Figure 24-14: Quicksort.

      (<- (echo)
             (is ?x (read))
             (echo ?x))
      (<- (echo 'done)
             (cut))
      (<- (echo ?x)
             (lisp (prog1 t (format t "~A~%" ?x)))
             (is ?y (read))
             (cut)
             (echo ?y))

   Figure 24-15: An I/O loop in Prolog.

   Collectively, the rules define a program that will continue to echo
what you type, until you type done:

     > (with-inference (echo))
     hi
     HI
     ho
     HO
     done
 

   Programs like this are difficult to read because they subvert the
abstract model of Prolog.  It might be easier to understand echo if we
look at a literal Lisp translation

     (defun echo (&rest args)
          (cond ((null args) (echo (read)))
                  ((eq (car args) 'done) nil)
                  (t (format t "~A~%" (car args))
                      (echo (read)))))

which in idiomatic Common Lisp would be:

     (defun echo (&optional (arg (read)))
          (unless (eq arg 'done)
             (format t "~A~%" arg)
             (echo)))


File: onlisp.info,  Node: 24-8 The Senses of Compile,  Prev: 24-7 Examples,  Up: 24 Prolog

24.8 24-8 The Senses of Compile
===============================

The word "compile" has several senses.  In the most general sense, to
compile is to transform some abstract description of a program into
lower-level code.  The program described in this chapter is certainly
a compiler in this sense, because it translates rules into Lisp
functions.

   In a more specific sense, to compile is to transform a program into
machine language.  Good Common Lisps compile functions into native
machine code.  As mentioned on page 25, if code which generates
closures is compiled, it will yield compiled closures.  Thus the
program described here is a compiler in the stricter sense as well.
In a good Lisp, our Prolog programs will get translated into machine
language.

   However, the program described here is still not a Prolog compiler.
For programming languages there is a still more specific sense of
"compile," and merely generating machine code is not enough to satisfy
this definition.  A compiler for a programming language must optimize
as well as translate.  For example, if a Lisp compiler is asked to
compile an expression like

     (+ x (+ 2 5))

it should be smart enough to realize that there is no reason to wait
until runtime to evaluate (+ 2 5).  The program can be optimized by
replacing it with 7, and instead compiling

     (+ x 7)

   In our program, all the compiling is done by the Lisp compiler, and
it is looking for Lisp optimizations, not Prolog optimizations.  Its
optimizations will be valid ones, but too low-level.  The Lisp
compiler doesn't know that the code it's compiling is meant to
represent rules.  While a real Prolog compiler would be looking for
rules that could be transformed into loops, our program is looking for
expressions that yield constants, or closures that could be allocated
on the stack.

   Embedded languages allow you to make the most of available
abstractions, but they are not magic.  If you want to travel all the
way from a very abstract representation to fast machine code, someone
still has to tell the computer how to do it.  In this chapter we
travelled a good part of that distance with surprisingly little code,
but that is not the same as writing a true Prolog compiler.


File: onlisp.info,  Node: 25 Object-Oriented Lisp,  Next: Appendix Packages,  Prev: 24 Prolog,  Up: Top

25 25 Object-Oriented Lisp
**************************

This chapter discusses object-oriented programming in Lisp.  Common
Lisp includes a set of operators for writing object-oriented programs.
Collectively they are called the Common Lisp Object System, or CLOS.
Here we consider CLOS not just as a way of writing object-oriented
programs, but as a Lisp program itself.  Seeing CLOS in this light is
the key to understanding the relation between Lisp and object-oriented
programming.

* Menu:

* 25-1 Plus ça Change::         
* 25-2 Objects in Plain Lisp::  
* 25-3 Classes and Instances::  
* 25-4 Methods::                
* 25-5 Auxiliary Methods and Combination::  
* 25-7 When to Object::         


File: onlisp.info,  Node: 25-1 Plus ça Change,  Next: 25-2 Objects in Plain Lisp,  Prev: 25 Object-Oriented Lisp,  Up: 25 Object-Oriented Lisp

25.1 25-1 Plus ça Change
========================

Object-oriented programming means a change in the way programs are
organized.  This change is analogous to the one that has taken place
in the distribution of processor power.  In 1970, a multi-user
computer system meant one or two big mainframes connected to a large
number of dumb terminals.  Now it is more likely to mean a large
number of workstations connected to one another by a network.  The
processing power of the system is now distributed among individual
users instead of centralized in one big computer.

   Object-oriented programming breaks up traditional programs in much
the same way: instead of having a single program which operates on an
inert mass of data, the data itself is told how to behave, and the
program is implicit in the interactions of these new data "objects."

   For example, suppose we want to write a program to find the areas
of two-dimensional shapes.  One way to do this would be to write a
single function which looked at the type of its argument and behaved
accordingly:

     (defun area (x)
       (cond ((rectangle-p x) (* (height x) (width x)))
                ((circle-p x) (* pi (expt (radius x) 2)))))

   The object-oriented approach is to make each object able to
calculate its own area.  The area function is broken apart and each
clause distributed to the appropriate class of object; the area method
of the rectangle class might be

     #'(lambda (x) (* (height x) (width x)))

and for the circle class,

     #'(lambda (x) (* pi (expt (radius x) 2)))

   In this model, we ask an object what its area is, and it responds
according to the method provided for its class.

   The arrival of CLOS might seem a sign that Lisp is changing to
embrace the object-oriented paradigm.  Actually, it would be more
accurate to say that Lisp is staying the same to embrace the
object-oriented paradigm.  But the principles underlying Lisp don't
have a name, and object-oriented programming does, so there is a
tendency now to describe Lisp as an object-oriented language.  It
would be closer to the truth to say that Lisp is an extensible
language in which constructs for object-oriented programming can
easily be written.

   Since CLOS comes pre-written, it is not false advertising to
describe Lisp as an object-oriented language.  However, it would be
limiting to see Lisp as merely that.  Lisp is an object-oriented
language, yes, but not because it has adopted the object-oriented
model.  Rather, that model turns out to be just one more permutation
of the abstractions underlying Lisp.  And to prove it we have CLOS,a
program written in Lisp, which makes Lisp an object-oriented language.

   The aim of this chapter is to bring out the connection between Lisp
and object-oriented programming by studying CLOS as an example of an
embedded language.  This is also a good way to understand CLOS itself:
in the end, nothing explains a language feature more effectively than
a sketch of its implementation.  In Section 7-6, macros were explained
this way.  The next section gives a similar sketch of how to build
object-oriented abstractions on top of Lisp.  This program provides a
reference point from which to describe CLOS in Sections 25-3­25-6.


File: onlisp.info,  Node: 25-2 Objects in Plain Lisp,  Next: 25-3 Classes and Instances,  Prev: 25-1 Plus ça Change,  Up: 25 Object-Oriented Lisp

25.2 25-2 Objects in Plain Lisp
===============================

We can mold Lisp into many different kinds of languages.  There is a
particularly direct mapping between the concepts of object-oriented
programming and the fundamental abstractions of Lisp.  The size of
CLOS tends to obscure this fact.  So before looking at what we can do
with CLOS, let's see what we can do with plain Lisp.Much of what we
want from object-orientedprogramming, we have already in Lisp.  We can
get the rest with surprisingly little code.  In this section, we will
define an object system sufficient for many real applications in two
pages of code.  Object-oriented programming, at a minimum, implies

  1. objects which have properties
  2. and respond to messages,
  3. and which inherit properties and methods from their parents.

   In Lisp, there are already several ways to store collections of
properties.  One way would be to represent objects as hash-tables, and
store their properties as entries within them.  We then have access to
individual properties through gethash:

     (gethash 'color obj)

   Since functions are data objects, we can store them as properties
too.  This means that we can also have methods; to invoke a given
method of an object is to funcall the property of that name:

     (funcall (gethash 'move obj) obj 10)

   We can define a Smalltalk style message-passing syntax upon this
idea:

     (defun tell (obj message &rest args)
       (apply (gethash message obj) obj args))

so that to tell obj to move 10 we can say

     (tell obj 'move 10)

   In fact, the only ingredient plain Lisp lacks is inheritance, and
we can provide a rudimentary version of that in six lines of code, by
defining a recursive version of gethash:

     (defun rget (obj prop)
       (multiple-value-bind (val win) (gethash prop obj)
             (if win
                   (values val win)
                   (let ((par (gethash 'parent obj)))
                     (and par (rget par prop))))))




      (defun rget (obj prop)
         (some2 #'(lambda (a) (gethash prop a))
                  (get-ancestors obj)))

      (defun get-ancestors (obj)
         (labels ((getall (x)
                        (append (list x)
                                  (mapcan #'getall
                                             (gethash 'parents x)))))
             (stable-sort (delete-duplicates (getall obj))
                             #'(lambda (x y)
                                  (member y (gethash 'parents x))))))

      (defun some2 (fn lst)
         (if (atom lst)
              nil
              (multiple-value-bind (val win) (funcall fn (car lst))
                 (if (or val win)
                      (values val win)
                      (some2 fn (cdr lst))))))

   Figure 25-1: Multiple inheritance.

   If we just use rget in place of gethash, we will get inherited
properties and methods.  We specify an object's parent thus:

   (setf (gethash 'parent obj) obj2)

   So far we have only single inheritance-an object can only have one
parent.  But we can have multiple inheritance by making the parent
property a list, and defining rget as in Figure 25-1.  With single
inheritance, when we wanted to retrieve some property of an object, we
just searched recursively up its ancestors.  If the object itself had
no information about the property we wanted, we looked at its parent,
and so on.  With multiple inheritance we want to perform the same kind
of search, but our job is complicated by the fact that an object's
ancestors can form a graph instead of a simple list.  We can't just
search this graph depth-first.  With multiple parents we can have the
hierarchy shown in Figure 25-2: a is descended from b and c, which are
both descended from d.  A depth-first (or rather, height-first)
traversal would go a, b, d, c, d.  If the desired property were
present in both d and c, we would

   352 OBJECT-ORIENTED LISP

   Figure 25-2: Multiple paths to a superclass.

   get the value stored in d, not the one stored in c.  This would
violate the principle that subclasses override the default values
provided by their parents.  If we want to implement the usual idea of
inheritance,we should never examine an object before one of its
descendants.  In this case, the proper search order would be a, b, c,
d.  How can we ensure that the search always tries descendants first?
The simplest way is to assemble a list of all the ancestors of the
original object, sort the list so that no object appears before one of
its descendants, and then look at each element in turn.  This strategy
is used by get-ancestors,which returns a properly ordered list of an
object and its ancestors.  To sort the list, get-ancestors calls
stable-sort instead of sort, to avoid the possibility of reordering
parallel ancestors.  Once the list is sorted, rget merely searches for
the first object with the desired property.  (The utility some2 is a
version of some for use with functions like gethash that indicate
success or failure in the second return value.)  The list of an
object's ancestors goes from most specific to least specific: if
orange is a child of citrus, which is a child of fruit, then the list
will go (orange citrus fruit).  When an object has multiple parents,
their precedence goes left-to-right.  That is, if we say

   (setf (gethash 'parents x) (list y z))

   then y will be considered before z when we look for an inherited
property.  For example, we can say that a patriotic scoundrel is a
scoundrel first and a patriot second:

   > (setq scoundrel (make-hash-table) patriot (make-hash-table)
patriotic-scoundrel (make-hash-table)) #<Hash-Table C4219E>

   (defun obj (&rest parents) (let ((obj (make-hash-table))) (setf
(gethash 'parents obj) parents) (ancestors obj) obj))

   (defun ancestors (obj) (or (gethash 'ancestors obj) (setf (gethash
'ancestors obj) (get-ancestors obj))))

   (defun rget (obj prop) (some2 #'(lambda (a) (gethash prop a))
(ancestors obj)))

   Figure 25-3: A function to create objects.

     > (setf (gethash 'serves scoundrel) 'self
                 (gethash 'serves patriot)             'country
                 (gethash 'parents patriotic-scoundrel)
                              (list scoundrel patriot))
     (#<Hash-Table C41C7E> #<Hash-Table C41F0E>)
     > (rget patriotic-scoundrel 'serves)
     SELF
     T

   Let's make some improvements to this skeletal system.  We could
begin with a function to create objects.  This function should build a
list of an object's ancestors at the time the object is created.  The
current code builds these lists when queries are made, but there is no
reason not to do it earlier.  Figure 25-3 defines a function called
obj which creates a new object, storing within it a list of its
ancestors.  To take advantage of stored ancestors, we also redefine
rget.

   Another place for improvement is the syntax of message calls.  The
tell itself is unnecessary clutter, and because it makes verbs come
second, it means that our programs can no longer be read like normal
Lisp prefix expressions: (tell (tell obj 'find-owner) 'find-owner)

   We can get rid of the tell syntax by defining each property name as
a function, as in Figure 25-4.  The optional argument meth?, if true,
signals that this property should be treated as a method.  Otherwise
it will be treated as a slot, and the value retrieved by rget will
simply be returned.  Once we have defined the name of either kind of
property,

          (defmacro defprop (name &optional meth?)
            `(progn
                (defun ,name (obj &rest args)
                  ,(if meth?
                        `(run-methods obj ',name args)
                        `(rget obj ',name)))
                (defsetf ,name (obj) (val)
                  `(setf (gethash ',',name ,obj) ,val))))

          (defun run-methods (obj name args)
            (let ((meth (rget obj name)))
              (if meth
                   (apply meth obj args)
                   (error "No ~A method for ~A." name obj))))

   Figure 25-4: Functional syntax.

     (defprop find-owner t)

   we can refer to it with a function call, and our code will read
like Lisp again:

     (find-owner (find-owner obj))

   Our previous example now becomes somewhat more readable:

     > (progn
             (setq scoundrel (obj))
             (setq patriot (obj))
             (setq patriotic-scoundrel (obj scoundrel patriot))
             (defprop serves)
             (setf (serves scoundrel) 'self)
             (setf (serves patriot) 'country)
             (serves patriotic-scoundrel))
     SELF
     T

   In the current implementation, an object can have at most one
method of a given name.  An object either has its own method, or
inherits one.  It would be convenient to have more flexibility on this
point, so that we could combine local and inherited methods.  For
example, we might want the move method of some object to be the move
method of its parent, but with some extra code run before or
afterwards.

   To allow for such possibilities, we will modify our program to
include before-, after-, and around-methods.  Before-methods allow us
to say "But first, do this."  They are called, most specific first, as
a prelude to the rest of the method call.  After-methods allow us to
say "P.S. Do this too."  They are called, most specific last, as an
epilogue to the method call.  Between them, we run what used to be the
whole method, and is now called the primary method.  The value of this
call is the one returned, even if after-methods are called later.
Before- and after-methods allow us to wrap new behavior around the
call to the primary method.  Around-methods provide a more drastic way
of doing the same thing.  If an around-method exists, it will be
called instead of the primary method.  Then, at its own discretion,
the around-method may itself invoke the primary method (via call-next,
which will be provided in Figure 25-7).  To allow auxiliary methods,
we modify run-methods and rget as in Fig- ures 25-5 and 25-6.  In the
previous version, when we ran some method of an object, we ran just
one function: the most specific primary method.  We ran the first
method we encountered when searching the list of ancestors.  With
auxiliary methods, the calling sequence now goes as follows:

   1.  The most specific around-method, if there is one.

   2.  Otherwise, in order:

   (a) All before-methods, from most specific to least specific.  (b)
The most specific primary method (what we used to call).  (c) All
after-methods, from least specific to most specific.

   Notice also that instead of being a single function, a method
becomes a four- part structure.  To define a (primary) method, instead
of saying:

   (setf (gethash 'move obj) #'(lambda ...))

   we say:

   (setf (meth-primary (gethash 'move obj)) #'(lambda ...))

   For this and other reasons, our next step should be to define a
macro for defining methods.  Figure 25-7 shows the definition of such
a macro.  The bulk of this code is taken up with implementing two
functions that methods can use to refer to other methods.  Around- and
primary methods can use call-next to invoke the next method, which is
the code that would have run if the current method didn't exist.  For
example, if the currently running method is the only around-method,
the next

   (defstruct meth around before primary after)

   (defmacro meth- (field obj) (let ((gobj (gensym))) '(let ((,gobj
,obj)) (and (meth-p ,gobj) (,(symb 'meth- field) ,gobj)))))

   (defun run-methods (obj name args) (let ((pri (rget obj name
:primary))) (if pri (let ((ar (rget obj name :around))) (if ar (apply
ar obj args) (run-core-methods obj name args pri))) (error "No primary
~A method for ~A." name obj))))

   (defun run-core-methods (obj name args &optional pri)
(multiple-value-prog1 (progn (run-befores obj name args) (apply (or
pri (rget obj name :primary)) obj args)) (run-afters obj name args)))

   (defun rget (obj prop &optional meth (skip 0)) (some2 #'(lambda (a)
(multiple-value-bind (val win) (gethash prop a) (if win (case meth
(:around (meth- around val)) (:primary (meth- primary val)) (t (values
val win)))))) (nthcdr skip (ancestors obj))))

   Figure 25-5: Auxiliary methods.

   method would be the usual sandwich of before-, most specific
primary, and after- methods.  Within the most specific primary method,
the next method would be the second most specific primary method.
Since the behavior of call-next depends on where it is called, it is
never defined globally with a defun, but is defined locally within
each method defined by defmeth.

   (defun run-befores (obj prop args) (dolist (a (ancestors obj)) (let
((bm (meth- before (gethash prop a)))) (if bm (apply bm obj args)))))

   (defun run-afters (obj prop args) (labels ((rec (lst) (when lst
(rec (cdr lst)) (let ((am (meth- after (gethash prop (car lst))))) (if
am (apply am (car lst) args)))))) (rec (ancestors obj))))

   Figure 25-6: Auxiliary methods (continued).

   An around- or primary method can use next-p to check whether there
is a next method.  If the current method is the primary method of an
object with no parents, for example, there would be no next method.
Since call-next yields an error when there is no next method, next-p
should usually be called to test the waters first.  Like call-next,
next-p is defined locally within individual methods.  The new macro
defmeth is used as follows.  If we just want to define the area method
of the rectangle object, we say

   (setq rectangle (obj)) (defprop height) (defprop width) (defmeth
(area) rectangle (r) (* (height r) (width r)))

   Now the area of an instance is calculated according to the method
of the class:

   > (let ((myrec (obj rectangle))) (setf (height myrec) 2 (width
myrec) 3) (area myrec)) 6

   (defmacro defmeth ((name &optional (type :primary)) obj parms &body
body) (let ((gobj (gensym))) '(let ((,gobj ,obj)) (defprop ,name t)
(unless (meth-p (gethash ',name ,gobj)) (setf (gethash ',name ,gobj)
(make-meth))) (setf (,(symb 'meth- type) (gethash ',name ,gobj))
,(build-meth name type gobj parms body)))))

   (defun build-meth (name type gobj parms body) (let ((gargs
(gensym))) '#'(lambda (&rest ,gargs) (labels ((call-next () ,(if (or
(eq type :primary) (eq type :around)) '(cnm ,gobj ',name (cdr ,gargs)
,type) '(error "Illegal call-next.")))  (next-p () ,(case type
(:around '(or (rget ,gobj ',name :around 1) (rget ,gobj ',name
:primary))) (:primary '(rget ,gobj ',name :primary 1)) (t nil))))
(apply #'(lambda ,parms ,@body) ,gargs)))))

   (defun cnm (obj name args type) (case type (:around (let ((ar (rget
obj name :around 1))) (if ar (apply ar obj args) (run-core-methods obj
name args)))) (:primary (let ((pri (rget obj name :primary 1))) (if
pri (apply pri obj args) (error "No next method."))))))

   Figure 25-7: Defining methods.

   (defmacro undefmeth ((name &optional (type :primary)) obj) '(setf
(,(symb 'meth- type) (gethash ',name ,obj)) nil))

   Figure 25-8: Removing methods.

   In a more complicated example, suppose we have defined a backup
method for the filesystem object:

   (setq filesystem (obj)) (defmeth (backup :before) filesystem (fs)
(format t "Remember to mount the tape.~%")) (defmeth (backup)
filesystem (fs) (format t "Oops, deleted all your files.~%") 'done)
(defmeth (backup :after) filesystem (fs) (format t "Well, that was
easy.~%"))

   The normal sequence of calls will be as follows:

   > (backup (obj filesystem)) Remember to mount the tape.  Oops,
deleted all your files.  Well, that was easy.  DONE

   Later we want to know how long backups take, so we define the
following around- method:

   (defmeth (backup :around) filesystem (fs) (time (call-next)))

   Now whenever backup is called on a child of filesystem (unless more
specific around-methods intervene) our around-method will be called.
It calls the code that would ordinarily run in a call to backup, but
within a call to time.  The value returned by time will be returned as
the value of the call to backup:

   > (backup (obj filesystem)) Remember to mount the tape.  Oops,
deleted all your files.  Well, that was easy.  Elapsed Time = .01
seconds DONE

   Once we are finished timing the backups, we will want to remove the
around- method.  That can be done by calling undefmeth (Figure 25-8),
which takes the same first two arguments as defmeth:

   (undefmeth (backup :around) filesystem)

   Another thing we might want to alter is an object's list of
parents.  But after any such change, we should also update the list of
ancestors of the object and all its children.  So far, we have no way
of getting from an object to its children, so we must also add a
children property.  Figure 25-9 contains code for operating on
objects' parents and children.  Instead of getting at parents and
children via gethash, we use the operators parents and children.  The
latter is a macro, and therefore transparent to setf.  The former is a
function whose inversion is defined by defsetf to be set-parents,
which does everything needed to maintain consistency in the new
doubly-linked world.  To update the ancestors of all the objects in a
subtree, set-parents calls maphier, which is like a mapc for
inheritance hierarchies.  As mapc calls a function on every element of
a list, maphier calls a function on an object and all its descendants.
Unless they form a proper tree, the function could get called more
than once on some objects.  Here this is harmless, because
get-ancestors does the same thing when called multiple times.  Now we
can alter the inheritance hierarchy just by using setf on an object's
parents:

   > (progn (pop (parents patriotic-scoundrel)) (serves
patriotic-scoundrel)) COUNTRY T

   When the hierarchy is modified, affected lists of children and
ancestors will be updated automatically.  (The children are not meant
to be manipulated directly, but they could be if we defined a
set-children analogous to set-parents.)  The last function in Figure
25-9 is obj redefined to use the new code.  As a final improvement to
our system, we will make it possible to specify new ways of combining
methods.  Currently, the only primary method that gets called is the
most specific (though it can call others via call-next).  Instead we
might like to be able to combine the results of the primary methods of
each of an object's ancestors.  For example, suppose that my-orange is
a child of orange, which is a child of citrus.  If the props method
returns (round acidic) for citrus, (orange sweet) for orange, and
(dented) for my-orange, it would be convenient to be able to make
(props my-orange) return the union of all these values: (dented orange
sweet round acidic).

   (defmacro children (obj) '(gethash 'children ,obj))

   (defun parents (obj) (gethash 'parents obj))

   (defun set-parents (obj pars) (dolist (p (parents obj)) (setf
(children p) (delete obj (children p)))) (setf (gethash 'parents obj)
pars) (dolist (p pars) (pushnew obj (children p))) (maphier #'(lambda
(obj) (setf (gethash 'ancestors obj) (get-ancestors obj))) obj) pars)

   (defsetf parents set-parents)

   (defun maphier (fn obj) (funcall fn obj) (dolist (c (children obj))
(maphier fn c)))

   (defun obj (&rest parents) (let ((obj (make-hash-table))) (setf
(parents obj) parents) obj))

   Figure 25-9: Maintaining parent and child links.

   We could have this if we allowed methods to apply some function to
the values of all the primary methods, instead of just returning the
value of the most specific.  Figure 25-10 contains a macro which
allows us to define the way methods are combined, and a new version of
run-core-methods which can perform method combination.  We define the
form of combination for a method via defcomb, which takes a method
name and a second argument describing the desired combination.  Or-

   (defmacro defcomb (name op) '(progn (defprop ,name t) (setf (get
',name 'mcombine) ,(case op (:standard nil) (:progn '#'(lambda (&rest
args) (car (last args)))) (t op)))))

   (defun run-core-methods (obj name args &optional pri) (let ((comb
(get name 'mcombine))) (if comb (if (symbolp comb) (funcall (case comb
(:and #'comb-and) (:or #'comb-or)) obj name args (ancestors obj))
(comb-normal comb obj name args)) (multiple-value-prog1 (progn
(run-befores obj name args) (apply (or pri (rget obj name :primary))
obj args)) (run-afters obj name args)))))

   (defun comb-normal (comb obj name args) (apply comb (mapcan
#'(lambda (a) (let* ((pm (meth- primary (gethash name a))) (val (if pm
(apply pm obj args)))) (if val (list val)))) (ancestors obj))))

   Figure 25-10: Method combination.

   dinarily this second argument should be a function.  However, it
can also be one of :progn, :and, :or,or:standard.  With the former
three, primary meth- ods will be combined as though according to the
corresponding operator, while :standard indicates that we want the
traditional way of running methods.

   (defun comb-and (obj name args ancs &optional (last t)) (if (null
ancs) last (let ((pm (meth- primary (gethash name (car ancs))))) (if
pm (let ((new (apply pm obj args))) (and new (comb-and obj name args
(cdr ancs) new))) (comb-and obj name args (cdr ancs) last)))))

   (defun comb-or (obj name args ancs) (and ancs (let ((pm (meth-
primary (gethash name (car ancs))))) (or (and pm (apply pm obj args))
(comb-or obj name args (cdr ancs))))))

   Figure 25-11: Method combination (continued).

   The central function in Figure 25-10 is the new run-core-methods.
If the method being called has no mcombine property, then the method
call proceeds as before.  Otherwise the mcombine of the method is
either a function (like +)ora keyword (like :or).  In the former case,
the function is just applied to a list of the values returned by all
the primary methods.(1)  In the latter, we use the function associated
with the keyword to iterate over the primary methods.

   The operators and and or have to be treated specially, as in Figure
25-11.  They get special treatment not just because they are special
forms, but because they short-circuit evaluation:

   > (or 1 (princ "wahoo")) 1

   Here nothing is printed because the or returns as soon as it sees a
non-nil argument.  Similarly, a primary method subject to or
combination should never get called if a more specific method returns
true.  To provide such short-circuiting for and and or, we use the
distinct functions comb-and and comb-or.  To implement our previous
example, we would write:

     (setq citrus (obj))
     (setq orange (obj citrus))


     (setq my-orange (obj orange))

     (defmeth (props) citrus (c) '(round acidic))
     (defmeth (props) orange (o) '(orange sweet))
     (defmeth (props) my-orange (m) '(dented))

     (defcomb props #'(lambda (&rest args) (reduce #'union args)))

   after which props would return the union of all the primary method
values: (2)

     > (props my-orange)
     (DENTED ORANGE SWEET ROUND ACIDIC)

   Incidentally, this example suggests a choice that you only have
when doing object- oriented programming in Lisp: whether to store
information in slots or methods.

   Afterward, if we wanted the props method to return to the default
behavior, we just set the method combination back to standard:

     > (defcomb props :standard)
     NIL
     > (props my-orange)
     (DENTED)

   Note that before- and after-methods only run in standard method
combination.  However, around-methods work the same as before.

   The program presented in this section is intended as a model, not
as a real foundation for object-oriented programming.  It was written
for brevity rather than efficiency.  However, it is at least a working
model, and so could be used for experiments and prototypes.  If you do
want to use the program for such purposes, one minor change would make
it much more efficient: don't calculate or store ancestor lists for
objects with only one parent.

   ---------- Footnotes ----------

   (1) A more sophisticated version of this code could use reduce to
avoid consing here.

   (2) Since the combination function for props calls union, the list
elements will not necessarily be in this order.


File: onlisp.info,  Node: 25-3 Classes and Instances,  Next: 25-4 Methods,  Prev: 25-2 Objects in Plain Lisp,  Up: 25 Object-Oriented Lisp

25.3 25-3 Classes and Instances
===============================

The program in the previous section was written to resemble CLOS as
closely as such a small program could.  By understanding it we are
already a fair way towards understanding CLOS. In the next few
sections we will examine CLOS itself.

   In our sketch, we made no syntactic distinction between classes and
instances, or between slots and methods.  In CLOS, we use the defclass
macro to define a class, and we declare the slots in a list at the
same time:

   2

   (defclass circle () (radius center))

   This expression says that the circle class has no superclasses, and
two slots, radius and center.  We can make an instance of the circle
class by saying:

   (make-instance 'circle)

   Unfortunately, we have defined no way of referring to the slots of
a circle,so any instance we make is going to be rather inert.  To get
at a slot we define an accessor function for it:

   (defclass circle () ((radius :accessor circle-radius) (center
:accessor circle-center)))

   Now if we make an instance of a circle, we can set its radius and
center slots by using setf with the corresponding accessor functions:

   > (setf (circle-radius (make-instance 'circle)) 2) 2

   We can do this kind of initialization right in the call to
make-instance if we define the slots to allow it:

   (defclass circle () ((radius :accessor circle-radius :initarg
:radius) (center :accessor circle-center :initarg :center)))

   The :initarg keyword in a slot definition says that the following
argument should become a keyword parameter in make-instance.  The
value of the keyword parameter will become the initial value of the
slot:

   > (circle-radius (make-instance 'circle :radius 2 :center '(0 .
0))) 2

   By declaring an :initform, we can also define slots which
initialize them- selves.  The visible slot of the shape class

   (defclass shape () ((color :accessor shape-color :initarg :color)
(visible :accessor shape-visible :initarg :visible :initform t)))

   will be set to t by default: > (shape-visible (make-instance
'shape)) T If a slot has both an initarg and an initform, the initarg
takes precedence when it is specified: > (shape-visible (make-instance
'shape :visible nil)) NIL Slots are inherited by instances and
subclasses.  If a class has more than one superclass, it inherits the
union of their slots.  So if we define the class screen-circle to be a
subclass of both circle and shape, (defclass screen-circle (circle
shape) nil) then instances of screen-circle will have four slots, two
inherited from each grandparent.  Note that a class does not have to
create any new slots of its own; this class exists just to provide
something instantiable that inherits from both circle and shape.  The
accessors and initargs work for instances of screen-circle just as
they would for instances of circle or shape: > (shape-color
(make-instance 'screen-circle :color 'red :radius 3)) RED We can cause
every screen-circle to have some default initial color by specifying
an initform for this slot in the defclass: (defclass screen-circle
(circle shape) ((color :initform 'purple))) Now instances of
screen-circle will be purple by default, > (shape-color (make-instance
'screen-circle)) PURPLE though it is still possible to initialize the
slot otherwise by giving an explicit :color initarg.  In our sketch of
object-oriented programming, instances inherited values di- rectly
from the slots in their parent classes.  In CLOS, instances do not
have slots in the same way that classes do.  We define an inherited
default for instances by defining an initform in the parent class.  In
a way, this is more flexible, because as well as being a constant, an
initform can be an expression that returns a different value each time
it is evaluated:

   (defclass random-dot () ((x :accessor dot-x :initform (random 100))
(y :accessor dot-y :initform (random 100))))

   Each time we make an instance of a random-dot its x- and y-position
will be a random integer between 0 and 99:

   > (mapcar #'(lambda (name) (let ((rd (make-instance 'random-dot)))
(list name (dot-x rd) (dot-y rd)))) '(first second third)) ((FIRST 25
8) (SECOND 26 15) (THIRD 75 59))

   In our sketch, we also made no distinction between slots whose
values were to vary from instance to instance, and those which were to
be constant across the whole class.  In CLOS we can specify that some
slots are to be shared-that is, their value is the same for every
instance.  We do this by declaring the slot to have :allocation
:class.  (The alternative is for a slot to have :allocation :instance,
but since this is the default there is no need to say so explicitly.)
For example, if all owls are nocturnal, then we can make the nocturnal
slot of the owl class a shared slot, and give it the initial value t:

   (defclass owl () ((nocturnal :accessor owl-nocturnal :initform t
:allocation :class)))

   Now every instance of the owl class will inherit this slot:

   > (owl-nocturnal (make-instance 'owl)) T

   If we change the "local" value of this slot in an instance, we are
actually altering the value stored in the class:

   > (setf (owl-nocturnal (make-instance 'owl)) 'maybe) MAYBE >
(owl-nocturnal (make-instance 'owl)) MAYBE

   This could cause some confusion, so we might like to make such a
slot read- only.  When we define an accessor function for a slot, we
create a way of both reading and writing the slot's value.  If we want
the value to be readable but not writable, we can do it by giving the
slot just a reader function, instead of a full-fledged accessor
function:

   (defclass owl () ((nocturnal :reader owl-nocturnal :initform t
:allocation :class)))

   Now attempts to alter the nocturnal slot of an instance will
generate an error:

   > (setf (owl-nocturnal (make-instance 'owl)) nil) >>Error: The
function (SETF OWL-NOCTURNAL) is undefined.


File: onlisp.info,  Node: 25-4 Methods,  Next: 25-5 Auxiliary Methods and Combination,  Prev: 25-3 Classes and Instances,  Up: 25 Object-Oriented Lisp

25.4 25-4 Methods
=================

Our sketch emphasized the similarity between slots and methods in a
language which provides lexical closures.  In our program, a primary
method was stored and inherited in the same way as a slot value.  The
only difference between a slot and a method was that defining a name
as a slot by

   (defprop area)

   made area a function which would simply retrieve and return a
value, while defining it as a method by

     (defprop area t)

   made area a function which would, after retrieving a value, funcall
it on its arguments.

   In CLOS the functional units are still called methods, and it is
possible to define them so that they each seem to be a property of
some class.  Here we define an area method for the circle class:

     (defmethod area ((c circle))
       (* pi (expt (circle-radius c) 2)))

   The parameter list for this method says that it is a function of
one argument which applies to instances of the circle class.

   We invoke this method like a function, just as in our sketch:

     > (area (make-instance 'circle :radius 1))
     3.14...

   We can also define methods that take additional arguments:

     (defmethod move ((c circle) dx dy)
       (incf (car (circle-center c)) dx)
       (incf (cdr (circle-center c)) dy)
       (circle-center c))

   If we call this method on an instance of circle, its center will be
shifted by dx,dy :

   > (move (make-instance 'circle :center '(1 .  1)) 2 3) (3.4)

   The value returned by the method reflects the circle's new
position.  As in our sketch, if there is a method for the class of an
instance, and for superclasses of that class, the most specific one
runs.  So if unit-circle is a subclass of circle, with the following
area method

     (defmethod area ((c unit-circle)) pi)

   then this method, rather than the more general one, will run when
we call area on an instance of unit-circle.  When a class has multiple
superclasses, their precedence runs left to right.  By defining the
class patriotic-scoundrel as follows

     (defclass scoundrel nil nil)
     (defclass patriot nil nil)
     (defclass patriotic-scoundrel (scoundrel patriot) nil)

   we specify that patriotic scoundrels are scoundrels first and
patriots second.  When there is an applicable method for both
superclasses,

     (defmethod self-or-country? ((s scoundrel))
       'self)

     (defmethod self-or-country? ((p patriot))
       'country)

   the method of the scoundrel class will run:

   > (self-or-country?  (make-instance 'patriotic-scoundrel)) SELF

   The examples so far maintain the illusion that CLOS methods are
methods of some object.  In fact, they are something more general.  In
the parameter list of the move method, the element (c circle) is
called a specialized parameter; it says that this method applies when
the first argument to move is an instance of the circle class.  In a
CLOS method, more than one parameter can be specialized.  The
following method has two specialized and one optional unspecialized
parameter:

     (defmethod combine ((ic ice-cream) (top topping)
                                    &optional (where :here))
        (append (list (name ic) 'ice-cream)
                        (list 'with (name top) 'topping)
                        (list 'in 'a
                              (case where
                                  (:here 'glass)
                                  (:to-go 'styrofoam))
                              'dish)))
   It is invoked when the first two arguments to combine are instances
of ice-cream and topping, respectively.  If we define some minimal
classes to instantiate
     (defclass stuff () ((name :accessor name :initarg :name)))
     (defclass ice-cream (stuff) nil)
     (defclass topping (stuff) nil)
   then we can define and run this method: > (combine (make-instance
'ice-cream :name 'fig) (make-instance 'topping :name 'olive) :here)
(FIG ICE-CREAM WITH OLIVE TOPPING IN A GLASS DISH) When methods
specialize more than one of their parameters, it is difficult to
continue to regard them as properties of classes.  Does our combine
method belong to the ice-cream class or the topping class?  In CLOS,
the model of objects responding to messages simply evaporates.  This
model seems natural so long as we invoke methods by saying something
like: (tell obj 'move 2 3) Then we are clearly invoking the move
method of obj.  But once we drop this syntax in favor of a functional
equivalent:

     (move obj 2 3)

   then we have to define move so that it dispatches on its first
argument-that is, looks at the type of the first argument and calls
the appropriate method.

   Once we have taken this step, the question arises: why only allow
dispatching on the first argument?  CLOS answers: why indeed?  In
CLOS, methods can specialize any number of their parameters-and not
just on user-defined classes, but on Common Lisp types,(1) and even on
individual objects.  Here is a combine method that applies to strings:

     (defmethod combine ((s1 string) (s2 string) &optional int?)
        (let ((str (concatenate 'string s1 s2)))
             (if int? (intern str) str)))

   Which means not only that methods are no longer properties of
classes, but that we can use methods without defining classes at all.

   > (combine "I am not a " "cook.")  "I am not a cook."

   Here the second parameter is specialized on the symbol palindrome:

     (defmethod combine ((s1 sequence) (x (eql 'palindrome))
                                        &optional (length :odd))
        (concatenate (type-of s1)
                               s1
                               (subseq (reverse s1)
                                             (case length (:odd 1) (:even 0)))))

   This particular method makes palindromes of any kind of sequence
elements: (2)

   > (combine '(able was i ere) 'palindrome) (ABLE WAS I ERE I WAS
ABLE)

   At this point we no longer have object-oriented programming, but
something more general.  CLOS is designed with the understanding that
beneath methods there is this concept of dispatch, which can be done
on more than one argument, and can be based on more than an argument's
class.  When methods are built upon this more general notion, they
become independent of individual classes.  Instead of adhering
conceptually to classes, methods now adhere to other methods with the
same name.  In CLOS such a clump of methods is called a generic
function.  All our combine methods implicitly define the generic
function combine.

   We can define generic functions explicitly with the defgeneric
macro.  It is not necessary to call defgeneric to define a generic
function, but it can be a convenient place to put documentation, or
some sort of safety-net for errors.  Here we do both:

     (defgeneric combine (x y &optional z)
        (:method (x y &optional z)
              "I can't combine these arguments.")
        (:documentation "Combines things."))

   Since the method given here for combine doesn't specialize any of
its arguments, it will be the one called in the event no other method
is applicable.

     > (combine #'expt "chocolate")
     "I can't combine these arguments."

   Before, this call would have generated an error.

   Generic functions impose one restriction that we don't have when
methods are properties of objects: when all methods of the same name
get joined into one generic function, their parameter lists must
agree.  That's why all our combine methods had an additional optional
parameter.  After defining the first combine method to take up to
three arguments,it would have caused an error if we attempted to
define another which only took two.

   CLOS requires that the parameter lists of all methods with the same
name be congruent.  Two parameter lists are congruent if they have the
same number of required parameters, the same number of optional
parameters, and compatible use of &rest and &key.  The actual keyword
parameters accepted by different methods need not be the same, but
defgeneric can insist that all its methods accept a certain minimal
set.  The following pairs of parameter lists are all congruent:

     (x)                     (a)
     (x &optional y) (a &optional b)
     (x y &rest z)           (a b &rest c)
     (x y &rest z)           (a b &key c d)

and the following pairs are not:

     (x)                     (a b)
     (x &optional y) (a &optional b c)
     (x &optional y) (a &rest b)
     (x &key x y)            (a)

   Redefining methods is just like redefining functions.  Since only
required parameters can be specialized, each method is uniquely
identified by its generic function and the types of its required
parameters.  If we define another method with the same
specializations, it overwrites the original one.  So by saying:

     (defmethod combine ((x string) (y string)
                                    &optional ignore)
       (concatenate 'string x "+"y))

we redefine what combine does when its first two arguments are
strings.

   Unfortunately, if instead of redefining a method we want to remove
it, there is no built-in converse of defmethod.  Fortunately, this is
Lisp, so we can write

      (defmacro undefmethod (name &rest args)
         (if (consp (car args))
              (udm name nil (car args))
              (udm name (list (car args)) (cadr args))))

      (defun udm (name qual specs)
         (let ((classes (mapcar #'(lambda (s)
                                            `(find-class ',s))
                                         specs)))
             `(remove-method (symbol-function ',name)
                                 (find-method (symbol-function ',name)
                                                    ',qual
                                                    (list ,@classes)))))

   Figure 25-12: Macro for removing methods.

one.  The details of how to remove a method by hand are summarized in
the implementation of undefmethod in Figure 25-12.  We use this macro
by giving arguments similar to those we would give to defmethod,
except that instead of giving a whole parameter list as the second or
third argument, we give just the class-names of the required
parameters.  So to remove the combine method for two strings, we say:

     (undefmethod combine (string string))

   Unspecialized arguments are implicitly of class t, so if we had
defined a method with required but unspecialized parameters:

     (defmethod combine ((fn function) x &optional y)
       (funcall fn x y))

   we could get rid of it by saying

     (undefmethod combine (function t))

   If we want to remove a whole generic function, we can do it the
same way we would remove the definition of any function, by calling
fmakunbound:

     (fmakunbound 'combine)

   ---------- Footnotes ----------

   (1) Or more precisely, on the type-like classes that CLOS defines
in parallel with the Common Lisp type hierarchy.

   (2) In one (otherwise excellent) Common Lisp implementation,
concatenate will not accept cons as its first argument, so this call
will not work.


File: onlisp.info,  Node: 25-5 Auxiliary Methods and Combination,  Next: 25-7 When to Object,  Prev: 25-4 Methods,  Up: 25 Object-Oriented Lisp

25.5 25-5 Auxiliary Methods and Combination
===========================================

Auxiliary methods worked in our sketch basically as they do in CLOS.
So far we have seen only primary methods, but we can also have
before-, after- and around- methods.  Such auxiliary methods are
defined by putting a qualifying keyword after the method name in the
call to defmethod.  If we define a primary speak method for the
speaker class as follows:

     (defclass speaker nil nil)

     (defmethod speak ((s speaker) string)
       (format t "~A" string))

   Then calling speak with an instance of speaker just prints the
second argument:

   > (speak (make-instance 'speaker) "life is not what it used to be")
life is not what it used to be NIL

   By defining a subclass intellectual which wraps before- and
after-methods around the primary speak method,

     (defclass intellectual (speaker) nil)

     (defmethod speak :before ((i intellectual) string)
       (princ "Perhaps "))

     (defmethod speak :after ((i intellectual) string)
       (princ " in some sense"))

   we can create a subclass of speakers which always have the last
(and the first) word:

   > (speak (make-instance 'intellectual) "life is not what it used to
be") Perhaps life is not what it used to be in some sense NIL

   In standard method combination, the methods are called as described
in our sketch: all the before-methods, most specific first, then the
most specific primary method, then all the after-methods, most
specific last.  So if we define before- or after-methods for the
speaker superclass,

     (defmethod speak :before ((s speaker) string)
       (princ "I think "))

   they will get called in the middle of the sandwich:

   > (speak (make-instance 'intellectual) "life is not what it used to
be") Perhaps I think life is not what it used to be in some sense NIL

   Regardless of what before- or after-methods get called, the value
returned by the generic function is the value of the most specific
primary method-in this case, the nil returned by format.  This changes
if there are around-methods.  If one of the classes in an object's
family tree has an around-method-or more precisely,if there is an
around-method specialized for the arguments passed to the generic
function-the around-method will get called first, and the rest of the
methods will only run if the around-method decides to let them.  As in
our sketch, an around- or primary method can invoke the next method by
calling a function: the function we defined as call-next is in CLOS
called call-next-method.  There is also a next-method-p, analogous to
our next-p.  With around-methods we can define another subclass of
speaker which is more circumspect:

     (defclass courtier (speaker) nil)

     (defmethod speak :around ((c courtier) string)
       (format t "Does the King believe that ~A? " string)
       (if (eq (read) 'yes)
             (if (next-method-p) (call-next-method))
             (format t "Indeed, it is a preposterous idea.~%"))
       'bow)

   When the first argument to speak is an instance of the courtier
class, the courtier's tongue is now guarded by the around-method:

   > (speak (make-instance 'courtier) "kings will last") Does the King
believe that kings will last?  yes I think kings will last BOW >
(speak (make-instance 'courtier) "the world is round") Does the King
believe that the world is round?  no Indeed, it is a preposterous
idea.  BOW

   Note that, unlike before- and after-methods, the value returned by
the around- method is returned as the value of the generic function.

   Generally, methods are run as in this outline, which is reprinted
from Sec- tion 25-2:

   1.  The most specific around-method, if there is one.

   2.  Otherwise, in order:

   (a) All before-methods, from most specific to least specific.  (b)
The most specific primary method.  (c) All after-methods, from least
specific to most specific.

   This way of combining methods is called standard method
combination.  As in our sketch, it is possible to define methods which
are combined in other ways: for example, for a generic function to
return the sum of all the applicable primary methods.

   In our program, we specified how to combine methods by calling
defcomb.  By default, methods were combined as in the outline above,
but by saying, for example,

     (defcomb price #'+)

we could cause the function price to return the sum of all the
applicable primary methods.

   In CLOS this is called operator method combination.  As in our
program, such method combination can be understood as if it resulted
in the evaluation of a Lisp expression whose first element was some
operator, and whose arguments were calls to the applicable primary
methods, in order of specificity.  If we defined the price generic
function to combine values with +, and there were no applicable
around-methods, it would behave as though it were defined:

     (defun price (&rest args)
       (+ (apply  most specific primary method  args)
              ...(apply  leastspecificprimarymethod  args)))

   If there are applicable around-methods, they take precedence, just
as in standard method combination.  Under operator method combination,
an around-methodcan still call the next method via call-next-method.
However, primary methods can no longer use call-next-method.  (This is
a difference from our sketch, where we left call-next available to
such methods.)

   In CLOS, we can specify the type of method combination to be used
by a generic function by giving the optional :method-combination
argument to defgeneric:

     (defgeneric price (x)
       (:method-combination +))

   Now the price method will use + method combination.  If we define
some classes with prices,

     (defclass jacket nil nil)
     (defclass trousers nil nil)
     (defclass suit (jacket trousers) nil)

     (defmethod price + ((jk jacket)) 350)
     (defmethod price + ((tr trousers)) 200)

then when we ask for the price of an instance of suit, we get the sum
of the applicable price methods:

   > (price (make-instance 'suit)) 550

   The following symbols can be used as the second argument to
defmethod or in the :method-combination option to defgeneric:

   + and append list max min nconc or progn

   By calling define-method-combination you can define other kinds of
method combination; see CLTL2, p.  830.

   Once you specify the method combination a generic function should
use, all methods for that function must use the same kind.  Now it
would cause an error if we tried to use another operator (or :before
or :after) as the second argument in a defmethod for price.  If we do
want to change the method combination of price we must remove the
whole generic function by calling fmakunbound.

25.6 25-6 CLOS and Lisp
=======================

CLOS makes a good example of an embedded language.  This kind of
program usually brings two rewards:

   1.  Embedded languages can be conceptually well-integrated with
their envi- ronment, so that within the embedded language we can
continue to think of programs in much the same terms.

   2.  Embedded languages can be powerful, because they take advantage
of all the things that the base language already knows how to do.

   CLOS wins on both counts.  It is very well-integrated with Lisp,
and it makes good use of the abstractions that Lisp has already.
Indeed, we can often see Lisp through CLOS, the way we can see the
shapes of objects through a sheet draped over them.

   It is no accident that we usually speak to CLOS through a layer of
macros.  Macros do transformation,and CLOS is essentially a program
which takes programs built out of object-oriented abstractions, and
translates them into programs built out of Lisp abstractions.

   As the first two sections suggested, the abstractions of
object-oriented pro- gramming map so neatly onto those of Lisp that
one could almost call the former a special case of the latter.  The
objects of object-oriented programming can easily be implemented as
Lisp objects, and their methods as lexical closures.  By taking
advantage of such isomorphisms, we were able to provide a rudimentary
form of object-oriented programming in just a few lines of code, and a
sketch of CLOS in a few pages.

   CLOS is a great deal larger and more powerful than our sketch, but
not so large as to disguise its roots as an embedded language.  Take
defmethod as an example.  Though CLTL2 does not mention it explicitly,
CLOS methods have all the power of lexical closures.  If we define
several methods within the scope of some variable,

     (let ((transactions 0))
       (defmethod withdraw ((a account) amt)
             (incf transactions)
             (decf (balance a) amt))
       (defmethod deposit ((a account) amt)
             (incf transactions)
             (incf (balance a) amt))
       (defun transactions ()
             transactions))

   then at runtime they will share access to the variable, just like
closures.  Methods can do this because, underneath the syntax, they
are closures.  In the expansion of a defmethod, its body appears
intact in the body of a sharp-quoted lambda- expression.

   Section 7-6 suggested that it was easier to conceive of how macros
work than what they mean.  Likewise, the secret to understanding CLOS
is to understand how it maps onto the fundamental abstractions of
Lisp.


File: onlisp.info,  Node: 25-7 When to Object,  Prev: 25-5 Auxiliary Methods and Combination,  Up: 25 Object-Oriented Lisp

25.7 25-7 When to Object
========================

The object-oriented style provides several distinct benefits.
Different programs need these benefits to varying degrees.  At one end
of the continuum there are programs-simulations, for example-which are
most naturally expressed in the abstractions of object-oriented
programming.  At the other end are programs written in the
object-oriented style mainly to make them extensible.

   Extensibility is indeed one of the great benefits of the
object-oriented style.  Instead of being a single monolithic blob of
code, a program is written in small pieces, each labelled with its
purpose.  So later when someone else wants to modify the program, it
will be easy to find the part that needs to be changed.  If we want to
change the way that objects of type ob are displayed on the screen, we
change the display method of the ob class.  If we want to make a new
class of objects like obs but different in a few respects, we can
create a subclass of ob;in the subclass, we change the properties we
want, and all the rest will be inherited by default from the ob class.
And if we just want to make a single ob which behaves differently from
the rest, we can create a new child of ob and modify the child's
properties directly.  If the program was written carefully to begin
with, we can make all these types of modifications without even
looking at the rest of the code.  From this point of view, an
object-oriented program is a program organized like a table: we can
change it quickly and safely by looking up the appropriate entry.

   Extensibility demands the least from the object-oriented style.  In
fact, it demands so little that an extensible program might not need
to be object-oriented at all.  If the preceding chapters have shown
anything, they have shown that Lisp programs do not have to be
monolithic blobs of code.  Lisp offers a whole range of options for
extensibility.  For example, you could quite literally have a program
organized like a table: a program which consisted of a set of closures
stored in an array.

   If it's extensibility you need, you don't have to choose between an
"object- oriented" and a "traditional" program.  You can give a Lisp
program exactly the degree of extensibility it needs, often without
resorting to object-oriented techniques.  A slot in a class is a
global variable.  And just as it is inelegant to use a global variable
where you could use a parameter, it could be inelegant to build a
world of classes and instances when you could do the same thing with
less effort in plain Lisp.  With the addition of CLOS, Common Lisp has
become the most powerful object-oriented language in widespread use.
Ironically, it is also the language in which object-oriented
programming is least necessary.


File: onlisp.info,  Node: Appendix Packages,  Next: Notes,  Prev: 25 Object-Oriented Lisp,  Up: Top

26 Appendix Packages
********************

Packages are Common Lisp's way of grouping code into modules.  Early
dialects of Lisp contained a symbol-table, called the oblist, which
listed all the symbols read so far by the system.  Through a symbol's
entry on the oblist, the system had access to things like its value
and its property list.  A symbol listed in the oblist was said to be
interned.

   Recent dialects of Lisp have split the concept of the oblist into
multiple packages.  Now a symbol is not merely interned, but interned
in a particular package.  Packages support modularity because symbols
interned in one package are only accessible in other packages (except
by cheating) if they are explicitly declared to be so.

   A package is a kind of Lisp object.  The current package is always
stored in the global variable *package*.  When Common Lisp starts up,
the current package will be the user package: either user (in CLTL1
implementations), or common-lisp-user (in CLTL2 implementations).

   Packages are usually identified by their names, which are strings.
To find the name of the current package, try:

   > (package-name *package*) "COMMON-LISP-USER" Usually a symbol is
interned in the package that was current at the time it was read.  To
find the package in which a symbol is interned, we can use
symbol-package: > (symbol-package 'foo) #<Package "COMMON-LISP-USER"
4CD15E>

   The return value here is the actual package object.  For future
use, let's give foo a value:

   > (setq foo 99) 99

   By calling in-package we can switch to a new package, creating it
if necessary:(1)

   > (in-package 'mine :use 'common-lisp) #<Package "MINE" 63390E>

   At this point there should be eerie music, because we are in a
different world: foo here is not what it used to be.

   MINE> foo >>Error: FOO has no global value.

   Why did this happen?  Because the foo we set to 99 above is a
distinct symbol from foo here in mine.(2)  To refer to the original
foo from outside the user package, we must prefix the package name and
two colons:

   MINE> common-lisp-user::foo 99

   So different symbols with the same print-name can coexist in
different pack- ages.  There can be one foo in package
common-lisp-user and another foo in package mine, and they will be
distinct symbols.  In fact, that's partly the point of packages: if
you're writing your program in a separate package, you can choose
names for your functions and variables without worrying that someone
will use the same name for something else.  Even if they use the same
name, it won't be the same symbol.

   Packages also provide a means of information-hiding.  Programs must
refer to functions and variables by their names.  If you don't make a
given name available outside your package, it becomes unlikely that
code in another package will be able to use or modify what it refers
to.

   In programs it's usually bad style to use package prefixes with
double colons.  By doing so you are violating the modularity that
packages are supposed to provide.  If you have to use a double colon
to refer to a symbol, it's because someone didn't want you to.

   Usually one should only refer to symbols which have been exported.
By exporting a symbol from the package in which it is interned, we
cause it to be visible to other packages.  To export a symbol we call
(you guessed it) export:

     MINE> (in-package 'common-lisp-user)
     #<Package "COMMON-LISP-USER" 4CD15E>
     > (export 'bar)
     T> (setq bar 5)
     5

   Now when we return to mine, we can refer to bar with only a single
colon, because it is a publicly available name:

     > (in-package 'mine)
     #<Package "MINE" 63390E>
     MINE> common-lisp-user:bar
     5

   By importing bar into mine we can go one step further, and make
mine actually share the symbol bar with the user package:

   MINE> (import 'common-lisp-user:bar) TMINE> bar 5

   After importing bar we can refer to it without any package
qualifier at all.  The two packages now share the same symbol; there
can't be a distinct mine:bar.

   What if there already was one?  In that case, the call to import
would have caused an error, as we see if we try to import foo:

   MINE> (import 'common-lisp-user::foo) >>Error: FOO is already
present in MINE.

   Before, when we tried unsuccessfully to evaluate foo in mine, we
thereby caused a symbol foo to be interned there.  It had no global
value and therefore generated an error, but the interning happened
simply as a consequence of typing its name.  So now when we try to
import foo into mine, there is already a symbol there with the same
name.

   We can also import symbols en masse by defining one package to use
another:

   MINE> (use-package 'common-lisp-user) T

   Now all symbols exported by the user package will automatically be
imported by mine.  (If foo had been exported by the user package, this
call would also have generated an error.)

   As of CLTL2, the package containing the names of built-in operators
and variables is called common-lisp instead of lisp, and new packages
no longer use it by default.  Since we used this package in the call
to in-package which created mine, all of Common Lisp's names will be
visible here:

   MINE> #'cons #<Compiled-Function CONS 462A3E>

   You're practically compelled to make any new package use
common-lisp (or some other package containing Lisp operators).
Otherwise you wouldn't even be able to get out of the new package.

   As with compilation, operations on packages are not usually done at
the toplevel like this.  More often the calls are contained in source
files.  Generally it will suffice to begin a file with an in-package
and a defpackage.  (The defpackage macro is new in CLTL2, but some
older implementations provide it.)  Here is what you might put at the
top of a file containing a distinct package of code:

   (in-package 'my-application :use 'common-lisp)

   (defpackage my-application (:use common-lisp my-utilities)
(:nicknames app) (:export win lose draw))

   This will cause the code in the file-or more precisely, the names
in the file-to be in the package my-application.  As well as
common-lisp, this package uses my-utilities, so any symbols exported
thence can appear without any package prefix in the file.

   The my-application package itself exports just three symbols: win,
lose, and draw.  Since the call to in-package gave my-application the
nickname app, code in other packages will be able to refer to them as
e.g.  app:win.

   The kind of modularity provided by packages is actually a bit odd.
We have modules not of objects, but of names.  Every package that uses
common-lisp imports the name cons, because common-lisp includes a
function with that name.  But in consequence a variable called cons
would also be visible every package that used common-lisp.  And the
same thing goes for Common Lisp's other name-spaces.  If packages are
confusing, this is the main reason why; they're not based on objects,
but on names.

   Things having to do with packages tend to happen at read-time, not
runtime, which can lead to some confusion.  The second expression we
typed:

   (symbol-package 'foo)

   returned the value it did because reading the query created the
answer.  To evaluate this expression, Lisp had to read it, which meant
interning foo.

   As another example, consider this exchange, which appeared above:

   MINE> (in-package 'common-lisp-user) #<Package "COMMON-LISP-USER"
4CD15E> > (export 'bar)

   Usually two expressions typed into the toplevel are equivalent to
the same two expressions enclosed within a single progn.  Not in this
case.  If we try saying

   MINE> (progn (in-package 'common-lisp-user) (export 'bar)) >>Error:
MINE::BAR is not accessible in COMMON-LISP-USER.

   we get an error instead.  This happens because the whole progn
expression is processed by read before being evaluated.  When read is
called, the current package is mine,sobar is taken to be mine:bar.  It
is as if we had asked to export this symbol, instead of
common-lisp-user:bar, from the user package.

   The way packages are defined makes it a nuisance to write programs
which use symbols as data.  For example, if we define noise as
follows:

   (in-package 'other :use 'common-lisp) (defpackage other (:use
common-lisp) (:export noise))

   (defun noise (animal) (case animal (dog 'woof) (cat 'meow) (pig
'oink)))

   then if we call noise from another package with an unqualified
symbol as an argument, it will usually fall off the end of the case
clauses and return nil:

   OTHER> (in-package 'common-lisp-user) #<Package "COMMON-LISP-USER"
4CD15E> > (other:noise 'pig) NIL

   That's because what we passed as an argument was
common-lisp-user:pig(no offense intended), while the case key is
other:pig.  To make noise work as one would expect, we would have to
export all six symbols used within it, and import them into any
package from which we intended to call noise.

   In this case, we could evade the problem by using keywords instead
of ordinary symbols.  If noise had been defined

   (defun noise (animal) (case animal (:dog :woof) (:cat :meow) (:pig
:oink)))

   then we could safely call it from any package:

     OTHER> (in-package 'common-lisp-user)
     #<Package "COMMON-LISP-USER" 4CD15E>
     > (other:noise :pig)
     :OINK

   Keywords are like gold: universal and self-evaluating.  They are
visible every- where, and they never have to be quoted.  A
symbol-driven function like defanaph (page 223) should nearly always
be written to use keywords.

   Packages are a rich source of confusion.  This introduction to the
subject has barely scratched the surface.  For all the details, see
CLTL2, Chapter 11.

   ---------- Footnotes ----------

   (1) In older implementations of Common Lisp, omit the :use
argument.

   (2) Some implementations of Common Lisp print the package name
before the toplevel prompt whenever we are not in the user package.
This is not required, but it is a nice touch.


File: onlisp.info,  Node: Notes,  Next: Book's Index,  Prev: Appendix Packages,  Up: Top

27 Notes
********

This section is also intended as a bibliography.  All the books and
papers listed here should be considered recommended reading.

   v Foderaro, John K. Introduction to the Special Lisp Section.  CACM
34, 9 (September 1991), p.  27.  viii The final Prolog implementation
is 94 lines of code.  It uses 90 lines of utilities from previous
chapters.  The ATN compiler adds 33 lines, for a total of 217.  Since
Lisp has no formal notion of a line, there is a large margin for error
when measuring the length of a Lisp program in lines.  ix Steele, Guy
L., Jr.  Common Lisp: the Language, 2nd Edition.  Digital Press,
Bedford (MA), 1990.  5 Brooks, Frederick P. The Mythical Man-Month.
Addison-Wesley, Reading (MA), 1975, p.  16.  18 Abelson, Harold, and
Gerald Jay Sussman, with Julie Sussman.  Structure and Interpretation
of Computer Programs.  MIT Press, Cambridge, 1985.  21 More precisely,
we cannot define a recursive function with a single lambda-expression.
We can, however, generate a recursive function by writing a function
to take itself as an additional argument,

   (setq fact #'(lambda (f n) (if (= n 0) 1(* n (funcall f f (- n
1)))))) and then passing it to a function that will return a closure
in which original function is called on itself:

   (defun recurser (fn) #'(lambda (&rest args) (apply fn fn args)))

   Passing fact to this function yields a regular factorial function,

   > (funcall (recurser fact) 8) 40320

   which could have been expressed directly as:

   ((lambda (f) #'(lambda (n) (funcall f f n))) #'(lambda (f n) (if (=
n 0) 1(* n (funcall f f (- n 1)))))) Many Common Lisp users will find
labels or alambda more convenient.  23 Gabriel, Richard P. Performance
and Standardization.  Proceedings of the First International Workshop
on Lisp Evolution and Standardization, 1988, p.  60.  Testing triangle
in one implementation, Gabriel found that "even when the C compiler is
provided with hand-generated register allocation information, the Lisp
code is 17% faster than an iterative C version of this function."  His
paper mentions several other programs which ran faster in Lisp than in
C, including one that was 42% faster.  24 If you wanted to compile all
the named functions currently loaded, you could do it by calling
compall: (defun compall () (do-symbols (s) (when (fboundp s) (unless
(compiled-function-p (symbol-function s)) (print s) (compile s)))))
This function also prints the name of each function as it is compiled.
26 You may be able to see whether inline declarations are being obeyed
by calling (disassemble 'foo), which displays some representation of
the object code of function foo.  This is also one way to check
whether tail-recursion optimization is being done.  31 One could
imagine nreverse defined as:

   (defun our-nreverse (lst) (if (null (cdr lst)) lst (prog1 (nr2 lst)
(setf (cdr lst) nil))))

   NOTES 389

   (defun nr2 (lst) (let ((c (cdr lst))) (prog1 (if (null (cdr c))
c(nr2 c)) (setf (cdr c) lst)))) 43 Good design always puts a premium
on economy, but there is an additional reason that programs should be
dense.  When a program is dense, you can see more of it at once.
People know intuitively that design is easier when one has a broad
view of one's work.  This is why easel painters use long-handled
brushes, and often step back from their work.  This is why generals
position themselves on high ground, even if they are thereby exposed
to enemy fire.  And it is why programmers spend a lot of money to look
at their programs on large displays instead of small ones.  Dense
programs make the most of one's field of vision.  A general cannot
shrink a battle to fit on a table-top, but Lisp allows you to perform
corresponding feats of abstraction in programs.  And the more you can
see of your program at once, the more likely it is to turn out as a
unified whole.  This is not to say that one should make one's programs
shorter at any cost.  If you take all the newlines out of a function,
you can fit it on one line, but this does not make it easier to read.
Dense code means code which has been made smaller by abstraction, not
text-editing.  Imagine how hard it would be to program if you had to
look at your code on a display half the size of the one you're used
to.  Making your code twice as dense will make programming that much
easier.  44 Steele, Guy L., Jr.  Debunking the "Expensive Procedure
Call" Myth or, Procedu- ral Call Implementations Considered Harmful
or, LAMBDA: The Ultimate GOTO. Proceedings of the National Conference
of the ACM, 1977, p.  157.  48 For reference, here are simpler
definitions of some of the functions in Figures 4-2 and 4-3.  All are
substantially (at least 10%) slower: (defun filter (fn lst) (delete
nil (mapcar fn lst)))

   (defun filter (fn lst) (mapcan #'(lambda (x) (let ((val (funcall fn
x))) (if val (list val)))) lst))

   (defun group (source n) (if (endp source) nil (let ((rest (nthcdr n
source))) (cons (if (consp rest) (subseq source 0 n) source) (group
rest n)))))

   390 NOTES

   (defun flatten (x) (mapcan #'(lambda (x) (if (atom x) (mklist x)
(flatten x))) x))

   (defun prune (test tree) (if (atom tree) tree (mapcar #'(lambda (x)
(prune test x)) (remove-if #'(lambda (y) (and (atom y) (funcall test
y))) tree))))

   49 Written as it is, find2 will generate an error if it runs off
the end of a dotted list:

   > (find2 #'oddp '(2 .  3)) >>Error: 3 is not a list.

   CLTL2 (p.  31) says that it is an error to give a dotted list to a
function expecting a list.  Implementations are not required to detect
this error; some do, some don't.  The situation gets murky with
functions that take sequences generally.  A dotted list is a cons, and
conses are sequences, so a strict reading of CLTL would seem to
require that

   (find-if #'oddp '(2 .  3))

   return nil instead of generating an error, because find-if is
supposed to take a sequence as an argument.  Implementations vary
here.  Some generate an error anyway, and others return nil.  However,
even implementations which follow the strict reading in the case above
tend to deviate in e.g.  the case of (concatenate 'cons '(a .  b) '(c
.  d)), which is likely to return (ac.d)instead of (a c).  In this
book, the utilities which expect lists expect proper lists.  Those
which operate on sequences will accept dotted lists.  However, in
general it would be asking for trouble to pass dotted lists to any
function that wasn't specifically intended for use on them.  66 If we
could tell how many parameters each function had, we could write a
version of compose so that, in f g, multiple values returned by g
would become the correspond- ing arguments to f.  In CLTL2, the new
function function-lambda-expression returns a lambda-expression
representing the original source code of a function.  However, it has
the option of returning nil, and usually does so for built-in func-
tions.  What we really need is a function that would take a function
as an argument and return its parameter list.  73 A version of
rfind-if which searches for whole subtrees could be defined as
follows:

   NOTES 391

   (defun rfind-if (fn tree) (if (funcall fn tree) tree (if (atom
tree) nil (or (rfind-if fn (car tree)) (and (cdr tree) (rfind-if fn
(cdr tree)))))))

   The function passed as the first argument would then have to apply
to both atoms and lists:

   > (rfind-if (fint #'atom #'oddp) '(2 (3 4) 5)) 3> (rfind-if (fint
#'listp #'cddr) '(a (b c d e))) (B C D E)

   95 McCarthy, John, Paul W. Abrahams, Daniel J. Edwards, Timothy P.
Hart, and Michael I. Levin.  Lisp 1.5 Programmer's Manual, 2nd
Edition.  MIT Press, Cam- bridge, 1965, pp.  70-71.  106 When Section
8-1 says that a certain kind of operator can only be written as a
macro, it means, can only be written by the user as a macro.  Special
forms can do everything macros can, but there is no way to define new
ones.  A special form is so called because its evaluation is treated
as a special case.  In an interpreter, you could imagine eval as a big
cond expression:

   (defun eval (expr env) (cond ...  ((eq (car expr) 'quote) (cadr
expr)) ...  (t (apply (symbol-function (car expr)) (mapcar #'(lambda
(x) (eval x env)) (cdr expr))))))

   Most expressions are handled by the default clause, which says to
get the function referred to in the car, evaluate all the arguments in
the cdr, and return the result of applying the former to the latter.
However, an expression of the form (quote x) should not be treated
this way: the whole point of a quote is that its argument is not
evaluated.  So eval has to have one clause which deals specifically
with quote.  Language designers regard special forms as something like
constitutional amend- ments.  It is necessary to have a certain
number, but the fewer the better.  The special forms in Common Lisp
are listed in CLTL2, p.  73.  The preceding sketch of eval is
inaccurate in that it retrieves the function before evaluating the
arguments, whereas in Common Lisp the order of these two operations is
deliberately unspecified.  For a sketch of eval in Scheme, see Abelson
and Sussman, p.  299.

   392 NOTES

   115 It's reasonable to say that a utility function is justified
when it pays for itself in brevity.  Utilities written as macros may
have to meet a stricter standard.  Reading macro calls can be more
difficult than reading function calls, because they can violate the
Lisp evaluation rule.  In Common Lisp, this rule says that the value
of an expression is the result of calling the function named in the
car on the arguments given in the cdr, evaluated left-to-right.  Since
functions all follow this rule, it is no more difficult to understand
a call to find2 than to find-books (page 42).  However, macros
generally do not preserve the Lisp evaluation rule.  (If one did, you
could have used a function instead.)  In principle, each macro defines
its own evaluation rule, and the reader can't know what it is without
reading the macro's definition.  So a macro, depending on how clear it
is, may have to save much more than its own length in order to justify
its existence.  126 The definition of for given in Figure 9-2, like
several others defined in this book, is correct on the assumption that
the initforms in a do expression will be evaluated left-to-right.
CLTL2 (p.  165) says that this holds for the stepforms, but says
nothing one way or the other about the initforms.  There is good cause
to believe that this is merely an oversight.  Usually if the order of
some operations is unspecified, CLTL will say so.  And there is no
reason that the order of evaluation of the initforms of a do should be
unspecified, since the evaluation of a let is left-to-right, and so is
the evaluation of the stepforms in do itself.  128 Common Lisp's
gentemp is like gensym except that it interns the symbol it creates.
Like gensym, gentemp maintains an internal counter which it uses to
make print names.  If the symbol it wants to create already exists in
the current package, it increments the counter and tries again:

   > (gentemp) T1 > (setq t2 1) 1> (gentemp) T3

   and so tries to ensure that the symbol created will be unique.
However, it is still possible to imagine name conflicts involving
symbols created by gentemp.  Though gentemp can guarantee to produce a
symbol not seen before, it cannot foresee what symbols might be
encountered in the future.  Since gensyms work perfectly well and are
always safe, why use gentemp?  Indeed, for macros the only advantage
of gentemp is that the symbols it makes can be written out and read
back in, and in such cases they are certainly not guaranteed to be
unique.  131 The capture of function names would be a more serious
problem in Scheme, due to its single name-space.  Not until 1991 did
the Scheme standard suggest any official way of defining macros.
Scheme's current provision for hygienic macros differs greatly from
defmacro.  For details, and a bibliography of recent research on the
subject, see the most recent Scheme report.

   NOTES 393

   137 Miller, Molly M., and Eric Benson.  Lisp Style and Design.
Digital Press, Bedford (MA), 1990, p.  86.  158 Instead of writing
mvpsetq, it would be cleaner to define an inversion for values.  Then
instead of

   (mvpsetq (w x) (values y z) ...)

   we could say

   (psetf (values w x) (values y z) ...)

   Defining an inversion for values would also render
multiple-value-setq un- necessary.  Unfortunately, as things stand in
Common Lisp it is impossible to define such an inversion;
get-setf-method won't return more than one store variable, and
presumably the expansion function of psetf wouldn't know what to do
with them if it did.  180 One of the lessons of setf is that certain
classes of macros can hide truly enormous amounts of computation and
yet leave the source code perfectly comprehensible.  Eventually setf
may be just one of a class of macros for programming with assertions.
For example, it might be useful to have a macro insist which took
certain ex- pressions of the form (predicate .  arguments), and would
make them true if they weren't already.  As setf has to be told how to
invert references, this macro would have to be told how to make
expressions true.  In the general case, such a macro call might amount
to a call to Prolog.  198 Gelernter, David H., and Suresh Jagannathan.
Programming Linguistics.  MIT Press, Cambridge, 1990, p.  305.  199
Norvig, Peter.  Paradigms of Artificial Intelligence Programming: Case
Studies in Common Lisp.  Morgan Kaufmann, San Mateo (CA), 1992, p.
856.  213 The constant least-negative-normalized-double-float and its
three cousins have the longest names in Common Lisp, with 38
characters each.  The operator with the longest name is
get-setf-method-multiple-value, with 30.  The following expression
returns a list, from longest to shortest, of all the symbols visible
in the current package: (let ((syms nil)) (do-symbols (s) (push s
syms)) (sort syms #'(lambda (x y) (> (length (symbol-name x)) (length
(symbol-name y)))))) 217 As of CLTL2, the expansion function of a
macro is supposed to be defined in the environment where the defmacro
expression appears.  This should make it possible to give propmacro
the cleaner definition:

   394 NOTES

   (defmacro propmacro (propname) '(defmacro ,propname (obj) '(get
,obj ',propname))) But CLTL2 does not explicitly state whether the
propname form originally passed to propmacro is part of the lexical
environment in which the inner defmacro occurs.  In principle, it
seems that if color were defined with (propmacro color),it should be
equivalent to: (let ((propname 'color)) (defmacro color (obj) '(get
,obj ',propname))) or (let ((propname 'color)) (defmacro color (obj)
(list 'get obj (list 'quote propname)))) However, in at least some
CLTL2 implementations, the new version of propmacro does not work.  In
CLTL1, the expansion function of a macro was considered to be defined
in the null lexical environment.  So for maximum portability, macro
definitions should avoid using the enclosing environment anyway.  238
Functions like match are sometimes described as doing unification.
They don't, quite; match will successfully match (f ?x) and ?x, but
those two expressions should not unify.  For a description of
unification, see: Nilsson, Nils J. Problem-Solving Methods in
Artificial Intelligence.  McGraw-Hill, New York, 1971, pp.  175-178.
244 It's not really necessary to set unbound variables to gensyms, or
to call gensym?  at runtime.  The expansion-generating code in Figures
18-7 and 18-8 could be written to keep track of the variables for
which binding code had already been generated.  To do this the code
would have to be turned inside-out, however: instead of generating the
expansion on the way back up the recursion, it would have to be
accumulated on the way down.  244 A symbol like ?x occurring in the
pattern of an if-match always denotes a new variable, just as a symbol
in the car of a let binding clause does.  So although Lisp variables
can be used in patterns, pattern variables from outer queries
cannot-you can use the same symbol, but it will denote a new variable.
To test that two lists have the same first element, it wouldn't work
to write: (if-match (?x .  ?rest1) lst1 (if-match (?x .  ?rest2) lst2
?x)) In this case, the second ?x is a new variable.  If both lst1 and
lst2 had at least one element, this expression would always return the
car of lst2.  However, since you can use (non-?ed) Lisp variables in
the pattern of an if-match, you can get the desired effect by writing:

   NOTES 395

   (if-match (?x .  ?rest1) lst1 (let ((x ?x)) (if-match (x .  ?rest2)
lst2 ?x)))

   The restriction, and the solution, apply to the with-answer and
with-inference macros defined in Chapters 19 and 24 as well.  254 If
it were a problem that "unbound" pattern variables were nil, you could
have them bound to a distinct gensym by saying (defconstant unbound
(gensym)) and then replacing the line

   '(,v (binding ',v ,binds)))

   in with-answer with:

   '(,v (aif2 (binding ',v ,binds) it unbound))

   258 Scheme was invented by Guy L. Steele Jr.  and Gerald J. Sussman
in 1975.  The language is currently defined by: Clinger, William, and
Jonathan A. Rees (Eds.).  Revised4 Report on the Algorithmic Language
Scheme.  1991.  This report, and various implementations of Scheme,
were at the time of printing available by anonymous FTP from
altdorf.ai.mit.edu:pub.  266 As another example of the technique
presented in Chapter 16, here is the derivation of the defmacro
template within the definition of =defun:

   (defmacro fun (x) '(=fun *cont* ,x))

   (defmacro fun (x) (let ((fn '=fun)) '(,fn *cont* ,x)))

   '(defmacro ,name ,parms (let ((fn ',f)) '(,fn *cont* ,,@parms)))

   '(defmacro ,name ,parms '(,',f *cont* ,,@parms))

   267 If you wanted to see multiple return values in the toplevel,
you could say instead:

   (setq *cont* #'(lambda (&rest args) (if (cdr args) args (car
args))))

   273 This example is based on one given in: Wand, Mitchell.
Continuation-Based Program Transformation Strategies.  JACM 27, 1
(January 1980), pp.  166.

   396 NOTES

   273 A program to transform Scheme code into continuation-passing
style appears in: Steele, Guy L., Jr.  LAMBDA: The Ultimate
Declarative.  MIT Artificial Intelligence Memo 379, November 1976, pp.
30-38.  292 These implementations of choose and fail would be clearer
in T, a dialect of Scheme which has push and pop, and allows define in
non-toplevel contexts:

   (define *paths* ()) (define failsym '@)

   (define (choose choices) (if (null?  choices) (fail)
(call-with-current-continuation (lambda (cc) (push *paths* (lambda ()
(cc (choose (cdr choices))))) (car choices)))))

   (call-with-current-continuation (lambda (cc) (define (fail) (if
(null?  *paths*) (cc failsym) ((pop *paths*))))))

   For more on T, see: Rees, Jonathan A., Norman I. Adams, and James
R. Meehan.  The T Manual, 5th Edition.  Yale University Computer
Science Department, New Haven, 1988.  The T manual, and T itself, were
at the time of printing available by anonymous FTP from
hing.lcs.mit.edu:pub/t3-1.  293 Floyd, Robert W. Nondeterministic
Algorithms.  JACM 14, 4 (October 1967), pp.  636-644.  298 The
continuation-passing macros defined in Chapter 20 depend heavily on
the optimization of tail calls.  Without it they may not work for
large problems.  For example, at the time of printing, few computers
have enough memory to allow the Prolog defined in Chapter 24 to run
the zebra benchmark without the optimization of tail calls.  (Warning:
some Lisps crash when they run out of stack space.)  303 It's also
possible to define a depth-first correct choose that works by
explicitly avoiding circular paths.  Here is a definition in T:

   (define *paths* ()) (define failsym '@) (define *choice-pts*
(make-symbol-table))

   (define-syntax (true-choose choices) '(choose-fn ,choices
',(generate-symbol t)))

   NOTES 397

   (define (choose-fn choices tag) (if (null?  choices) (fail)
(call-with-current-continuation (lambda (cc) (push *paths* (lambda ()
(cc (choose-fn (cdr choices) tag)))) (if (mem equal?  (car choices)
(table-entry *choice-pts* tag)) (fail) (car (push (table-entry
*choice-pts* tag) (car choices)))))))) In this version, true-choose
becomes a macro.  (The T define-syntax is like defmacro except that
the macro name is put in the car of the parameter list.)  This macro
expands into a call to choose-fn, a function like the depth-first
choose defined in Figure 22-4, except that it takes an additional tag
argument to identify choice-points.  Each value returned by a
true-choose is recorded in the global hash-table *choice-pts*.
Ifagiventrue-choose is about to return a value it has already
returned, it fails instead.  There is no need to change fail itself;
we can use the fail defined on page 396.  This implementation assumes
that paths are of finite length.  For example, it would allow path as
defined in Figure 22-13 to find a path from a to e in the graph
displayed in Figure 22-11 (though not necessarily a direct one).  But
the true-choose defined above wouldn't work for programs with an
infinite search-space: (define (guess x) (guess-iter x 0))

   (define (guess-iter x g) (if (= x g) g(guess-iter x (+ g
(true-choose '(-1 0 1)))))) With true-choose defined as above, (guess
n) would only terminate for non- positive n.  How we define a correct
choose also depends on what we call a choice point.  This version
treats each (textual) call to true-choose as a choice point.  That
might be too restrictive for some applications.  For example, if
two-numbers (page 291) used this version of choose, it would never
return the same pair of numbers twice, even if it was called by
several different functions.  That might or might not be what we want,
depending on the application.  Note also that this version is intended
for use only in compiled code.  In interpreted code, the macro call
might be expanded repeatedly, each time generating a new gensymed tag.
305 Woods, William A. Transition Network Grammars for Natural Language
Analysis.  CACM 3, 10 (October 1970), pp.  591-606.

   398 NOTES

   312 The original ATN system included operators for manipulating
registers on the stack while in a sub-network.  These could easily be
added, but there is also a more general solution: to insert a
lambda-expression to be applied to the register stack directly into
the code of an arc body.  For example, if the node mods (page 316) had
the following line inserted into the body of its outgoing arc,

   (defnode mods (cat n mods/n ((lambda (regs) (append (butlast regs)
(setr a 1 (last regs))))) (setr mods *)))

   then following the arc (however deep) would set the the topmost
instance of the register a (the one visible when traversing the
topmost ATN)to1.  323 If necessary, it would be easy to modify the
Prolog to take advantage of an existing database of facts.  The
solution would be to make prove (page 336) a nested choose:

   (=defun prove (query binds) (choose (choose-bind b2 (lookup (car
query) (cdr query) binds) (=values b2)) (choose-bind r *rules*
(=funcall r query binds))))

   325 To test quickly whether there is any match for a query, you
could use the following macro:

   (defmacro check (expr) '(block nil (with-inference ,expr (return
t))))

   344 The examples in this section are translated from ones given in:
Sterling, Leon, and Ehud Shapiro.  The Art of Prolog: Advanced
Programming Techniques.  MIT Press, Cambridge, 1986.  349 The lack of
a distinct name for the concepts underlying Lisp may be a serious
barrier to the language's acceptance.  Somehow one can say "We need to
use C++ because we want to do object-oriented programming," but it
doesn't sound nearly as convincing to say "We need to use Lisp because
we want to do Lisp programming."  To administrative ears, this sounds
like circular reasoning.  Such ears would rather hear that Lisp's
value hinged on a single, easily understood concept.  For years we
have tried to oblige them, with little success.  Lisp has been
described as a "list- processing language," a language for "symbolic
computation," and most recently, a "dynamic language."  None of these
phrases captures more than a fraction of what Lisp is about.  When
retailed through college textbooks on programming languages, they
become positively misleading.  Efforts to sum up Lisp in a single
phrase are probably doomed to failure, because the power of Lisp
arises from the combination of at least five or six features.  Perhaps

   NOTES 399

   we should resign ourselves to the fact that the only accurate name
for what Lisp offers is Lisp.  352 For efficiency, sort doesn't
guarantee to preserve the order of sequence elements judged equal by
the function given as the second argument.  For example, a valid
Common Lisp implementation could do this:

   > (let ((v #((2 .  a) (3 .  b) (1 .  c) (1 .  d)))) (sort (copy-seq
v) #'< :key #'car)) #((1 .  D) (1 .  C) (2 .  A) (3 .  B))

   Note that the relative order of the first two elements has been
reversed.  The built-in stable-sort provides a way of sorting which
won't reorder equal elements:

   > (let ((v #((2 .  a) (3 .  b) (1 .  c) (1 .  d)))) (stable-sort
(copy-seq v) #'< :key #'car)) #((1 .  C) (1 .  D) (2 .  A) (3 .  B))

   It is a common error to assume that sort works like stable-sort.
Another common error is to assume that sort is nondestructive.  In
fact, both sort and stable-sort can alter the sequence they are told
to sort.  If you don't want this to happen, you should sort a copy.
The call to stable-sort in get-ancestors is safe because the list to
be sorted has been freshly made.

   400 NOTES


File: onlisp.info,  Node: Book's Index,  Next: Concept Index,  Prev: Notes,  Up: Top

28 Book's Index
***************

aand 191 =apply 267 abbrev 214 arch abbrevs 214 Lisp as 8
abbreviations 213 bottom-up program as 4 Abelson, Harold 18 architects
284 Abelson, Julie 18 Armstrong, Louis vii ablock 193 artificial
intelligence 1 Abrahams, Paul W. 391 asetf 223 :accessor 365
assignment accumulators 23, 47, 394 macros for 170 acond 191 order of
177 acond2 198, 239 parallel 96 Adams, Norman I. 396 in Prolog 343
after 50 and referential transparency 198 aif 191 see also:
generalized variables aif2 198 assoc 196 alambda 193 ATNs 305 Algol 8
arc types 311 allf 169 correctness of 312 :allocation 367 destructive
operations in 313 always 227 like functional programs 316 alrec 205
for natural language 305 anaphora-see macros, anaphoric nondeterminism
in 308 ANSI Common Lisp ix operations on register stack 398 antecedent
322 order of arcs 308 append recursion in 306 Prolog implementation
331 registers of 306, 312 append1 45 represented as functions 309
apply 13 tracing 309 with macros 110 atrec 210 on &rest parameters 137
augmented transition networks-see ATNs

   401

   402 INDEX

   Autocad 1, 5 call-next-method 200, 375 automata theory 292 sketch
of 358 avg 182 call-with-current-continuation awhen 191 (call/cc) 260
awhen2 198 at toplevel 292 awhile 191 capital expenditures 43 awhile2
198 capture 118 avoiding with gensyms 128 backtraces 111 avoiding with
packages 130 backtracking 292 avoiding by prior evaluation 125
backquote (')84 of block names 131 in ATNs 307 detecting potential 121
nested 214, 217, 395 free symbol capture 119 bad-reverse 29 avoiding
125 barbarians 283 of function names 131, 392 Basic 30, 33 intentional
190, 267, 313 battlefield 8 macro argument capture 118 before 50 of
tags 131 Benson, Eric 137 case 15 best 52 >case 152 Bezier curves 185
case-sensitivity 331 =bind 267 chains of closures 76, 269 binding 239
Chocoblobs 298 binding lists 239 choose 287 bindings, altering 107
extent of 291 blackboards 281 choose block 154 Common Lisp version 295
implicit 131, 155 Scheme version 293 block-names 131 choose-bind 295
body (of expressions) 87, 91, 87 chronological backtracking 292 body
(of a rule) 322 classes &body 87 defining 364 bookshops 41 see also:
superclasses bottom-up design v, 3, 321 Clinger, William 395 and
functional arguments 42 CLOS 364 and incremental testing 38 as an
embedded language 349, 377 and shape of programs 4 see also: classes,
generic functions, multilayer 321 methods, slots bound-see variables,
bound closed world assumption 249 break-loop 56 closures 17, 62, 76
brevity viii, 43 CLTL-see Common Lisp: the Language bricks, furniture
made of 117 code-walkers 237, 273 Brooks, Frederick P. 5 Common Lisp:
the Language ix Common Lisp case-sensitivity of 331 C 388 definition
of ix C++ 398

   INDEX 403

   differences between versions complement 62 compilation of closures
25 compose 66 complement 62 composition-see functions, defpackage 384
composition of destructuring-bind 93 conc1 45 dynamic-extent 150
conc1f 170, 174 environment of expanders 96, 393 concf 170 no
expansion in compiled code 136 concnew 170 function-lambda-expression
390 conditionals 108, 150 *gensym-counter* 129 condlet 146 -if-not
deprecated 62 congruent parameter lists 372 ignore-errors 147
consequent 322 inversions from defun 179 consing Lisp package 384
avoiding 31, 150, 197, 363 name of user package 381 constitutional
amendments 391 redefining built-in operators 131, constraints 332 199
*cont* 266 &rest parameters not fresh 137 context symbol-macros 205
and referential transparency 199 with-slots 236 see also:
environments; macros, see also: CLOS, series context-creating
evaluation rule 392 continuations 258 long names in 393 destructive
operations in 261, 313 vs.  Scheme 259 cost of 284 Common Lisp Object
System-see CLOS see also: call-with-current-con- common-lisp 384
tinuation common-lisp-user 381 continuation-passing macros 266 compall
388 use in multiprocessing 283 compilation 24 use in nondeterministic
choice 296 bounds-checking during 186 restrictions on 270 computation
during 109, 181, 197, and tail-recursion optimization 298 254, 335
continuation-passing style (CPS) 273 of embedded languages 116, 254
cookies 184 errors emerging during 139 copy-list 71, 206 inline 26,
109, 110 copy-tree 71, 210 testing 388 courtiers 375 of local
functions 23, 25, 81, 346 cut 337 of macro calls 83, 101, 136 with
fail 342 of networks 79 green 339 restrictions on 25 red 339 senses of
346 in Lisp 298 of queries 254 cut 301 see also: tail-recursion
optimization compile 24, 116, 388 databases compile-file 25 caching
updates to 179 compiled-function-p 24 locks on 148

   404 INDEX

   natural language interfaces to 306 generalization of 156 queries on
246 Dolphin Seafood 219 representation of 247 dotted lists 70, 390
with Prolog 398 duplicate 50 dbind 232 dynamic extent 127, 150 def!
64 dynamic languages 398 defanaph 223 dynamic scope 16 defclass 364
defdelim 228 Edwards, Daniel J. 391 defgeneric 371 elt 244
define-modify-macro 168 Emacs-see Gnu Emacs defmacro 82, 95 embedded
languages 7, 188, 246 defpackage 384 ATNsas309 defprop 354 benefits of
110,116, 246, 377 defun 10, 113 borderline of 246 defining inversions
with 179 compilation of 116 =defun 267 not quite compilers 346 defsetf
178 implementation of 116 delay 211 for multiprocessing 275 delete-if
64 Prolog as 321 density of source code 59, 389 query languages as 246
destruc 232 see also: CLOS destructive operations 31, 64 end-of-file
(eof) 197, 225 destructuring English 306 on arrays 234 environment on
instances 236 argument 95 on lists 230 interactive 8 in macros 93 of
macro expanders 96, 393 and reference 236 of macro expansions 108 on
sequences 231 null 96, 278, 394 on structures 235 error 148
destructuring-bind 93, 213, 230 error-checking 45 differences 207 eval
disassemble 388 explicit 34, 163, 197, 278 dispatching 370, 371 on
macroexpansions 92 do 98 sketch of 391 implicit block in 131
evaluation multiple-valued version 162 avoiding 151, 181 order of
evaluation in 392 lazy 211 do-file 199 order of do-symbols 388, 393 in
Common Lisp 135 do-tuples/c 156 in Scheme 259 do-tuples/o 156 sketch
of 391 do* 97 evaluation rule 392 multiple-valued version 159 evenp 14
dolist 94 evolution

   INDEX 405

   design by 1 funcall 13, 259 of Lisp 158 =funcall 267 of programming
languages 8 function calls, avoiding expander code 99 by inline
compilation 26 expansion code 99 with macros 109 explode 58 by tail
recursion 23 exploratory programming 1, 284 functional interfaces 35
export 383 functional programs 28 :export 384 almost 35 expt 32 and
bottom-up programming 37 extensibility 5 from imperative ones 33 of
object-oriented programs 16, 379 shape of 30 extent, dynamic 127, 150
functions as arguments 13, 42, 177 f 173, 222 constant 226 factions
167 closures of 17, 62, 76 factorials 343, 387 use in nondeterministic
choice 296 fail 287 stack allocation of 150 fail combined with macros
141, 149, 266 Common Lisp version 295 compiled 24 Scheme version 293
composition of 66, 201, 228 failure 195 as a data type 9 fboundp 388
defining 10 fif 67 filleting 115 filter 47 generating recursive 68,
204 simpler version 389 generic-see generic functions find2 50
internal 172 evolution of 41 interpreted 24 find-if 41, 195 as lists
27 sketch of 206 literal 11 version for trees 73 recursive 21, 193
finished programs 285 local 21 fint 67 vs.  macros 109 flatten 47, 72,
210 names of 11, 213 simpler version 389 as properties 15 Floyd,
Robert W. 293 redefining built-in 131, 174 fmakunbound 373 as return
values 17, 61, 76, 201 fn 202, 229 set operations on 67, 201 Foderaro,
John K. v with state 18, 65 for 154 tail-recursive 23 force 211
transforming into macros 102 Fortran 8 undefining 373 free-see
variables, free see also: compilation; defgeneric; fullbind 324 defun;
labels fun x function-lambda-expression 390 fun 67

   406 INDEX

   Gabriel, Richard P. 23 incf 171 garbage generalization of 173
avoiding-see consing, avoiding incremental testing 37 collection 8, 81
indexing 249 generalized variables 107, 165 inheritance meaning of 179
single 196 see also: inversions of slots 366 generic functions 371
multiple 366 defining 371 sketch of 351 removing 373 in-if 152 see
also: methods :initarg 365 gensym 128 :initform 365 to indicate
failure 197 in-package 382 as unbound 244, 330 inq 152 gensym?  243
instances 365 *gensym-counter* 129 intellectuals 374 gentemp 392
interactive development 37, 316 Gelernter, David H. 198 interactive
environment 8 get 63 intercourse, lexical 108 gethash 196 Interleaf 1,
5 recursive version 350 intern 128, 136, 266 get-setf-method 171
interning 128, 136, 381 gift-shops, airport 278 intersection 207 Gnu
Emacs 1, 5 intersections 207 go 100, 155 inversions gods 8 asymmetric
179 gold 386 defining 178 good-reverse 30 see also: generalized
variables group 47 iteration simpler version 389 macros for 108, 154
vs.  nondeterministic choice 291, 325 Hart, Timothy P. 391 without
loops 264, 325 hash tables 65, 247, 350 head 322 Jagannathan, Suresh
198 hiding implementation details 216, 382 jazz vii hygienic macros
392 joiner 62 joke, practical-see Nitzberg, Mark ice-cream 370
ice-skating 33 keywords 386 if3 150 if-match 242 labels 21
ignore-errors 147 lambda 11 Igor 289 =lambda 267 imperative
programming 33 lambda-expressions 11, 21 import 383 last 45 in 152
last1 45

   INDEX 407

   Latin 306 macro-characters-see read-macros lawyers 298 macros 82
let 144, 199 as abbreviations 213 let* 172 access 167, 216 lengths of
programs 387 anaphoric 189 Levin, Michael I. 391 defining
automatically 218 lexical scope 16 for distinguishing failure from
fal- life, meaning of 197 sity 195 lions 37 for generating recursive
functions Lisp 204 1.5 95 multiple-valued 198 defining features of 1,
8, 349, 398 and referential transparency 198 integration with user
programs 110 see also: call-next-method slowness of 285 and apply 110
speed of 388 applications of 111 see also Common Lisp, Scheme, T
arguments to 107 lists for building functions 201 accumulating 47
calls invertible 166, 216 as binary trees 70 clarity 99, 233 as code
116 and CLOS 378 decreased role of 44 for computation at compile-time
181 disambiguating return values with 196 context-creating 143 dotted
390 combined with functions 141, 149, as facts 247 266 flat-see
flatten compiled 83, 101, 136 interleaving 160 complex 96 operating on
end of 170 defining 82 quoted 37 efficiency 99 recursers on 68, 204
environment argument to 95 as trees 262 environment of expander 96,
393 uses for 70 environment of expansion 108 list processing 44, 398
errors in locality 36 modifying arguments 137 logic programs 334
modifying expansions 139 longer 47 non-functional expanders 136
simpler version 389 nonterminating expansion 139 loop 154 number of
evaluations 133, 167 loops order of evaluation 135 interrupting 154
see also: capture see also: iteration expansion of 83 lrec 69 in
compiled code 136 multiple 136, 138 McCarthy, John 1, 391
non-terminating 139 mac 92 testing 92 macroexpand 91 time of 83
macroexpand-1 91 from functions 102

   408 INDEX

   vs.  functions 109 misuse of 151 hygienic 392 Prolog implementation
332 justification of 392 returns a cdr 50 macro-defining 213, 266
Miller, Molly M. 137 parameter lists 93 member-if 196 position in
source code 102, 266 memq 88 as programs 96 memoizing 65, 174
proportion in a program 117 message-passing 350 recursion in 139 vs.
Lisp syntax 353 redefining 101, 138 methods built-in 199 adhere to one
another 369 simple 88 after- 374 skeletons of 121 sketch of 357 style
for 99 around- 375 testing 91 sketch of 356 unique powers of 106
auxiliary 374 when to use 106 sketch of 356 see also: backquote,
read-macros, before- 374 symbol-macros sketch of 357 mainframes 348 of
classes 368 make-dispatch-macro-character 226 without classes 371
make-instance 365 as closures 378 make-hash-table 65 redefining 372
make-string 58 removing 373 map-> 54 sketch of 359 map0-n 54
isomorphic to slots 368 map1-n 54 specialization of 369 mapa-b 54, 228
on objects 371 mapc 163 on types 370 mapcan 41, 46 see also: generic
functions nondestructive version 55 method combination sketch of 55
and mapcar 13 sketch of 363 version for multiple lists 55 operator 376
version for trees 55 sketch of 362 mapcars 54 or mapcon 176, 218
sketch of 363 mappend 54 progn mappend-mklist idiom 160 sketch of 362
mapping functions 53 standard 376 mark 301 sketch of 358 match 239
:method-combination 377 matching-see pattern-matching Michelangelo 11
maxmin 207 mines 264 Meehan, James R. 396 mklist 45, 160 member 88
mkstr 58

   INDEX 409

   modularity 167, 381, 382 restrictions on 297 de Montaigne, Michel 2
and tail-recursion optimization 298, most 52 396 most-of 182 Scheme
implementation 293 mostn 52 appearance of foresight 289 moving parts 4
breadth-first 303 multiple inheritance-see inheritance, correct 302
multiple depth-first 292 multiple values 32 in ATNs 308 to avoid
side-effects 32 nonterminating 293 to distinguish failure from falsity
196, in Prolog 334 239 in functional programs 286 in generalized
variables 172 vs.  iteration 291, 325 iteration with 158 optimizing
298 receiving-see multiple-value-bind and parsing-see ATNs
returning-see values and search 290 multiple-value-bind 32 see also:
choose, fail leftover parameters nil 234 Norvig, Peter 199
multiprocessing 275 nreverse 31 mvdo 162 sketch of 388 mvdo* 159
nthmost 183 mvpsetq 161 Mythical Man-Month, The 5 object-oriented
programming dangers of 379 name-spaces 12, 205, 259, 273, 384, 392
defining features of 350 natural language-see ATNs like distributed
systems 348 nconc 31, 35, 137 and extensibility 16, 379 negation name
of 349 of facts 249 in plain Lisp 349 in Prolog 325 see also: C++;
classes; CLOS; generic in queries 252 functions; inheritance; methods;
networks message-passing; slots; Smalltalk representing 76, 79 on-cdrs
205 next-method-p 375 on-trees 210 sketch of 358 open systems 6
:nicknames 384 open-coding-see compilation, inline nif 150
orthogonality 63 nildefault block name 131 *package* 125, 381
forbidden in case clauses 153 packages 381 multiple roles of 51, 195
aberrations involving 384 nilf 169 avoiding capture with 130, 131
Nitzberg, Mark-see joke, practical creating 382 nondeterministic
choice 286 current 381 Common Lisp implementation 295 using distinct
131, 382 need for CPS macros 296 inheriting symbols from 384

   410 INDEX

   nicknames for 384 order of 329 switching 382 subverting 346 user
381 syntax of 331 see also: intern; interning promises 211 parsers,
nondeterministic-see ATNs prompt 56 paths, traversing 155 property
lists 15, 63, 216 pat-match 242 propmacro 216 pattern-matching 186,
238 alternative definition 393 pattern variables 238 propmacros 216
phrenology 30 prune 47 planning 2 simpler version 389 pointers 76
pruning search trees-see cut pools 313 psetq 96 popn 173
multiple-valued version 161 pop-symbol 220 pull 173, 223 position 49
pull-if 173 *print-array* 245 push-nreverse idiom 47 *print-circle* 70
pushnew 174 print-names 57, 129, 382 processes 275 queries
instantiation of 278 complex 249, 335 scheduling of 279 conditional
191 state of 278 query languages 249 proclaim 23, 45 quicksort 345
productivity 5 quote 84, 391 programming languages see also: '
battlefield of 8 quoted lists, returning 37, 139 embedded-see embedded
languages expressive power of vii extensible 5 rapid prototyping 1,
284 high-level 8 of individual functions 24, 48 see also: Algol;
Basic; C; C++; Com- read 56, 128, 197, 224 mon Lisp; Fortran; Lisp;
Pro- read-delimited-list 227 log; Scheme; Smalltalk; T :reader 367
Prolog 321 read-eval-print loop 57 assignment in 343 read-from-string
58 calling Lisp from 343 read-line 56 case-sensitivity of 331 readlist
56 conceptual ingredients 321 read-macros 224 nondeterminism in 333
recurser 388 programming techniques 332 recursion restrictions on
variables 344 on cdrs 68, 204 rules 329 in grammars 306 bodyless 323,
330 in macros 139, 192 implicit conjunction in body 328 without naming
388 left-recursive 334 on subtrees 70, 208 tail- 23, 140

   INDEX 411

   reduce 207, 363 setf 165 Rees, Jonathan A. 395, 396 see also:
generalized variables, inver- referential transparency 198 sions
remove-duplicates set-macro-character 224 sketch of 206 setq remove-if
14 destroys referential transparency 198 remove-if-not 40 ok in
expansions 100 rep 324 now redundant 170 reread 58 Shapiro, Ehud 398
&rest parameters 87 sharp (#) 226 not guaranteed fresh 137 shuffle 161
in utilities 174 side-effects 28 return 131, 155 destroy locality 36
return-from 131, 154 in macro expanders 136 return values mitigating
35 functions as-see functions, as return on &rest parameters 137
values on quoted objects 37 multiple-see multiple values signum 86
re-use of software 4 simple?  242 reverse 30 single 45 rfind-if 73,
210 Sistine Chapel 11 alternate version 390 skeletons-see macros,
skeletons of rget 351 sketches 284 rich countries 285 sleep 65 rmapcar
54 slots Rome 283 accessor functions for 365 rotatef 29 declaring 364
rplaca 166 as global variables 379 rules initializing 365 structure of
322 isomorphic to methods 368 as virtual facts 323 read-only 367 see
also: Prolog, rules in shared 367 Smalltalk 350 Scheme some vs.
Common Lisp 259 sketch of 206 cond 192 sort 14, 352 macros in 392
sortf 176 returning functions in 62 sorting scope 16, 62 of arguments
176 scoundrels, patriotic 352 partial 184 scrod 219 see also:
stable-sort search trees 265 special 17 sequence operators 244 special
forms 9, 391 series 55 specialization-see methods, specializa- set 178
tion of set-difference 207 speed 23

   412 INDEX

   splicing 86 tagbody 155 splines-see Bezier curves tail-recursion
optimization 22 split-if 50 needed with CPS macros 298 sqrt 32 testing
for 388, 396 squash 160 taxable operators 32 stable-sort 352, 399
testing stacks incremental 37 allocation on 150 of macros-see macros,
testing of ATN registers 312 TEX vi, 5 in continuations 260, 261 tf
169 use for iteration 264 Theodebert 236 overflow of 396 three-valued
logic 151 Steele, Guy Lewis Jr.  ix, 43, 213, 395, till 154 396 time
65, 359 Sterling, Leon 398 times of evaluation 224, 229 strings toggle
169 building 57 top-down design 3 matching 231, 244 trace 111, 266,
309 as vectors 233 transition networks 306 Structure and
Interpretation of Computer transformation Programs 18 embedded
languages implemented by structured programming 100 116, 241 subseq
244 of macro arguments 107, 112 superclasses trec 75 precedence of 369
trees 70, 262 sketch of 352 cross-products of 265 Sussman, Gerald Jay
18, 395 leavesof72 symb 58 recursers on 70 symbols true-choose
building 57 breadth-first version 304 as data 385 T implementation 396
exported 383 depth-first version 396 imported 383 truncate 32
interning-see intern ttrav 74 names of 57, 129, 382 Turing Machines
vii see also: keywords twenty questions 77 symbol-function 12, 388
typecase 62 symbolic computation 398 type-of 371 symbol-macrolet 105,
205, 210 typep 243 symbol-name 58 types symbol-package 381 declaration
of 23 symbol-value 12, 178 specialization on 370 symbol-macros 105,
205, 236, 237 typing 44, 112 swapping values 29 undefmethod 373 T 396
unification 394

   INDEX 413

   union 206 with-output-to-string 58 unspecified order of result 207,
364 with-places 237 unions 207 with-slots 236 unspecialized parameters
373 with-struct 235 unwind-protect 148 writer's cramp 44 :use 384
&whole 95 user 381 Woods, William A. 305 utilities 40 workstations 348
as an investment 43, 392 world, ideal 109 become languages 113
mistaken argument against 59 X Windows vi, 5

   var?  239 zebra benchmark 396 variable capture-see capture
variables bound 16 #' 10, 226 free 16, 121 #( 233 generalized-see
generalized variables #.  75 global 36, 125, 268, 379 #: 128 varsym?
239 #?  226 redefined 335 #[ 227 vectors #\ 233 for ATN registers 313
#{ 229 creating with backquote 86 ' 225 matching 231, 244 see also:
quote visual aspects of source code 30, 213, , 84 231 ,@ 86, 138
voussoirs 8 : 383 values 32 :: 382 inversion for 393 @ 294 =values 267
240, 252, 328 ' see backquote | 58 wait 280 Wand, Mitchell 395
Weicker, Jacqueline J. x when-bind 145 when-bind* 145 while 154
with-answer 251 redefined 255 with-array 234 with-gensyms 145
with-inference 324 redefined 335, 340 with-matrix 234 with-open-file
147


File: onlisp.info,  Node: Concept Index,  Next: Function Index,  Prev: Book's Index,  Up: Top

Concept Index
*************

 [index ]
* Menu:

* 1 The Extensible Language:             1 Extensible Language.
                                                            (line   6)
* 1-1 Design by Evolution:               1-1 Design by Evolution.
                                                            (line   6)
* 1-2 Programming Bottom-Up:             1-2 Programming Bottom-Up.
                                                            (line   6)
* 1-3 Extensible Software:               1-3 Extensible Software.
                                                            (line   6)
* 1-4 Extending Lisp:                    1-4 Extending Lisp.
                                                            (line   6)
* 1-5 Why Lisp (or When):                1-5.Why Lisp (or When).
                                                            (line   6)
* 10 Other Macro Pitfalls:               10 Other Macro Pitfalls.
                                                            (line   6)
* 10-1 Number of Evaluations:            10-1 Number of Evaluations.
                                                            (line   6)
* 10-2 Order of Evaluation:              10-2 Order of Evaluation.
                                                            (line   6)
* 10-3 Non-functional Expanders:         10-3 Non-functional Expanders.
                                                            (line   6)
* 10-4 Recursion:                        10-4 Recursion.    (line   6)
* 11 Classic Macros:                     11 Classic Macros. (line   6)
* 11-1 Creating Context:                 11-1 Creating Context.
                                                            (line   6)
* 11-2 The with- Macro:                  11-2 The with- Macro.
                                                            (line   6)
* 11-3 Conditional Evaluation:           11-3 Conditional Evaluation.
                                                            (line   6)
* 11-4 Iteration:                        11-4 Iteration.    (line   6)
* 11-5 Iteration with Multiple Values:   11-5 Iteration with Multiple Values.
                                                            (line   6)
* 11-6 Need for Macros:                  11-6 Need for Macros.
                                                            (line   6)
* 12 Generalized Variables:              12 Generalized Variables.
                                                            (line   6)
* 12-1 The Concept:                      12-1 The Concept.  (line   6)
* 12-2 The Multiple Evaluation Problem:  12-2 The Multiple Evaluation Problem.
                                                            (line   6)
* 12-3 New Utilities:                    12-3 New Utilities.
                                                            (line   6)
* 12-4 More Complex Utilities:           12-4 More Complex Utilities.
                                                            (line   6)
* 12-5 Defining Inversions:              12-5 Defining Inversions.
                                                            (line   6)
* 13 Computation at Compile-Time:        13 Computation at Compile-Time.
                                                            (line   6)
* 13-1 New Utilities:                    13-1 New Utilities.
                                                            (line   6)
* 13-2 Example Bezier Curves:            13-2 Example Bezier Curves.
                                                            (line   6)
* 13-3 Applications:                     13-3 Applications. (line   6)
* 14 Anaphoric Macros:                   14 Anaphoric Macros.
                                                            (line   6)
* 14-1 Anaphoric Variants:               14-1 Anaphoric Variants.
                                                            (line   6)
* 14-2 Failure:                          14-2 Failure.      (line   6)
* 14-3 Referential Transparency:         14-3 Referential Transparency.
                                                            (line   6)
* 15 Macros Returning Functions:         15 Macros Returning Functions.
                                                            (line   6)
* 15-1 Building Functions:               15-1 Building Functions.
                                                            (line   6)
* 15-2 Recursion on Cdrs:                15-2 Recursion on Cdrs.
                                                            (line   6)
* 15-3 Recursion on Subtrees:            15-3 Recursion on Subtrees.
                                                            (line   6)
* 15-4 Lazy Evaluation:                  15-4 Lazy Evaluation.
                                                            (line   6)
* 16 Macro-Defining Macros:              16 Macro-Defining Macros.
                                                            (line   6)
* 16-1 Abbreviations:                    16-1 Abbreviations.
                                                            (line   6)
* 16-2 Properties:                       16-2 Properties.   (line   6)
* 16-3 Anaphoric Macros:                 Anaphoric Macros.  (line   6)
* 17 Read-Macros:                        17 Read-Macros.    (line   6)
* 17-1 Macro Characters:                 17-1 Macro Characters.
                                                            (line   6)
* 17-2 Dispatching Macro Characters:     17-2 Dispatching Macro Characters.
                                                            (line   6)
* 17-3 Delimiters:                       17-3 Delimiters.   (line   6)
* 17-4 When What Happens:                17-4 When What Happens.
                                                            (line   6)
* 18 Destructuring:                      18 Destructuring.  (line   6)
* 18-1 Destructuring on Lists:           18-1 Destructuring on Lists.
                                                            (line   6)
* 18-2 Other Structures:                 18-2 Other Structures.
                                                            (line   6)
* 18-3 Reference:                        18-3 Reference.    (line   6)
* 19 A Query Compiler:                   19 A Query Compiler.
                                                            (line   6)
* 19-1 The Database:                     19-1 The Database. (line   6)
* 19-2 Pattern-Matching Queries:         19-2 Pattern-Matching Queries.
                                                            (line   6)
* 19-3 A Query Interpreter:              19-3 A Query Interpreter.
                                                            (line   6)
* 19-4 Restrictions on Binding:          19-4 Restrictions on Binding.
                                                            (line   6)
* 19-5 A Query Compiler:                 19-5 A Query Compiler.
                                                            (line   6)
* 2 Functions:                           2 Functions.       (line   6)
* 2-1 Functions as Data:                 2-1 Functions as Data.
                                                            (line   6)
* 2-10 Functions from Lists:             2-10 Functions from Lists.
                                                            (line   6)
* 2-2 Defining Functions:                2-2 Defining Functions.
                                                            (line   6)
* 2-3 Functional Arguments:              2-3 Functional Arguments.
                                                            (line   6)
* 2-4 Functions as Properties:           2-4 Functions as Properties.
                                                            (line   6)
* 2-5 Scope:                             2-5 Scope.         (line   6)
* 2-7 Local Functions:                   2-7 Local Functions.
                                                            (line   6)
* 2-8 Tail-Recursion:                    2-8 Tail-Recursion.
                                                            (line   6)
* 2-9 Compilation:                       2-9 Compilation.   (line   6)
* 20 Continuations:                      20 Continuations.  (line   6)
* 20-1 Scheme Continuations:             20-1 Scheme Continuations.
                                                            (line   6)
* 20-2 Continuation-Passing Macros:      20-2 Continuation-Passing Macros.
                                                            (line   6)
* 20-3 Code-Walkers and CPS Conversion:  20-3 Code-Walkers and CPS Conversion.
                                                            (line   6)
* 21 Multiple Processes:                 21 Multiple Processes.
                                                            (line   6)
* 21-1 The Process Abstraction:          21-1 The Process Abstraction.
                                                            (line   6)
* 21-2 Implementation:                   21-2 Implementation.
                                                            (line   6)
* 21-3 The Less-than-Rapid Prototype:    21-3 The Less-than-Rapid Prototype.
                                                            (line   6)
* 22 Nondeterminism:                     22 Nondeterminism. (line   6)
* 22-1 The Concept:                      22-1 The Concept.  (line   6)
* 22-2 Search:                           22-2 Search.       (line   6)
* 22-3 Scheme Implementation:            22-3 Scheme Implementation.
                                                            (line   6)
* 22-4 Common Lisp Implementation:       22-4 Common Lisp Implementation.
                                                            (line   6)
* 22-6 True Nondeterminism:              22-6 True Nondeterminism.
                                                            (line   6)
* 23 Parsing with ATNs:                  23 Parsing with ATNs.
                                                            (line   6)
* 23-1 Background:                       23-1 Background.   (line   6)
* 23-2 The Formalism:                    23-2 The Formalism.
                                                            (line   6)
* 23-3 Nondeterminism:                   23-3 Nondeterminism.
                                                            (line   6)
* 23-4 An ATN Compiler:                  23-4 An ATN Compiler.
                                                            (line   6)
* 23-5 A Sample ATN:                     23-5 A Sample ATN. (line   6)
* 24 Prolog:                             24 Prolog.         (line   6)
* 24-1 Concepts:                         24-1 Concepts.     (line   6)
* 24-2 An Interpreter:                   24-2 An Interpreter.
                                                            (line   6)
* 24-3 Rules:                            24-3 Rules.        (line   6)
* 24-4 The Need for Nondeterminism:      24-4 The Need for Nondeterminism.
                                                            (line   6)
* 24-5 New Implementation:               24-5 New Implementation.
                                                            (line   6)
* 24-6 Adding Prolog Features:           24-6 Adding Prolog Features.
                                                            (line   6)
* 24-7 Examples:                         24-7 Examples.     (line   6)
* 24-8 The Senses of Compile:            24-8 The Senses of Compile.
                                                            (line   6)
* 25 Object-Oriented Lisp:               25 Object-Oriented Lisp.
                                                            (line   6)
* 25-1 Plus ça Change:                   25-1 Plus ça Change.
                                                            (line   6)
* 25-2 Objects in Plain Lisp:            25-2 Objects in Plain Lisp.
                                                            (line   6)
* 25-3 Classes and Instances:            25-3 Classes and Instances.
                                                            (line   6)
* 25-4 Methods:                          25-4 Methods.      (line   6)
* 25-5 Auxiliary Methods and Combination: 25-5 Auxiliary Methods and Combination.
                                                            (line   6)
* 25-6 CLOS and Lisp:                    25-5 Auxiliary Methods and Combination.
                                                            (line 174)
* 25-7 When to Object:                   25-7 When to Object.
                                                            (line   6)
* 3 Functional Programming:              3 Functional Programming.
                                                            (line   6)
* 3-1 Functional Design:                 3-1 Functional Design.
                                                            (line   6)
* 3-2 Imperative Outside-In:             3-2 Imperative Outside-In.
                                                            (line   6)
* 3-3 Functional Interfaces:             3-3 Functional Interfaces.
                                                            (line   6)
* 3-4 Interactive Programming:           3-4 Interactive Programming.
                                                            (line   6)
* 4 Utility Functions:                   4 Utility Functions.
                                                            (line   6)
* 4-1 Birth of a Utility:                4-1 Birth of a Utility.
                                                            (line   6)
* 4-2 Invest in Abstraction:             4-2 Invest in Abstraction.
                                                            (line   6)
* 4-3 Operations on Lists:               4-3 Operations on Lists.
                                                            (line   6)
* 4-4 Search:                            4-4 Search.        (line   6)
* 4-5 Mapping:                           4-5 Mapping.       (line   6)
* 4-6 I/O:                               4-6 I/O.           (line   6)
* 4-7 Symbols and Strings:               4-7 Symbols and Strings.
                                                            (line   6)
* 4-8 Density:                           4-8 Density.       (line   6)
* 5 Returning Functions:                 5 Returning Functions.
                                                            (line   6)
* 5-1 Common Lisp Evolves:               5-1 Common Lisp Evolves.
                                                            (line   6)
* 5-2 Orthogonality:                     5-2 Orthogonality. (line   6)
* 5-3 Memoizing:                         5-3 Memoizing.     (line   6)
* 5-4 Composing Functions:               5-4 Composing Functions.
                                                            (line   6)
* 5-5 Recursion on Cdrs:                 5-5 Recursion on Cdrs.
                                                            (line   6)
* 5-6 Recursion on Subtrees:             5-6 Recursion on Subtrees.
                                                            (line   6)
* 5-7 When to Build Functions:           5-7 When to Build Functions.
                                                            (line   6)
* 6 Functions as Representation:         6 Functions as Representation.
                                                            (line   6)
* 6-1 Networks:                          6-1 Networks.      (line   6)
* 6-2 Compiling Networks:                6-2 Compiling Networks.
                                                            (line   6)
* 6-3 Looking Forward:                   6-3 Looking Forward.
                                                            (line   6)
* 7 Macros:                              7 Macros.          (line   6)
* 7-1 How Macros Work:                   7-1 How Macros Work.
                                                            (line   6)
* 7-10 Macros from Functions:            7-10 Macros from Functions.
                                                            (line   6)
* 7-11 Symbol Macros:                    7-11 Symbol Macros.
                                                            (line   6)
* 7-2 Backquote:                         7-2 Backquote.     (line   6)
* 7-3 Defining Simple Macros:            7-3 Defining Simple Macros.
                                                            (line   6)
* 7-4 Testing Macroexpansion:            7-4 Testing Macroexpansion.
                                                            (line   6)
* 7-5 Destructuring in Parameter Lists:  7-5 Destructuring in Parameter Lists.
                                                            (line   6)
* 7-6 A Model of Macros:                 7-6 A Model of Macros.
                                                            (line   6)
* 7-7 Macros as Programs:                7-7 Macros as Programs.
                                                            (line   6)
* 7-8 Macro Style:                       7-8 Macro Style.   (line   6)
* 7-9 Dependence on Macros:              7-9 Dependence on Macros.
                                                            (line   6)
* 8 When to Use Macros:                  8 When to Use Macros.
                                                            (line   6)
* 8-1 When Nothing Else Will Do:         8-1 When Nothing Else Will Do.
                                                            (line   6)
* 8-2 Macro or Function?:                8-2 Macro or Function?.
                                                            (line   6)
* 8-3 Applications for Macros:           8-3 Applications for Macros.
                                                            (line   6)
* 9 Variable Capture:                    9 Variable Capture.
                                                            (line   6)
* 9-1 Macro Argument Capture:            9-1 Macro Argument Capture.
                                                            (line   6)
* 9-2 Free Symbol Capture:               9-2 Free Symbol Capture.
                                                            (line   6)
* 9-3 When Capture Occurs:               9-3 When Capture Occurs.
                                                            (line   6)
* 9-4 Avoiding Capture with Better Names: 9-4 Avoiding Capture with Better Names.
                                                            (line   6)
* 9-5 Avoiding Capture by Prior Evaluation: 9-5 Avoiding Capture by Prior Evaluation.
                                                            (line   6)
* 9-6 Avoiding Capture with Gensyms:     9-6 Avoiding Capture with Gensyms.
                                                            (line   6)
* 9-7 Avoiding Capture with Packages:    9-7 Avoiding Capture with Packages.
                                                            (line   6)
* 9-8 Capture in Other Name-Spaces:      9-8 Capture in Other Name-Spaces.
                                                            (line   6)
* 9-9 Why Bother?:                       9-9 Why Bother?.   (line   6)
* Appendix Packages:                     Appendix Packages. (line   6)
* Book's Index:                          Book's Index.      (line   6)
* Notes:                                 Notes.             (line   6)


File: onlisp.info,  Node: Function Index,  Prev: Concept Index,  Up: Top

Function Index
**************

 [index ]
* Menu:

* 14-1 Anaphoric Variants:               14-1 Anaphoric Variants.
                                                              (line 6)

